<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis常用命令学习]]></title>
    <url>%2F2019%2F04%2F27%2FRedis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[学习Redis基本命令 字符串 SET set key value [expiration EX seconds|PX milliseconds][NX|XX] 将字符串值 value 关联到 key 。如果 key 已经持有其他值， SET 就覆写旧值， 无视类型。当 SET 命令对一个带有生存时间（TTL）的键进行设置之后， 该键原有的 TTL 将被清除。 从 Redis 2.6.12 版本开始， SET 命令只在设置操作成功完成时才返回 OK ； 如果命令使用了 NX或者 XX 选项， 但是因为条件没达到而造成设置操作未执行， 那么命令将返回空批量回复（NULL Bulk Reply）。 SET key “value”GET key SET key “value” EX seconds：将键的过期时间设置为 seconds 秒。 执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value 。 SET key “value” NX：只在键不存在时， 才对键进行设置操作。 执行 SET key value NX 的效果等同于执行 SETNX key value 。 SET key “value” XX：只在键已经存在时， 才对键进行设置操作。 GET 返回与键 key 相关联的字符串值。 GETSET 将键 key 的值设为 value ， 并返回键 key 在被设置之前的旧值。 键 key 在被设置之前并不存在， 那么命令返回 nil 。 STRLEN key 返回键 key 储存的字符串值的长度。当键 key 不存在时， 命令返回 0 。 APPEND 如果键 key 已经存在并且它的值是一个字符串， APPEND 命令将把 value 追加到键 key 现有值的末尾。如果 key 不存在， APPEND 就简单地将键 key 的值设为 value ， 就像执行 SET key value 一样。 SETRANGE SETRANGE key offset value 从偏移量 offset 开始， 用 value 参数覆写(overwrite)键 key 储存的字符串值。不存在的键 key 当作空白字符串处理。 GETRANGE GETRANGE key start end 返回键 key 储存的字符串值的指定部分， 字符串的截取范围由 start 和 end 两个偏移量决定 (包括 start 和 end 在内)。 INCR 为键 key 储存的数字值加上一。如果键 key 不存在， 那么它的值会先被初始化为 0 ， 然后再执行 INCR 命令。如果键 key 储存的值不能被解释为数字， 那么 INCR 命令将返回一个错误。 INCRBY INCRBY key increment 为键 key 储存的数字值加上增量 increment 。如果键 key 不存在， 那么键 key 的值会先被初始化为 0 ， 然后再执行 INCRBY 命令。 List LPUSH 将一个或多个值 value 插入到列表 key 的表头。如果有多个 value 值，那么各个 value 值按从左到右的顺序依次插入到表头： 比如说，对空列表 mylist 执行命令 LPUSH mylist a b c ，列表的值将是 c b a ，这等同于原子性地执行 LPUSH mylist a 、 LPUSH mylist b 和 LPUSH mylist c 三个命令。 LPUSHX 将值 value 插入到列表 key 的表头，当且仅当 key 存在并且是一个列表。 RPUSH 参考 redisdoc]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-结构型]]></title>
    <url>%2F2019%2F04%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[设计模式中结构型模式。结构型模式旨在通过改变代码结构来达到解耦的目的，使得我们的代码容易维护和扩展。 主要包括代理模式（Proxy Pattern），适配器模式（Adapter Pattern），桥接（Bridge），装饰器模式（Decorator Pattern），外观模式（Facade Pattern），组合模式（Composite Pattern），享元模式。 1. 代理模式（Proxy Pattern）代理模式（Proxy Pattern）中，一个类代表另一个类的功能。 Spring框架的AOP就是代理模式的体现。 意图：为其他对象提供一种代理以控制对这个对象的访问。 1234567891011121314151617181920212223242526272829303132public interface FoodService&#123; Food makeChicken(); Food makeNoodle();&#125;public class FoodServiceImpl implements FoodService&#123; public Food makechicken()&#123; Food f = new Chicken(); f.setChicken("aa"); f.setSpicy("bb"); return f; &#125; public Food makeNoodle()&#123; Food f = new Noodle(); f.setNoodle("aa"); f.setSalt("bb"); return f; &#125;&#125;public class FoodServiceProxy implements FoodService&#123; private FoodService foodService = new FoodServiceImpl(); public Food makeChicken()&#123; // 制作chicken Food food = foodService.makeChicken(); // chicken制作完成 food.addCondiment("add"); return food; &#125;&#125; 代理模式说白了就是做 “方法包装” 或做 “方法增强”。AOP 中，其实就是动态代理的过程。比如 Spring 中，我们自己不定义代理类，但是 Spring 会帮我们动态来定义代理，然后把我们定义在 @Before、@After、@Around 中的代码逻辑动态添加到代理中。 JDK java.util.Arrays#asList() java.util.Collections#list() java.util.Collections#enumeration() javax.xml.bind.annotation.adapters.XMLAdapter 2. 适配器模式（Adapter Pattern）适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。 123456789101112131415161718public interface Duck &#123; public void quack();// 鸭叫 public void fly();&#125;public interface Cock &#123; public void gobble();// 鸡叫 public void fly();&#125;public class WildCock implements Cock&#123; public void gobble()&#123; System.out.println("鸡叫");; &#125; public void fly()&#123; System.out.println("鸡飞"); &#125;&#125; 使用适配器模式，让鸭实现鸡叫 123456789101112public class CockAdapter implements Duck&#123; Cock cock; public CockAdapter(Cock cock) &#123; this.cock = cock; &#125; @Override public void quack()&#123; // 鸡叫 cock.gobble(); &#125;&#125; 3. 桥梁模式（Bridge）桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。 首先定义桥梁，接口，定义提供的接口方法 123public interface DrawApi&#123; public void draw(int radius, int x, int y);&#125; 实现类 123456789101112public class RedPen implements DrawApi&#123; @Override public void draw(int radius, int x, int y)&#123; System.out.println("用红色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125;public class GreenPen implements DrawAPI &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用绿色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125; 定义抽象类 12345678public abstract class Shape &#123; protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI)&#123; this.drawAPI = drawAPI; &#125; public abstract void draw(); &#125; 1234567891011121314// 长方形public class Rectangle extends Shape &#123; private int x; private int y; public Rectangle(int x, int y, DrawAPI drawAPI) &#123; super(drawAPI); this.x = x; this.y = y; &#125; public void draw() &#123; drawAPI.draw(0, x, y); &#125;&#125; 1234public static void main(String[] args) &#123; Shape redRectangle = new Rectangle(4, 8, new RedPen()); redRectangle.draw();&#125; JDK AWT JDBC 4. 装饰模式（Decorator Pattern）装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。 意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 1234567/** * 定义基本饮料类 */public abstract class Beverage&#123; public abstract String getDesc(); public abstract double price();&#125; 添加三个饮料实现红茶， 绿茶 1234567891011121314151617181920212223public class BlackTea extends Beverage&#123; @Override public String getDesc() &#123; return "红茶"; &#125; @Override public double price() &#123; return 11; &#125;&#125;public class GreenTea extends Beverage&#123; @Override public String getDesc() &#123; return "绿茶"; &#125; @Override public double price() &#123; return 22; &#125;&#125; 调料，即装饰器的基类，继承自Beverage 1234// 调料public abstract class Condiment extends Beverage&#123; &#125; 定义具体调料 12345678910111213141516171819202122232425262728public class Lemon extends Condiment&#123; // private Beverage beverage; // 传入具体饮料 public Lemon(Beverage beverage)&#123; this.beverage = beverage; &#125; @Override public String getDesc() &#123; // 装饰 return beverage.getDesc() + " 加柠檬"; &#125;&#125;public class Mango extends Condiment &#123; private Beverage bevarage; public Mango(Beverage bevarage) &#123; this.bevarage = bevarage; &#125; public String getDescription() &#123; return bevarage.getDescription() + ", 加芒果"; &#125; public double cost() &#123; return beverage.cost() + 3; // 加芒果需要 3 元 &#125;&#125; 客户端 12345678910public static void main(String[] args) &#123; // 首先，我们需要一个基础饮料，红茶、绿茶或咖啡 Beverage beverage = new GreenTea(); // 开始装饰 beverage = new Lemon(beverage); // 先加一份柠檬 beverage = new Mongo(beverage); // 再加一份芒果 System.out.println(beverage.getDescription() + " 价格：￥" + beverage.cost()); //"绿茶, 加柠檬, 加芒果 价格：￥16"&#125; JDK java.io.BufferedInputStream(InputStream) java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap 5. 外观模式（Facade Pattern）外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。 意图：为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 创建接口，和实现类 123456789101112131415161718public interface Shape&#123; void draw();&#125;public class Circle implements Shape&#123; @Override public void draw()&#123; System.out.println("Circle draw"); &#125;&#125;public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println("Square::draw()"); &#125;&#125; 创建外观类 12345678910111213141516public class ShapeMaker&#123; private Shape circle; private Shape square; public ShapeMaker() &#123; circle = new Circle(); square = new Square(); &#125; public void drawCircle()&#123; circle.draw(); &#125; public void drawSquare()&#123; square.draw(); &#125;&#125; 客户端 123456public static void main(String[] args) &#123; ShapeMaker shapeMaker = new ShapeMaker(); shapeMaker.drawCircle(); shapeMaker.drawSquare(); &#125; 6. 组合模式（Composite Pattern）组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。 1234567891011121314151617181920212223242526272829public class Employee &#123; private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; // 下属 public Employee(String name,String dept, int sal) &#123; this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); &#125; public void add(Employee e) &#123; subordinates.add(e); &#125; public void remove(Employee e) &#123; subordinates.remove(e); &#125; public List&lt;Employee&gt; getSubordinates()&#123; return subordinates; &#125; public String toString()&#123; return ("Employee :[ Name : " + name + ", dept : " + dept + ", salary :" + salary+" ]"); &#125; &#125; JDK javax.swing.JComponent#add(Component) java.awt.Container#add(Component) java.util.Map#putAll(Map) java.util.List#addAll(Collection) java.util.Set#addAll(Collection) 7. 享元模式JDKJava 利用缓存来加速大量小对象的访问时间。 java.lang.Integer#valueOf(int) java.lang.Boolean#valueOf(boolean) java.lang.Byte#valueOf(byte) java.lang.Character#valueOf(char) 参考 Javadoop - 设计模式也可以这么简单 CS-Notes - 设计模式 菜鸟教程 - 设计模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-创建型]]></title>
    <url>%2F2019%2F04%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[设计模式中的创建型模式。创建型模式的作用就是创建对象，说到创建一个对象，最熟悉的就是 new 一个对象，然后 set 相关属性。但是，在很多场景下，我们需要给客户端提供更加友好的创建对象的方式，尤其是那种我们定义了类，但是需要提供给其他开发者用的时候。包括单例，简单工厂，工厂方法，抽象工厂，生成器，原型模式。 1. 单例模式（重要）为了保证全局使用的是同一对象，一方面是安全性考虑，一方面是为了节省资源。 将该类的构造方法声明为private,使得无法从外部类来实例化对象，然后在类内部的方法中返回实例化的单一对象。 1. 饿汉模式12345678910public class Singleton &#123; // new Singleton() 堵死 private Singleton() &#123;&#125;; // 私有静态实例，该类第一次使用进行创建 private static Singleton instance = new Singleton(); public static Singleton getInstance() &#123; return instance; &#125;&#125; 单例的实例被声明成 static 和 final 变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。一般情况下使用。 2. 懒汉模式(线程不安全)123456789101112public class Singleton &#123; private Singleton() &#123; &#125; private static Singleton instance; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 使用了懒加载模式，但是却存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例 3. 懒汉模式 （线程安全）123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance;&#125; 使用 synchronized,每次调用getInstance方法时都需要进行同步，造成不必要的同步开销， 4. 双重检查模式（DCL）1234567891011121314public class Singleton &#123; private Singleton()&#123;&#125; private volatile static Singleton instance; public static Singleton getInstance()&#123; if(instance == null)&#123; synchronized (Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 双重检验锁模式（double checked locking pattern），两次检验instance是否为null。 5. 嵌套类类单例模式（推荐）1234567891011public class Singleton &#123; private Singleton() &#123;&#125; private static class SingletonHolder &#123; private static final Singleton INSTANCEE = new Singleton(); &#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCEE; &#125;&#125; 这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。 6. 枚举类（最佳）123public enum EasySingleton&#123; INSTANCE;&#125; 实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。 总结一般情况下使用第一种 饿汉模式，明确要求要懒加载（lazy initialization），使用第五种静态内部类。涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。 2. 简单工厂模式简单工厂模式通常就是这样，一个工厂类 XxxFactory，里面有一个静态方法，根据我们不同的参数，返回不同的派生自同一个父类（或实现同一接口）的实例对象。 12345678910public class SimpleFactory &#123; public Product createProduct(int type)&#123; if(type == 1)&#123; return new ConcreteProduct1(); &#125; else if(type == 2)&#123; return new ConcreteProduct2(); &#125; return new ConcreteProduct(); &#125;&#125; 3. 工厂模式（重要）意图：定义了一个创建对象的接口，但由子类决定要实例化哪个类。工厂方法把实例化操作推迟到子类。 简单工厂中，创建对象的是另一个类，而在工厂方法中，是由子类来创建对象。 Spring中的IOC就用到了工厂模式。 1234567891011121314151617181920212223public interface FoodFactory&#123; Food makeFood(String name);&#125;public class ChineseFoodFactory implements FoodFactory&#123; @Override public Food makeFood(String name)&#123; if (name.equals("A")) &#123; return new ChineseFoodA(); &#125; else if (name.equals("B")) &#123; return new ChineseFoodB(); &#125; else &#123; return null; &#125; &#125;&#125;public class AmericaFoodFactory implements FoodFactory&#123; @Override public Food makeFood(String name)&#123; return new AmericaFood(name); &#125;&#125; 调用 12345678public class App&#123; public static void main(String[] args)&#123; // 选择具体工厂 FoodFactory fac = new ChineseFoodFactory(); // 由工厂生产对象 Food food = fac.makeFood("A"); &#125;&#125; 4. 抽象工厂模式意图：提供一个接口，用于创建 相关的对象家族 。主要解决接口选择问题。 12345678public static void main(String[] args)&#123; // 建造大厂 ComputerFactory cf = new AmdFactory(); Cpu cpu = cf.makeCpu(); Disk disk = cf.makeDisk(); // 组装 Computer res = new Computer(cpu, disk);&#125; 5. 建造者模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class User &#123; private String name; private String pass; private String nickName; private int age; private User(String name, String pass, String nickName, int age) &#123; this.name = name; this.pass = pass; this.nickName = nickName; this.age = age; &#125; // 静态方法，生成一个Builder public static UserBuilder builder() &#123; return new UserBuilder(); &#125; public static class UserBuilder &#123; // 下面是和 User 一模一样的一堆属性 private String name; private String pass; private String nickName; private int age; private UserBuilder() &#123; &#125; // 链式调用各个属性值，返回UserBuilder public UserBuilder name(String name) &#123; this.name = name; return this; &#125; public UserBuilder pass(String pass) &#123; this.pass = pass; return this; &#125; public UserBuilder nickName(String nickName) &#123; this.nickName = nickName; return this; &#125; public UserBuilder age(int age) &#123; this.age = age; return this; &#125; // build() 方法负责将 UserBuilder 中设置好的属性“复制”到 User 中。 public User build() &#123; return new User(name, pass, nickName, age); &#125; &#125;&#125; 6. 原型模式意图：原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。 123public abstract class Prototype&#123; abstract Prototype myClone();&#125; 1234567891011public class ConcretePrototype extends Prototype&#123; String filed; public ConcretePrototype(Stirng filed)&#123; this.filed = filed; &#125; @Override Prototype myClone() &#123; return new ConcretePrototype(filed); &#125;&#125; Object 类中有一个 clone() 方法，它用于生成一个新的对象，java 要求我们的类必须先实现 Cloneable 接口，此接口没有定义任何方法，但是不这么做的话，在 clone() 的时候，会抛出 CloneNotSupportedException 异常。 java 的克隆是浅克隆，碰到对象引用的时候，克隆出来的对象和原对象中的引用将指向同一个对象。通常实现深克隆的方法是将对象进行序列化，然后再进行反序列化。 参考 Javadoop - 设计模式也可以这么简单 CS-Notes - 设计模式 设计模式（二）单例模式的七种写法 菜鸟教程-单例模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序]]></title>
    <url>%2F2019%2F04%2F11%2F%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[整理常用排序算法。 约定将排序代码放在 sort()方法中。待排序元素实现Comparable接口。 12345678910111213141516171819202122232425public abstract class BaseSort&lt;T extends Comparable&lt;T&gt;&gt; &#123; /** * 排序代码 * * @param array 排序数组 */ public abstract void sort(T[] array); /** * 判断前一个元素是否小于后一个元素 */ protected boolean less(T a, T b) &#123; return a.compareTo(b) &lt; 0; &#125; /** * 交换数组中两个元素 */ protected void swap(T[] nums, int i, int j) &#123; T temp = nums[i]; nums[i] = nums[j]; nums[j] = nums[i]; &#125;&#125; 选择排序描述首先找到数组中最小的那个元素，然后将它和数组中第一个元素交换位置（第一个元素就是最小元素就和自己交换）。之后在剩下的元素中找到最小元素，将它和数组第二位置元素交换位置。知道整个数组有序。它在不断选在剩余元素中的最小者。 选择排序需要 N^2 / 2次比较和 N 次交换。它的运行时间和输入无关。数据移动是最少的。 该算法将第 i 小的元素放在第 i 个位置，i左边的元素不会再被访问。 时间复杂度：O(N^2)。空间复杂度O(1)。排序稳定。 动图 代码1234567891011121314public class Selection&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] array) &#123; int len = array.length; for (int i = 0; i &lt; len; i++) &#123; for (int j = i + 1; j &lt; len; j++) &#123; int min = i; if (less(array[j], array[min])) min = j; swap(array, i, min); &#125; &#125; &#125;&#125; 插入排序描述从第一个元素开始，该元素认为被已排序，取出下一个元素 当前索引左边的元素有序，但可能会被移动。所需时间取决于输入的元素初始序列。 时间复杂度O(n^2)，空间O(1)，稳定。 动图 代码1234567891011public class Insertion&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; for (int i = 1; i &lt; len; ++i) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j - 1]); --j) &#123; swap(a, j, j - 1); &#125; &#125; &#125;&#125; 希尔排序描述基于插入排序。思想是使数组中任意间隔为h的元素都是有序的。希尔排序使用插入排序对间隔 h 的序列进行排序。通过不断减小 h，最后令 h=1，就可以使得整个数组是有序的。 希尔排序的运行时间达不到平方级别，使用递增序列 1, 4, 13, 40, … 的希尔排序所需要的比较次数不会超过 N 的若干倍乘于递增序列的长度。后面介绍的高级排序算法只会比希尔排序快两倍左右。 动图 代码123456789101112131415161718public class Shell&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; int h = 1; while (h &lt; len / 3) &#123; h = 3 * h + 1; &#125; while (h &gt;= 1) &#123; for (int i = h; i &lt; len; ++i) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; swap(a, j, j - 1); &#125; &#125; h /= 3; &#125; &#125;&#125; 归并排序描述将一个数组递归的分成两半分别排序，然后将结果归并。 稳定排序。性能不受输入影响。时间复杂度O(NlogN) 动图 1. 原地归并将a[low … mid]和 a[mid + 1… hi]归并成一个有序数组，将结果存在 a[ low … hi]中。 1234567891011121314151617181920212223242526public class MergeSort&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; protected T[] aux; protected void merge(T[] a, int low, int mid, int high) &#123; // 先将所有元素复制到aux[] 中，然后归并回 a[]中。 int i = low, j = mid + 1; // 复制数据到辅助数组 for (int k = low; k &lt;= high; ++k) &#123; aux[i] = a[i]; &#125; for (int k = low; k &lt;= high; ++k) &#123; if (i &gt; mid) &#123; // 左边用尽，取右边元素 a[k] = aux[j++]; &#125; else if (j &gt; high) &#123; a[k] = aux[i++]; &#125; else if (less(aux[j], aux[i])) &#123; // 右半边当前元素小于左半边当前，取右半边 a[k] = aux[j++]; &#125; else &#123; a[k] = aux[i++]; &#125; &#125; &#125;&#125; 2. 自顶向下归并排序时间复杂度一般为O(NlogN) 1234567891011121314151617181920public class Up2DownMerge&lt;T extends Comparable&lt;T&gt;&gt; extends MergeSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; aux = (T[]) new Comparable[a.length]; sort(a, 0, a.length - 1); &#125; private void sort(T[] a, int low, int high) &#123; if (high &lt;= low) &#123; return; &#125; int mid = low + (high - low) &gt;&gt; 1; // 将左半边排序 sort(a, low, mid); // 右半边排序 sort(a, mid + 1, high); // 归并 merge(a, low, mid, high); &#125;&#125; 3. 自底向上归并123456789101112public class Down2UpMerge&lt;T extends Comparable&lt;T&gt;&gt; extends MergeSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; aux = (T[]) new Comparable[len]; for (int sz = 1; sz &lt; len; sz += sz) &#123; for (int low = 0; low &lt; len - sz; low += sz * 2) &#123; merge(a, low, low + sz - 1, Math.min(low + sz + sz - 1, len - 1)); &#125; &#125; &#125;&#125; 快速排序描述平均时间复杂度：O(NlogN)，额外空间O(NlogN)，不稳定 动图 基本算法12345678910111213141516171819202122232425262728293031323334353637383940414243public class QuickSort&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] array) &#123; sort(array, 0, array.length - 1); &#125; private void sort(T[] array, int low, int high) &#123; if (high &lt;= low) &#123; return; &#125; int j = partition(array, low, high); sort(array, low, j - 1); sort(array, j + 1, high); &#125; /** 一般写法 **/ private void sort2(T[] arr, int lo, int hi) &#123; if (lo &gt;= hi) &#123; return; &#125; int i = lo, j = hi; T k = arr[lo]; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; arr[j].compareTo(k) &gt; 0) &#123; j--; &#125; if (i &lt; j) &#123; arr[i++] = arr[j]; &#125; while (i &lt; j &amp;&amp; arr[i].compareTo(k) &lt; 0) &#123; i++; &#125; if (i &lt; j) &#123; arr[j--] = arr[i]; &#125; &#125; arr[i] = k; sort(arr, lo, i - 1); sort(arr, i + 1, hi); &#125;&#125; 切分1234567891011121314151617181920212223242526272829303132private int partition(T[] a, int low, int high) &#123; int i = low, j = high + 1; T temp = a[low]; while (true) &#123; while (less(a[++i], temp) &amp;&amp; i != high) ; while (less(temp, a[--j]) &amp;&amp; j != low) ; if (i &gt;= j) &#123;break;&#125; swap(a, i, j); &#125; // 切分值留在j中。 swap(a, low, j); return j;&#125;/** * 切分的另一种写法 */private int partition2(T[] a, int low, int high) &#123; T pivot = a[low]; while (low &lt; high) &#123; // 从右向左，找到第一个小于pivot的元素 while (low &lt; high &amp;&amp; less(pivot, a[])) high--; // 交换 a[low] = a[high]; // 从左到右找到第一个大于pivot的元素 while (low &lt; high &amp;&amp; less(a[], pivot)) low++; a[high] = a[low]; &#125; a[low] = pivot; return low; // a[0..low-1] &lt; pivot &lt; a[low+1...high]&#125; 按照a[low]的值进行切分。从左向右找到第一个大于temp的元素a[i]，从右向左找到第一个小于temp的元素a[j]，交换a[i] 和 a[j]，使得i左侧的元素都不大于temp，j右侧的元素都不小于temp，i和j相遇时循环退出，交换a[low]和a[j]。 改进-三向快速切分对于有大量重复元素的数组，可以将数组切分为三部分，分别对应小于、等于和大于切分元素。 三向切分快速排序对于有大量重复元素的随机数组可以在线性时间内完成排序。 12345678910111213141516171819202122232425public class QuickSort3way&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; sort(a, 0, a.length - 1); &#125; private void sort(T[] a, int low, int high) &#123; if (high &lt; low) return; int lt = low, i = low + 1, gt = high; T v = a[low]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; swap(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; swap(a, i, gt--); &#125; else &#123; i++; &#125; &#125; // a[lo...lt-1] &lt; v=a[lt...gt] &lt; a[gt+1...high] sort(a, low, lt - 1); sort(a, gt + 1, high); &#125;&#125; 使用切分解决Top K问题快速排序的 partition() 方法，会返回一个整数 j 使得 a[l..j-1] 小于等于 a[j]，且 a[j+1..h] 大于等于 a[j]，此时 a[j] 就是数组的第 j 大元素。partition()可以使用O(N)的平均复杂时间从无序数组找到第K大元素。 可以利用这个特性找出数组的第 k 个元素。 1234567891011121314public T select(T[] nums, int k) &#123; int low = 0, high = nums.length - 1; while (high &gt; low) &#123; int j = partition2(nums, low, high); if (j == k) &#123; return nums[k]; &#125; else if (j &gt; k) &#123; high = j - 1; &#125; else &#123; low = j + 1; &#125; &#125; return nums[k];&#125; 题目二输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 在线编程 123456789101112131415161718192021public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int [] input, int k) &#123; int len = input.length; ArrayList&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(len &lt; 0 || k &gt; len || k&lt;=0) return res; int start = 0, end = len - 1; int index = partion(input, start, end); while(index != (k - 1))&#123; if(index &gt; (k-1))&#123; end = index - 1; index = partion(input, start, end); &#125;else&#123; start = index + 1; index = partion(input, start, end); &#125; &#125; for(int i = 0;i &lt; k;i++)&#123; res.add(input[i]); &#125; return res; &#125;&#125; 堆排序描述时间复杂度，最坏平均最好都是O(NlogN)，空间O(1)，不稳定。 动图 实现堆heap[0]不放元素，根节点是heap[1] 1234567891011121314151617181920212223242526public class Heap&lt;T extends Comparable&lt;T&gt;&gt; &#123; private T[] heap; private int n; public Heap(int maxN) &#123; this.heap = (T[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return n == 0; &#125; public int siza() &#123; return n; &#125; public boolean less(int i, int j) &#123; return heap[i].compareTo(heap[j]) &lt; 0; &#125; public void swap(int i, int j) &#123; T temp = heap[i]; heap[i] = heap[j]; heap[j] = temp; &#125;&#125; 上浮在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮。 123456789/** * 节点比父节点大，上浮 */private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k &gt;&gt; 1, k)) &#123; swap(k &gt;&gt; 1, k); k = k &gt;&gt; 1; &#125;&#125; 下沉12345678910111213/** * 父节点小于子节点，下沉 */private void sink(int k) &#123; while ((k &lt;&lt; 1) &lt;= n) &#123; int j = k &lt;&lt; 1; // 找到两个子节点最大的那个子节点 if (j &lt; n &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; swap(k, j); k = j; &#125;&#125; 插入元素插入到最底，然后上浮到合适位置 1234public void insert(T a)&#123; heap[ ++ n] = a; swim(n);&#125; 删除最大12345678910/** * 删除最大元素。首先从数组顶端删除最大，将数组最后一个放在顶端，然后让该元素下沉。 */public T delMax()&#123; T max = heap[1]; swap(1, n --); heap[n+1] = null; sink(1); return max;&#125; 堆排序将最大元素和当前堆中数组最后一个元素交换位置，并且不删除它，那么就可以得到一个从未到头的递减序列。 构建从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 交换堆顶与最后一个元素交换后进行下沉操作 实现123456789101112131415161718192021222324public class HeapSort&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; for (int k = len &gt;&gt; 1; k &gt;= 1; k--) &#123; sink(a, k, len); &#125; while (len &gt; 1) &#123; // 交换后进行下沉操作 swap(a, 1, len--); sink(a, 1, len); &#125; &#125; private void sink(T[] num, int k, int n) &#123; while ((k &lt;&lt; 1) &lt;= n) &#123; int j = k &lt;&lt; 1; if (j &lt; n &amp;&amp; less(num[j], num[j + 1])) j++; if (!less(num[k], num[j])) break; swap(num, k, j); k = j; &#125; &#125;&#125; 分析堆高度为logN，插入删除的复杂度都是logN。 堆排序对N个节点进行下沉，复杂度NlogN。 没有利用额外空间。没有利用局部性原理缓存。 题目输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 在线编程 利用堆解决使用最大堆保存这k个数，每次只和堆顶比，如果比堆顶小，删除堆顶，新数入堆。 时间：O(nlogk) Java中的优先队列(PriorityQueue)是基于堆实现的。优先队列中的元素可以通过Compartor定义规则。 12345678910111213141516171819202122232425import java.util.ArrayList;import java.util.PriorityQueue;import java.util.Comparator;public class Solution &#123; public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int[] input, int k) &#123; int len = input.length; ArrayList&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if (k &lt;= 0 || len &lt; k) return res; PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;&gt;(k, Comparator.reverseOrder()); // 将数组中的元素入堆 for (int a : input) &#123; if (maxHeap.size() &lt; k) &#123; maxHeap.offer(a); &#125; else if (maxHeap.peek() &gt; a) &#123; maxHeap.poll(); maxHeap.offer(a); &#125; &#125; res.addAll(maxHeap); return res; &#125;&#125; 总结 稳定性定义：经过排序之后,能使值相同的数据保持原顺序中的相对位置不变 稳定性口诀： 快选堆希不稳（快速排序，选择排序，堆排序，希尔排序） 插冒归计基稳（插入排序，冒泡排序，归并排序，计数，基数） 参考 《算法》第四版 博客园 - 十大经典排序算法（动图演示） 被忽视的 partition 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-四]]></title>
    <url>%2F2019%2F04%2F11%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[线程池 概述 使用线程池好处 降低资源消耗，重复利用已创建线程 提高响应速度，任务可以不创建就立即执行 提高线程可管理性，线程池统一分配，监控 Executor框架接口Executor接口123public interface Executor &#123; void execute(Runnable command);&#125; 启动线程： 12Thread t = new Thread();executor.execute(t); ExecutorService接口一般使用该接口 12ExecutorService executor = Executors.newFixedThreadPool(args...);ExecutorService executor = Executors.newCachedThreadPool(args...); ThreadPoolExecutorThreadPoolExecutor 是 JDK 中的线程池实现，这个类实现了一个线程池需要的各个方法，它实现了任务提交、线程管理、监控等等方法。 构造函数及重要属性1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize：核心线程数量，默认不会被回收 maximumPoolSize：最大线程数量，线程池能容纳的最大容量，上限被CAPACITY限制（2^29-1）。corePoolSize到maximumPoolSize之间的线程会被回收 keepAliveTime：如果线程数超过corePoolSize，有些线程空闲时间超过该值，执行关闭这些线程 unit：keepAliveTime单位 workQueue：存放任务的队列，添加任务时如果当前线程数超过corePoolsize，向该队列添加任务，线程池中的线程负责到队列中拉取任务 threadFactory：创建线程的工厂类 handler：任务执行失败使用handler通知调用者，默认为抛出异常。 线程池状态123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; Running：接受新任务，处理队列中的任务 Shutdown：不接受提交新任务，处理等待队列中的任务 Stop：不接受提交新任务，不处理队列中任务，中断正在执行的线程 Tidying：所有任务销毁，执行terminated() Terminated：terminated()结束后 拒绝策略队列和线程池都满了，线程池饱和，采取一种策略处理提交的新任务。 线程池框架提供四种策略： AbortPolicy：直接抛出异常。（默认策略） CallerRunsPolicy：只用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务 DiscardPolicy：不处理，丢弃。 Executors工具类，提供工厂方法创建不同类型的线程池。 四种常用线程池 newFixedThreadPool(int Threads)：创建固定数目线程的线程池 newCachedThreadPool()：创建一个可缓存的线程池，调用execute 将重用以前构造的线程（如果线程可用）。如果没有可用的线程，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。 newSingleThreadExecutor()：创建一个单线程化的Executor。 newScheduledThreadPool(int corePoolSize)：建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。 问题一般不建议使用Executors创建。使用Executors创建线程池可能会导致OOM(OutOfMemory ,内存溢出) 正确创建线程池直接调用ThreadPoolExecutor的构造函数来自己创建线程池 123ExecutorService executor = new ThreadPoolExecutor(10, 10, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue(10)); 使用Guava的ThreadFactoryBuilder创建，不仅可以避免OOM的问题，还可以自定义线程名称，更加方便的出错的时候溯源。 123456789101112131415public class ExecutorsDemo &#123; private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat("demo-pool-%d").build(); private static ExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); public static void main(String[] args) &#123; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; pool.execute(new SubThread()); &#125; &#125;&#125; 总结线程创建时机 当前线程数少于corePoolSize，提交任务时新建一个新线程，有该线程执行这个任务 如果当前线程数已经达到corePoolSize，将提交的任务添加到队列中，等待线程池中的线程取队列中取任务。 如果队列已满，就创建新的线程执行任务，需要保证线程池中的线程数不超过maximumPoolSize，如果超过，执行拒绝策略。 参考 Javadoop - 深度解读 java 线程池设计思想及源码实现 掘金 - 深入理解 Java 线程池：ThreadPoolExecutor 掘金 - 重走JAVA之路（五）：面试又被问线程池原理？教你如何反击 Java中线程池，你真的会用吗？ 方腾飞等. Java并发编程的艺术. 机械工业出版社, 2015.]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap源码分析]]></title>
    <url>%2F2019%2F04%2F10%2FConcurrentHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap是HashMap的线程安全版，基于JDK1.8分析其源码。 概述 经典的开源框架Spring的底层数据结构就是使用ConcurrentHashMap实现的。 hash冲突的处理方式也与HashMap类似，冲突的记录被存储到同一位置。 JDK8中实现线程安全是使用CAS算法，而不是以前的Segment概念。 key和value都不允许为空。 初始化1234567891011121314/** * Creates a new, empty map with the default initial table size (16). */public ConcurrentHashMap() &#123;&#125;public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125; 通过提供初始容量，计算了 sizeCtl，sizeCtl = 【 (1.5 * initialCapacity + 1)，然后向上取最近的 2 的 n 次方】 12345678910111213141516171819202122232425private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // cas 将sizeCtl设置为-1，代表抢到了锁 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; // 默认初始容量为16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; // 数组赋值给table table是volatile的 table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; sizeCtl123456789/** * Table initialization and resizing control. When negative, the * table is being initialized or resized: -1 for initialization, * else -(1 + the number of active resizing threads). Otherwise, * when table is null, holds the initial table size to use upon * creation, or 0 for default. After initialization, holds the * next element count value upon which to resize the table. */private transient volatile int sizeCtl; 控制标识符，不同的值有不同的属性。 负数代表正在初始化或正在扩容 -1代表正在初始化 -N标识有N-1个线程正在进行扩容操作 正数或0表示hash表还没被初始化，数值表示初始化或下一次扩容的大小。类似于HashMap中loadfactor的概念。它的值始终是当前ConcurrentHashMap容量的0.75倍，这与loadfactor是对应的。 它是多线程共享的。 Node12345678910111213141516171819202122232425262728293031323334353637383940414243444546static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + "=" + val; &#125; public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; /** * Virtualized support for map.get(); overridden in subclasses. */ Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null; &#125;&#125; 这里的Node和HashMap中实现类似，但有不同， 它对val和next设置了volatile同步锁 不允许调用setValue方法直接改变属性值 增加了find方法辅助map.get()方法 Unsafe与CAS大量使用U.compareAndSwap方法，利用CAS算法实现无锁修改值。基本思想是不断的比较当前内存中的变量值与你指定的变量值是否相等，相等则接受，否则拒绝，因此当前线程中的值并不是最新值，修改可能覆盖其他线程的修改结果。类似乐观锁，SVN的思想。 三个核心方法12345678910111213// 获得i位置上的节点static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125;// 使用cas算法设置i节点的值，实现并发是因为指定i节点原来的值static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;// 使用volatile方法设置节点的值static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; put方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 计算hash int hash = spread(key.hashCode()); // 相应链表长度 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // table为空，初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 根据hash计算节点的index else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 用一次CAS操作技能新值放入其中，put操作结束 // 如果cas失败，说明有并发操作，进入下一个循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 遇到表连接点，帮助进行整合表 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; // f是该位置的头节点且不为空 V oldVal = null; // 对table的index位置加锁，只锁住当前index位置 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 说明是链表节点 if (fh &gt;= 0) &#123; // 记录链表长度 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // hash与key相同，执行覆盖操作 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; // 遍历到了最后一个节点，新建节点插到最后 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 红黑树节点 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 链表长度大于8，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) // 不一定会进行红黑树转换，如果当前数组长度小于64， // 选择进行数组扩容，而不是转换红黑树 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 当key或value为null 的时候，抛出异常，因此ConcurrentHashMap的key与value都不能为空。 流程：计算key的hashCode，然后计算table的index（(n-1) &amp; hash），如果index位置为null，使用casTabAt方法插入，否则使用synchronized关键字对index位置加锁，仅仅锁住index位置因此其他线程可以安全地获取其他位置，提高了并发。然后判断index位置上第一个节点的hashCode值，小于0为红黑树根节点。如果是链表节点，遍历，当hash与key相同时，修改节点值，否则添加新节点。是红黑树节点的情况暂不分析。 get123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 计算hash int h = spread(key.hashCode()); // hash对应index位置不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; // 链表头节点的key与传入的key相同且不为null，返回该节点的值 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 节点在树上 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表查找节点 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 计算hash 根据hash得到index ：hash &amp; (len - 1) 根据该位置的节点性质查找 null，返回null 该位置节点恰好就是，返回该节点的值 该位置节点hash &lt; 0 ，正在扩容，或者是红黑树 链表，遍历查找 1.7中的ConcurrentHashMap1.7中主要使用Segment实现线程安全。 整个ConcurrentHashMap有一个个Segment组成，即ConcurrentHashMap是一个Segment数组，Segment通过集成ReentrantLock进行加锁，每次锁住一个segment。 Segment数组不能扩容，扩容是Segment数组某个位置内部数组HashEntry进行扩容。 参考 CSDN-ConcurrentHashMap源码分析（JDK8版本） 掘金-Java 8 ConcurrentHashMap源码分析 Javadoop - Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用aiohttp进行异步爬虫]]></title>
    <url>%2F2019%2F04%2F04%2F%E4%BD%BF%E7%94%A8aiohttp%E8%BF%9B%E8%A1%8C%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[不久前出于兴趣需要爬取一个网站的图片，保存到本地。这里记录下使用aiohttp的过程。 使用成熟的框架Scrapy爬虫时，其对于图片处理的不是很好，对于GIF也没有太大的支持。查找资料后发现了aiohttp这个框架。 单独使用aiohttp使用BeautifulSoup解析HTML页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748async def process_html(page_url): """解析文章页面，填充item""" async with aiohttp.ClientSession() as session: async with session.get(page_url) as response: cont = await response.read() soup = bs(cont, 'lxml') item['title'] = soup.find('h1').string item['page_url'] = page_url item['time'] = item['page_url'].split('/')[0] content = soup.find('div', class_ = 'main') data_src_temp = content.find_all( 'img', attrs = &#123;'type': 'image'&#125;) # 得到图片链接 for link in data_src_temp: src_temp = link.get('image') item['images_url'].append(src_temp) time_path = os.path.join('imagepath', item['time']) page_path = set_down_path(time_path, item['title']) # print(item['images_url']) for idx, image_url in enumerate(item['images_url']): await down_one(image_url, page_path, idx) async def down_one(img_url, page_path_temp, idx): """得到content后保存到本地""" # 图片后缀 suffix = img_url.split('.')[-1] # 组装单个图片路径 image_name = page_path_temp + "/" + str(idx) + '.' + suffix if os.path.exists(image_name): return # 得到图片内容 async with aiohttp.ClientSession() as session: async with session.get(img_url) as response: content = await response.read() with open(image_name, 'wb') as file: file.write(content) def run(): print("start") t1 = time.time() loop = asyncio.get_event_loop() tasks = [process_html(url) for url in page_urls] loop.run_until_complete(asyncio.wait(tasks)) loop.close() t2 = time.time() print('总共耗时：%s' % (t2 - t1)) aiohttp+Scrapyaiohttp是requests的异步替代版。 下面是结合Scrapy的代码，由Scrapy处理得到每页中每张图片的地址，在pipelines.py中使用aiohttp+asyncio下载图片。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class SaveImagePipeline(object): def set_down_path(self, time_path, title): """ 设置图片的文件夹路径 """ try: if not os.path.exists(time_path): os.mkdir(time_path) page_path = os.path.join(time_path, title) if not os.path.exists(page_path): os.mkdir(page_path) except IOError as e: logging.error(e) return '' return page_path async def down_one(self, img_url, page_path, idx): """得到content后保存到本地""" # 图片后缀 suffix = img_url.split('.')[-1] # 组装单个图片路径 image_name = page_path + "/" + str(idx) + '.' + suffix if os.path.exists(image_name): return # 得到图片内容 async with aiohttp.ClientSession() as session: try: async with session.get(img_url, verify_ssl = False) as response: if response.status == 404: return content = await response.read() with open(image_name, 'wb') as file: file.write(content) except aiohttp.client_exceptions.ClientConnectionError: return tasks = '' def process_item(self, item, spider): post_time = item['time'] title = item['title'] time_path = os.path.join(settings['SAVE_IMAGE_PATH'], post_time) page_path = self.set_down_path(time_path, title) loop = asyncio.get_event_loop() self.tasks = [self.down_one(url, page_path, idx) for idx, url in enumerate(item['images_url'])] loop.run_until_complete(asyncio.wait(self.tasks)) 如果图片更多，保存图片的操作就成了性能限制，可以尝试使用 aiofiles 进行图片保存 参考Welcome to AIOHTTP 掘金-python使用异步每秒钟就能下载一张高清大图，快不快？]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码解析]]></title>
    <url>%2F2019%2F04%2F04%2FHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[基于JDK1.8分析HashMap的底层实现。 概述HashMap线程不安全，允许key为null，value为null，遍历无序。 其底层实现有三种数据结构：数组，链表，红黑树。在JDK8中，一个桶存储的链表结构大于8时会转化为红黑树，在红黑树中查找时间复杂度为O(logn)。 数组用来存储键值对，每一个键值对别成为Entry，这是HashMap的主干。其中的米一个元素初始值都为null。 链表节点NodeJava8中使用Node替代7中的Entry，适用于链表。 12345678910111213141516171819202122232425262728293031323334353637383940static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; // 每一个节点的hashCode由key的hashcode和value的hashCode得到 return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; // 重写equals public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 链表中的每一个节点的hashCode由key的hashcode和value的hashCode得到。 构造函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 默认capacity，table的容量大小，默认16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认装载因子，table能够使用的比例static final float DEFAULT_LOAD_FACTOR = 0.75f;// size 的临界值，当 size 大于等于 threshold 就必须进行扩容操作。int threshold;// 哈希桶transient Node&lt;K,V&gt;[] table;// 默认构造函数，指定loadFactor为默认0.75fpublic HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125;// 指定初始容量的构造函数public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;// 指定初始容量和装载因子的构造函数public HashMap(int initialCapacity, float loadFactor) &#123; // 边界处理 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); // 初始容量不能大于2的30次方 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 装载因子的边界处理 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 新建hash表public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 指定加载因子为默认0.75f this.loadFactor = DEFAULT_LOAD_FACTOR; // putMapEntries(m, false);&#125; 重要参数： capacity：table 容量大小，默认为16，且必须为2的n次方 size：键值对数量 threshold（阈值）：size临界值，size大于等于threshold时需要进行扩容 loadfactor：装载因子，threshold = capacity * loadfactor 增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。 由于在计算中位运算比取模运算效率高的多，所以 HashMap 规定数组的长度为 2^n 。这样用 2^n - 1 做位运算与取模效果一致，并且效率还要高出许多。 tableSizeFor，计算数组容量1234567891011121314151617/** * Returns a power of two size for the given target capacity. 根据期望容量，返回2的n次方实，数组实际容量 length */static final int tableSizeFor(int cap) &#123; //经过下面的 或 和位移 运算， n最终各位都是1。 int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; // 判断n是否越界，小于0赋值1，大于最大容量设为最大容量 // 返回 2的n次方作为 table（哈希桶）的阈值 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; putMapEntries()将另一个Map的所有元素加入表中，参数evict初始化时为false，其他情况为true 12345678910111213141516171819final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; put操作put()往哈希表里插入一个节点的putVal函数,如果参数onlyIfAbsent是true，那么不会覆盖相同key的值value。如果evict是false。那么表示是在初始化时调用的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;// onlyIfAbsent为true时，只有不存在key是进行put操作final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // tab当前hash桶，p临时链表节点 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 第一次放入值，table为空，执行初始化resize() if ((tab = table) == null || (n = tab.length) == 0) // 扩容hash表，并将长度赋给n n = (tab = resize()).length; // 当前节index节点为空，没有hash冲突，直接构建新节点，挂载在index处 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; // 发生了hash冲突 Node&lt;K,V&gt; e; K k; // 如果该index处的第一个数据与插入数据hash相同，key也相等，当前节点赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // p节点是红黑树的节点，调用红黑树的插入 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 不是覆盖操作 // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 遍历到尾部，添加新节点（Java 7是插入到链表前面） p.next = newNode(hash, key, value, null); // 添加新节点后链表长度大于8，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 找到了要覆盖的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // e不为空，存在旧值的key与要插入的key相等 执行覆盖，返回旧值 if (e != null) &#123; // existing mapping for key // 覆盖节点，返回oldva V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; // 以上完成插入新节点的操作 ++modCount; // 判断size是否大于临界值，执行resize操作 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 桶下标 index=(n - 1) &amp; hash HashMap不是在new时申请空间，而是在第一次put时申请空间。没有发生hash冲突，直接构建新节点挂在到index处。 概述：执行put操作时，如果是第一次put，执行resize() 方法；根据key计算hash，hash &amp; (n - 1) 得到在数组中的index位置，如果index位置为空，创建Node节点，挂载在index位置处；index不为空，发生了hash冲突，此时判断index处的第一个节点的key与hash与放入的key与hash是否相等，相等执行覆盖。如果第一个节点是红黑树节点，调用红黑树插入方法，否则是链表节点。遍历链表节点，将要存的节点插入到链表最后，如果存在相等的key，执行覆盖。插入完成后，判断size是否大于临界值，大于则执行resize(); 在JDK8中，插入链表是插在链表最后，即尾插入，而JDK7中是头插入。头插入的一个缺点是在并发情况下插入扩容可能出现链表环发生死循环。 hash()1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; HashMap允许key为null，key为null，hash为0，下标为0 根据key取hash值，扰动函数，使hash均衡，减少hash碰撞的几率。它会综合hash值高位和低位的特征，并存放在低位，因此在与运算时，相当于高低位一起参与了运算，以减少hash碰撞的概率。 JDK8中简化操作。 resize() 重点初始化或加倍哈希桶大小。如果是当前哈希桶是null,分配符合当前阈值的初始容量目标。否则，扩容成以前的两倍。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105final Node&lt;K,V&gt;[] resize() &#123; // 当前表的哈希桶 Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 当前桶容量大于0 if (oldCap &gt; 0) &#123; // 大于最大容量 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 将临界值设为最大 threshold = Integer.MAX_VALUE; // 返回当前哈希桶，不再扩容 return oldTab; &#125; // 如过当前容量的两倍小于最大容量并且当前容量大于默认容量 // 新容量为当前容量的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 新的临界值也为当前的两倍 newThr = oldThr &lt;&lt; 1; &#125; // //如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 容量为0，代表第一次执行put操作，需要初始化 // 容量和临界值都初始化为默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //如果新的阈值是0，对应的是 当前表是空的，但是有阈值的情况 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; //进行越界修复 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 当前哈希桶不为空 if (oldTab != null) &#123; // 遍历 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; // 当前节点有元素，值赋给e if ((e = oldTab[j]) != null) &#123; // 置空，便于GC oldTab[j] = null; //当前链表就一个元素，没有发生hash冲突 if (e.next == null) // 直接将元素放在新的桶里 // 这里去下标 当前节点的hash 与 桶的长度减一 // 桶的长度是2的n次方，这样就是取模 newTab[e.hash &amp; (newCap - 1)] = e; // 发生过hash碰撞且节点是红黑树节点 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 没有放生哈希碰撞，节点小于8，依次放入新的哈希桶对应位置 else &#123; // preserve order //因为扩容是容量翻倍，所以原链表上的每个节点，现在可能存放在原来的下标，即low位， // 或者扩容后的下标，即high位。 high位= low位+原哈希桶容量 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //这里又是一个利用位运算 代替常规运算的高效点： // 利用哈希值 与 旧的容量，可以得到哈希值去模后，是大于等于oldCap还是小于oldCap， // 等于0代表小于oldCap，应该存放在低位，否则存放在高位 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 高位相同的逻辑 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 低位链表存在源index处 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 高位存在新index if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; HashMap中用到了许多位运算，更高效 扩容时，将旧的数组中引用置null，便于GC 取下标 是用 哈希值 与运算 （桶的长度-1） i = (n - 1) &amp; hash。 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。但是效率更高 因为扩容是容量翻倍，所以原链表上的每个节点，现在可能存放在原来的下标，即low位， 或者扩容后的下标，即high位。 high位= low位+原哈希桶容量 resize是很费时间的操作，因此最好在HashMap初始化时指定大小，尽量减少调用resize方法。 get操作get()12345678910111213141516171819202122232425262728293031public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;// 传入扰动后的hash 和 key查找final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 哈希表不为空，根据hash计算下标，该下标有节点的话 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 如果链表头结点就是要查找的节点，直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 链表头结点的下一个节点不为空 if ((e = first.next) != null) &#123; // 是红黑树树节点，使用红黑树的查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 是链表，遍历链表 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; // 没有找到，返回null return null;&#125; 计算key 的hash，根据hash计算index，hash &amp; (len - 1) 判断数组该位置第一个原始是否恰好为要找的 判断第一个节点元素类型是否为TreeNode，是用红黑树方法取数据，不是继续 便利链表，找到相等的key 以上在O(1)的时间里查找执行完 7与8的一些不同 7是数组+链表的结构；8是数组+链表+红黑树，链表长度大于8转化为红黑树 插入时7是头插法；8是尾插法。一种原因是防止形成链表环 7是先计算size后插入；8是先插入后计算 参考 CS-Notes-HashMap 掘金-面试必备：HashMap源码解析（JDK8） Javadoop - Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析 掘金 - HashMap为何从头插入改为尾插入]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL基本语句总结]]></title>
    <url>%2F2019%2F04%2F03%2FMySQL%E5%9F%BA%E6%9C%AC%E8%AF%AD%E5%8F%A5%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[学习《MySQL必知必会》，整理基本语句 查询普通查询DISTINCT 返回唯一的结果12SELECT DISTINCT id FROM products LIMIT 限制查询结果123SELECT id FROM productsLIMIT 5; 1LIMIT 5,5 从5行开始的第五行。（检索的第一行为0为而不是1） 排序查询ORDER BY默认按照升序排序。 123SELECT id FROM productsORDER BY age, name; 首先按照age，在按照name，仅age 有多个相同的时候。 排序方向1ORDER BY age DESC, name 按照age降序排序。name 升序排序。 过滤数据WHERE123SELECT id FROM productsWHERE id = 3; BETWEEN1WHERE price BETWEEN 5 AND 10; 检索5-10之间。 AND1WHERE price age &lt; 10 AND price &gt; 5; OR1WHERE price age &lt; 10 OR price &gt; 5; 计算次序WHERE可包含任意数目的AND和OR操作符。允许两者结合以进行复杂 和高级的过滤。 SQL（像多数语言一样）在处理OR操作符前，优先处理AND操 作符。AND在计算次序中优先级更高 1WHERE (id = 1001 OR id = 1003) AND price &gt; 10; 因为圆括号具有较AND或OR操作符高 的计算次序，DBMS首先过滤圆括号内的OR条件。 任何时候使用具有AND和OR操作 符的WHERE子句，都应该使用圆括号明确地分组操作符。 ININ WHERE子句中用来指定要匹配值的清单的关键字，功能与OR 相当。 IN操作符用来指定条件范 围，范围中的每个条件都可以进行匹配。1WHERE id IN (1002, 1004); IN操作符一般比OR操作符清单执行更快。 使用别名1SELECT vend_name, '(',vend_country, ')' AS vend_title 函数聚集函数 AVG() COUNT MAX MIN() SUM() 1SELECT AVG(age) AS avg_price 分组GROUP BY123SELECT id, COUNT(*) AS num_prodsFROM productsGROUP BY id; 将分别计算每个id的数量。 HAVING大部分类型的WHERE子句都可以用HAVING来替代。唯一的差别是 WHERE过滤行，而HAVING过滤分组。HAVING支持所有WHERE操作符1234SELECT id, COUNT(*) AS ordersFROM ordersGROUP BY idHAVING COUNT(*) &gt;= 2; HAVING子句，它过滤COUNT(*) &gt;=2（两个以上的订单）的那些分组。 有另一种理解方法，WHERE在数据 分组前进行过滤，HAVING在数据分组后进行过滤。这是一个重 要的区别，WHERE排除的行不包括在分组中 12345SELECT id, COUNT(*) AS ordersFROM ordersWHERE price &gt;= 10GROUP BY idHAVING COUNT(*) &gt;= 2; 第一行是使用了聚集函数的基本SELECT，它与前 面的例子很相像。WHERE子句过滤所有prod_price至少为10的 行。然后按vend_id分组数据，HAVING子句过滤计数为2或2以上的分组。 分组和排序一般在使用GROUP BY子句时，应该也给 出ORDER BY子句。这是保证数据正确排序的唯一方法。 12345SELECT order_num, SUM(quantity*item_price) AS ordertotalFROM orderitemsGROUP BY order_numHAVING SUM(quantity*item_price) &gt;= 50ORDER BY ordertotal GROUP BY子句用来按订单号（order_num列） 分组数据，以便SUM(*)函数能够返回总计订单价格。HAVING子 句过滤数据，使得只返回总计订单价格大于等于50的订单。后，用ORDER BY子句排序输出。 子查询123SELECT order_numFROM orderitemsWHERE prod_id = 'TNT2' 123SELECT cust_idFROM ordersWHERE order_num IN (20005, 20007) 1234567SELECT cust_idFROM ordersWHERE order_num IN ( SELECT order_num FROM orderitems WHERE prod_id = 'TNT2') 首先执行括号中的查询 联结外键（foreign key） 外键为某个表中的一列，它包含另一个表 的主键值，定义了两个表之间的关系 创建联结1234SELECT vent_name, prod_name, prod_priceFROM vendors, productsWHERE vendors.vend_id = products.vend_idORDER BY vend_name, prod_name WHERE子句 指示MySQL匹配vendors表中的vend_id和products表中的vend_id。 内部联结(INNER JOIN ON)123SELECT vend_name, prod_name, prod_priceFROM vendors INNER JOIN productsON vendors.vend_id = products.vend_id 与前面语句相同。两个表之间的关系是FROM子句的组成部分，以INNER JOIN指定。联结条件用特定的ON子句而不是WHERE 子句给出。传递给ON的实际条件与传递给WHERE的相同。 首选 INNER JOIN 高级联结使用表别名12SELECT cust_name, cust_ageFROM customers AS c, orders AS o, ordertimes AS oi 建立c作为customers 的别名 自联结1234SELECT p1.prod_id, p1.prod_nameFROM products AS p1, products AS p2WHERE p1.vend_id = p2.vend_idAND p2.prod_id = 'DTNTR'; products是同一张表，第一次出现使用p1，第二次出现使用p2 使用自联结替代子查询 自然联结外部联结(LEFT OUTER JOIN)123SELECT customers.cust_id, orders.order_numFROM customers LEFT OUTER JOIN ordersON customers.cust_id = orders.cust_id; 使用LEFT OUTER JOIN从FROM 子句的左边表（customers表）中选择所有行。 联结详解内连接 INNER JOIN ON 左连接 LEFT JOIN ON / LEFT OUTER JOIN ON左边的表选择所有行，右边只显示符合搜索条件的记录 右连接 RIGHT JOIN ON / RIGHT OUTRE JOIN ON 组合查询可用UNION操作符来组合数条SQL查询。利用UNION，可给出多条SELECT语句，将它们的结果组合成单个结果集。 UNION1234567SELECT vend_id, prod_id, prod_priceFROM productsWHERE prod_price &lt;=5UNIONSELECT vend_id, prod_id, prod_priceFROM productsWHERE vend_id IN (1001, 1002) 等价于 123SELECT vend_id, prod_id, prod_priceFROM productsWHERE prod_price &lt;=5 OR vend_id IN (1001, 1002) 注意： UNION中的每个查询必须包含相同的列、表达式或聚集函数 UNION必须由两条或两条以上的SELECT语句组成，语句之间用关 键字UNION分隔（因此，如果组合4条SELECT语句，将要使用3个 UNION关键字） UNION ALLUNION默认去除重复的行，使用UNION ALL 避免。 排序SELECT语句的输出用ORDER BY子句排序。在用UNION组合查询时，只 能使用一条ORDER BY子句，它必须出现在最后一条SELECT语句之后。对 于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一 部分的情况，因此不允许使用多条ORDER BY子句。 增改删插入数据1234567INSERT INTO customers(cust_name, cust_id)VALUES('name', 'id'), ('name_2', 'id_2'); 更新数据123UPDATE customersSET cust_email = 'mail'WHERE cust_id = 1001; 注意不要忘了where 删除数据12DELETE FROM customersWHERE cust_di = 1002; 表操作创建表12345CREATE TABLE customers( cust_id int NOT NULL AUTO_INCREMENT, cust_name char(50)NOT NULL, PRIVARY KEY (cust_id))ENGINE=InnoDB; 参考《MySQL必知必会》 CSDN-图解MySQL 内连接、外连接、左连接、右连接、全连接……太多了]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-三]]></title>
    <url>%2F2019%2F03%2F28%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[线程状态转换和线程同步，volatile和synchronized 线程状态的转换 状态 新建状态（New）：新创建了一个线程对象 就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的 start() 方法，该状态的线程位于可运行的线程池中，变为可运行状态，这个时候，只要获取了 cpu 的执行权，就可以运行，进入运行状态。 运行状态（Running）： 就绪状态的线程从 cpu 获得了执行权之后，便可进入此状态，执行 run() 方法里面的代码。 阻塞状态（Blocked）：阻塞状态是线程因为某种原因失去了 cpu 的使用权，暂时停止运行，一直等到线程进入就绪状态，才有机会转到运行状态，阻塞一般分为下面三种： 等待阻塞 ：运行的线程执行了 wait() 方法， JVM 会把该线程放入线程等待池中，（wait() 会释放持有的锁 ） 同步阻塞：运行的线程在获取对象的同步锁时，如果该同步锁被其他线程占用，这时此线程是无法运行的，那么 JVM 就会把该线程放入锁池中，导致阻塞 其他阻塞：运行的线程执行 sleep() 或者 join() 方法，或者发出了 I/O 请求，JVM 会把该线程置为阻塞状态，当 sleep() 状态超时、join() 等待线程终止或者超时、或者 I/O 处理完毕时，线程会重新进入就绪状态，（注意：sleep() 是不会释放本身持有的锁的） 无限期等待：等待其他线程显式地唤醒，否则不分配CPU时间片 死亡状态（Dead）：线程执行完了之后或者因为程序异常退出了 run() 方法，结束该线程的生命周期 线程同步继承Thread类的线程同步错误实现12345678910111213141516171819202122232425262728293031public class Main3 &#123; public static void main(String[] args) &#123; Ticket3 ticket1 = new Ticket3(); Ticket3 ticket2 = new Ticket3(); Ticket3 ticket3 = new Ticket3(); ticket2.start(); ticket1.start(); ticket3.start(); &#125;&#125;class Ticket3 extends Thread &#123; private int ticket = 5; @Override public void run() &#123; while (ticket &gt; 0) &#123; synchronized (this) &#123; if (ticket &gt; 0) &#123; System.out.println(currentThread().getName() + "运行，此时的剩余票数" + this.ticket--); &#125; &#125; try &#123; sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 继承Thread类的线程同步正确实现12345678910111213141516171819202122232425262728public class Main4 &#123; public static void main(String[] args) &#123; Ticket4 ticket4 = new Ticket4(); new Thread(ticket4).start(); new Thread(ticket4).start(); new Thread(ticket4).start(); &#125;&#125;class Ticket4 extends Thread&#123; private int ticket = 6; @Override public void run() &#123; while (ticket &gt; 0)&#123; synchronized (this)&#123; System.out.println(currentThread().getName() + "运行，此时的剩余票数为" + -- this.ticket); &#125; try &#123; sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 使用Runnable接口实现1234567891011121314151617181920212223242526272829class Thread2 implements Runnable &#123; private int ticket = 6; @Override public void run() &#123; while (ticket &gt; 0) &#123; synchronized (this) &#123; System.out.println(currentThread().getName() + "运行，此时的剩余票数" + --this.ticket); &#125; try &#123; sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Main2 &#123; public static void main(String[] args) &#123; Thread2 thread2 = new Thread2(); new Thread(thread2).start(); new Thread(thread2).start(); new Thread(thread2).start(); &#125;&#125; volatile和synchronized关键字首先需要理解线程安全的两个方面：执行控制和内存可见。 执行控制的目的是控制代码执行（顺序）及是否可以并发执行。 内存可见控制的是线程执行结果在内存中对其它线程的可见性。根据Java内存模型的实现，线程在具体执行时，会先拷贝主存数据到线程本地（CPU缓存），操作完成后再把结果从线程本地刷到主存。 volatilevolatile关键字解决的是内存可见性的问题，会使得所有对volatile变量的读写都会直接刷到主存，即保证了变量的可见性。这样就能满足一些对变量可见性有要求而对读取顺序没有要求的需求。 使用volatile关键字仅能实现对原始变量(如boolen、 short 、int 、long等)操作的原子性，但需要特别注意， volatile不能保证复合操作的原子性，即使只是i++，实际上也是由多个原子操作组成：read i; inc; write i，假如多个线程同时执行i++，volatile只能保证他们操作的i是同一块内存，但依然可能出现写入脏数据的情况。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 volatile自身变量具有特性： 可见性。对一个volatile变量的读，总是能看到任意线程对这个volatile变量最后的写入。 原子性。对任意单个volatile变量的读/写具有原子性，但i++不具有。 synchronizedsynchronized关键字解决的是执行控制的问题，它会阻止其它线程获取当前对象的监控锁，这样就使得当前对象中被synchronized关键字保护的代码块无法被其它线程访问，也就无法并发执行。 更重要的是，synchronized还会创建一个内存屏障，内存屏障指令保证了所有CPU操作结果都会直接刷到主存中，从而保证了操作的内存可见性，同时也使得先获得这个锁的线程的所有操作，都happens-before于随后获得这个锁的线程的操作。 synchronized可以修饰代码块，方法，类，静态方法 修饰代码块作用于同一个对象 12345public void func() &#123; synchronized (this) &#123; // ... &#125;&#125; 修饰方法作用于同一个对象 123public synchronized void func () &#123; // ...&#125; 修饰类12345678910public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125; 两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 静态方法123public synchronized static void fun() &#123; // ...&#125; 两者比较 volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读。synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 volatile仅能够修饰变量，synchronized可以修饰变量，方法，类级别 volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化 对于工作内存与主内存同步延迟现象导致的可见性问题，可以使用synchronized关键字或者volatile关键字解决，它们都可以使一个线程修改后的变量立即对其他线程可见。对于指令重排导致的可见性问题和有序性问题，则可以利用volatile关键字解决，因为volatile的另外一个作用就是禁止重排序优化。 参考 《Java并发编程的艺术》 CSDN - 全面理解Java内存模型(JMM)及volatile关键字]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-二]]></title>
    <url>%2F2019%2F03%2F28%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[Java内存模型 Java内存模型线程安全问题。《深入理解Java虚拟机》定义，当多个线程访问同一个对象，如果不考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确结果，藏鞥对象是线程安全的。 出现线程安全的原因一般是 主内存和工作内存数据不一致和重排序导致。 Java内存模型 并发编程两个关键问题：线程之间如何通信，线程之间如何同步。 两种通信机制：共享内存，消息传递 共享内存：线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信，典型的共享内存通信方式就是通过共享对象进行通信。 消息传递：线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信，在java中典型的消息传递方式就是wait()和notify()。 Java并发采用共享内存。 Java线程之间的通信有Java内存模型（JMM）控制，他决定了一个线程的共享变量的写入何时对另一个线程可见。 从抽象角度：JMM定义了线程和主内存之间的抽象关系，线程之间的共享变量存储在主内存中，每个线程都有一个私有本地内存，本地内存中存储了该线程共享变量的副本。本地内存并不真实存在。 两个线程，A和B通信，经历步骤： 线程A将本地内存A中更新过的共享变量刷新到主内存中 线程B到主内存中读取A更新过得变量。 内存模型三大特性三大特性：原子性，可见性，有序性 原子性即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？ 1`i = ``9``;` 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。 那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 可见性可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 主要有三种实现可见性的方式： volatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 有序性有序性指，在本线程内观察，所有操作都是有序的，在一个线程观察另一个线程，所有操作都是无序的。无序是因为发生了指令重排序。在Java内存模型，允许编译器和处理器对指令进行重排序，重排序不会影响单线程程序的执行，会影响到多线程并发执行的正确性。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。 重排序为提高性能，编译器处理器对指令进行重排序，分为三种： 编译器优化 指令级并行 内存系统 针对编译器重排序，JMM的编译器重排序规则会禁止一些特定类型的编译器重排序；针对处理器重排序，编译器在生成指令序列的时候会通过插入内存屏障指令来禁止某些特殊的处理器重排序。 编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序 参考 全面理解Java内存模型(JMM)及volatile关键字 全面理解Java内存模型 Java-并发-Java内存模型 Java内存模型和JVM内存管理 掘金-Java内存模型以及happens-before规则]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令]]></title>
    <url>%2F2019%2F03%2F28%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[整理一些常用的git命令 本地push到远程初始化本地 1git init 本地关联远程 1git remote add origin git@gitres 添加和提交 12git add .git commit -m "注释" push 远程 1234第一次推送master分支时，加上-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，git push -u origin mastergit push origin master 文件操作添加文件目录1234# 添加当前目录所有文件到暂存区git add .git add [file1] [file2]...git add [dir] 撤销add1git rm --cached &lt;file&gt;]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-一]]></title>
    <url>%2F2019%2F03%2F27%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Java创建线程，线程常用函数 创建线程三种方式：继承Thread类重写run方法，实现Runnable接口，实现callable接口。 继承Thread类重写run方法123456789101112131415161718192021222324252627282930class Thread1 extends Thread &#123; private String name; private int ticket = 20; private Random rand = ThreadLocalRandom.current(); public Thread1(String name) &#123; this.name = name; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(name + "运行：" + i); &#125; try &#123; sleep(rand.nextInt(100)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class Demo extends Thread &#123; public static void main(String[] args) &#123; Thread1 thread1 = new Thread1("A"); Thread1 thread2 = new Thread1("B"); thread1.start(); thread2.start(); &#125;&#125; 实现Runnable接口1234567891011121314151617181920212223242526272829class DemoByRun implements Runnable &#123; private String name; public DemoByRun(String name) &#123; this.name = name; &#125; private Random random = ThreadLocalRandom.current(); @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(name + "运行：" + i); &#125; try &#123; Thread.sleep(random.nextInt(50)); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;&#125;public class Main&#123; public static void main(String[] args) &#123; new Thread(new DemoByRun("A")).start(); new Thread(new DemoByRun("B")).start(); &#125;&#125; 实现callable接口123456789101112131415public class Main5 &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; DemoByCallable call = new DemoByCallable(); FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(call); new Thread(futureTask).start(); System.out.println(futureTask.get()); &#125;&#125;class DemoByCallable implements Callable&lt;String&gt; &#123; @Override public String call() &#123; return "hello"; &#125;&#125; 比较实现Runnable接口比继承Thread类所具有的优势： 1）：适合多个相同的程序代码的线程去处理同一个资源 2）：可以避免java中的单继承的限制 3）：增加程序的健壮性，代码可以被多个线程共享，代码和数据独立 4）：线程池只能放入实现Runable或callable类线程，不能直接放入继承Thread的类 两者都有的： 适合多个相同的程序代码的线程去处理同一个资源增加程序的健壮性，代码可以被多个线程共享，代码和数据独立 线程常用函数start与run区别start()是启动一个新线程。通过start()方法来启动的新线程，处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行相应线程的run()方法， start() 可以启动一个新线程，run()不能 start()不能被重复调用，run()可以 start()中的run代码可以不执行完就继续执行下面的代码，即进行了线程切换。直接调用run方法必须等待其代码全部执行完才能继续执行下面的代码。 start() 实现了多线程，run()没有实现多线程。 setPriority(): 更改线程的优先级。 MIN_PRIORITY = 1NORM_PRIORITY = 5MAX_PRIORITY = 10 Join()为什么要用join()方法在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。1234567891011121314151617181920public class Main &#123; public static void main(String[] args) &#123; System.out.println(Thread.currentThread().getName()+"主线程运行开始!"); Thread1 mTh1=new Thread1("A"); Thread1 mTh2=new Thread1("B"); mTh1.start(); mTh2.start(); try &#123; mTh1.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; mTh2.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+ "主线程运行结束!"); &#125;&#125; yield():暂停当前正在执行的线程对象，并执行其他线程。 yield()应该做的是让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。结论：yield()从未导致线程转到等待/睡眠/阻塞状态。在大多数情况下，yield()将导致线程从运行状态转到可运行状态，但有可能没有效果。 sleep()和yield()的区别 sleep()和yield()的区别):sleep()使当前线程进入停滞状态，所以执行sleep()的线程在指定的时间内肯定不会被执行；yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。 sleep 方法使当前运行中的线程睡眼一段时间，进入不可运行状态，这段时间的长短是由程序设定的，yield 方法使当前线程让出 CPU 占有权，但让出的时间是不可设定的。实际上，yield()方法对应了如下操作：先检测当前是否有相同优先级的线程处于同可运行状态，如有，则把 CPU 的占有权交给此线程，否则，继续运行原来的线程。所以yield()方法称为“退让”，它把运行机会让给了同等优先级的其他线程 另外，sleep 方法允许较低优先级的线程获得运行机会，但 yield() 方法执行时，当前线程仍处在可运行状态，所以，不可能让出较低优先级的线程些时获得 CPU 占有权。在一个运行系统中，如果较高优先级的线程没有调用 sleep 方法，又没有受到 I\O 阻塞，那么，较低优先级线程只能等待所有较高优先级的线程运行结束，才有机会运行。 wait()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MyThreadPrint extends Thread &#123; private String name; private final Object prev; private final Object self; private MyThreadPrint(String name, Object prev, Object self) &#123; this.name = name; this.prev = prev; this.self = self; &#125; @Override public void run() &#123; int count = 10; while (count &gt; 0) &#123; synchronized (prev) &#123; synchronized (self) &#123; System.out.println(name); count--; self.notify(); &#125; try &#123; prev.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Object A = new Object(); Object B = new Object(); Object C = new Object(); MyThreadPrint myA = new MyThreadPrint("A", C, A); MyThreadPrint myB = new MyThreadPrint("B", A, B); MyThreadPrint myC = new MyThreadPrint("C", B, C); try &#123; new Thread(myA).start(); Thread.sleep(100); new Thread(myB).start(); Thread.sleep(100); new Thread(myC).start(); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Obj.wait()，与Obj.notify()必须要与synchronized(Obj)一起使用，也就是wait,与notify是针对已经获取了Obj锁进行操作，从语法角度来说就是Obj.wait(),Obj.notify必须在synchronized(Obj){…}语句块内。从功能上来说wait就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的notify()唤醒该线程，才能继续获取对象锁，并继续执行。但有一点需要注意的是notify()调用后，并不是马上就释放对象锁的，而是在相应的synchronized(){}语句块执行结束，自动释放锁后，JVM会在wait()对象锁的线程中随机选取一线程，赋予其对象锁，唤醒线程，继续执行。Thread.sleep()与Object.wait()二者都可以暂停当前线程，释放CPU控制权，主要的区别在于Object.wait()在释放CPU同时，释放了对象锁的控制。 一个对象锁是prev，就是前一个线程所持有的对象锁。还有一个就是自身对象锁。主要的思想就是，为了控制执行的顺序，必须要先持有prev锁，也就前一个线程要释放自身对象锁，再去申请自身对象锁，两者兼备时打印，之后首先调用self.notify()释放自身对象锁，唤醒下一个等待线程，再调用prev.wait()释放prev对象锁，终止当前线程，等待循环结束后再次被唤醒。运行上述代码，可以发现三个线程循环打印ABC，共10次。程序运行的主要过程就是A线程最先运行，持有C,A对象锁，后释放A,C锁，唤醒B。线程B等待A锁，再申请B锁，后打印B，再释放B，A锁，唤醒C，线程C等待B锁，再申请C锁，后打印C，再释放C,B锁，唤醒A。看起来似乎没什么问题，但如果你仔细想一下，就会发现有问题，就是初始条件，三个线程按照A,B,C的顺序来启动，按照前面的思考，A唤醒B，B唤醒C，C再唤醒A。但是这种假设依赖于JVM中线程调度、执行的顺序。 wait和sleep区别共同点： 他们都是在多线程的环境下，都可以在程序的调用处阻塞指定的毫秒数，并返回。 wait()和sleep()都可以通过interrupt()方法 打断线程的暂停状态 ，从而使线程立刻抛出InterruptedException。如果线程A希望立即结束线程B，则可以对线程B对应的Thread实例调用interrupt方法。如果此刻线程B正在wait/sleep /join，则线程B会立刻抛出InterruptedException，在catch() {} 中直接return即可安全地结束线程。需要注意的是，InterruptedException是线程自己从内部抛出的，并不是interrupt()方法抛出的。对某一线程调用 interrupt()时，如果该线程正在执行普通的代码，那么该线程根本就不会抛出InterruptedException。但是，一旦该线程进入到 wait()/sleep()/join()后，就会立刻抛出InterruptedException 。不同点： Thread类的方法：sleep(),yield()等Object的方法：wait()和notify()等 每个对象都有一个锁来控制同步访问。Synchronized关键字可以和对象的锁交互，来实现线程的同步。sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。 wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用 所以sleep()和wait()方法的最大区别是： sleep()睡眠时，保持对象锁，仍然占有该锁； 而wait()睡眠时，释放对象锁。 但是wait()和sleep()都可以通过interrupt()方法打断线程的暂停状态，从而使线程立刻抛出InterruptedException（但不建议使用该方法）。 参考Java多线程学习（吐血超详细总结） Java多线程基础学习]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose收集]]></title>
    <url>%2F2019%2F03%2F26%2Fdocker-compose%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[自己写的，收集整理的一些docker-compose.yml Aria2一个多线程下载器，可由网页端管理 123456789101112131415version: '2'services: aria2: image: wahyd4/aria2-ui container_name: aria2 ports: - "6810:80" - "6800:6800" volumes: - /usr/conf/aria2:/root/conf - /media/download/aria2:/var/www:rw #- /usr/data/aria2:/var/www:rw environment: - DOMAIN=:80 restart: always MongoDB123456789101112131415version: '3.1'services: mongo: image: mongo container_name: mongodb restart: always environment: MONGO_INITDB_ROOT_USERNAME: username MONGO_INITDB_ROOT_PASSWORD: password ports: - "27017:27017" volumes: - /usr/data/mongodb:/data/db MongoDB删除重复字段 123456789101112131415161718192021222324252627282930db.climage.aggregate([ &#123; $group: &#123; _id: &#123; title: '$title', page_url: '$page_url' &#125;, count: &#123; $sum: 1 &#125;, dups: &#123; $addToSet: '$_id' &#125; &#125; &#125;, &#123; $match: &#123; count: &#123; $gt: 1 &#125; &#125; &#125;]).forEach(function(doc) &#123; doc.dups.shift(); db.climage.remove(&#123; _id: &#123; $in: doc.dups &#125; &#125;);&#125;); Redis1234567891011version: '2'services: redis: image: redis container_name: redis ports: - 6379:6379 volumes: - /usr/conf/redis/redis.conf:/usr/local/etc/redis/redis.conf - /usr/conf/redis/data:/data restart: unless-stopped]]></content>
      <categories>
        <category>docker-compose</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java虚拟机]]></title>
    <url>%2F2019%2F03%2F22%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[《深入理解Java虚拟机》读书笔记，以及其他关于JVM的一些博客 Java运行时数据区分为：程序计数器，Java虚拟机栈，本地方法区，Java堆，方法区 程序计数器，Java虚拟机，本地方法区是线程私有，随线程而生，随线程而灭。 程序计数器记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空），分支，跳转，异常处理都需要计数器完成。 Java虚拟机栈每个方法在执行的同时会创建一个栈帧用于存储局部变量表，操作数栈，常量池引用等信息。每一个方法从调用到执行完成的过程，对应一个栈帧在虚拟机中入栈到出栈的过程。 异常： 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。 本地方法栈为虚拟机使用到的Native方法服务。 异常： StackOverError， OutOfMemoryError Java堆被所有线程共享。存放对象实例，是垃圾收集器管理的主要区域，“GC堆”。 异常： OutOfMemoryError 方法区线程共享。存放被虚拟机加载的类信息，常量，静态变量，即时编译后的代码等数据。和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。 运行时常量池是方法区的一部分。用于存放编译期生成的各种字面量和符号引用。具备动态性。 直接内存在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。 垃圾收集主要针对堆和方法区。 判断对象是否可回收引用计数法为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 目前主流Java虚拟机没有使用这种方法。 可达性分析算法以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。 可作为GC Roots的对象： 虚拟机栈引用的对象 方法区静态属性引用对象 常量引用的对象 本地方法栈中引用的对象 引用类型 强引用 强引用的对象不会被回收。 1Object obj = new Object(); 软引用 有用但非必须的对象。在内存不够的情况下被回收。 弱引用 一定会被回收。 虚引用 又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。 为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。 回收过程一个对象死亡经历两次标记过程。第一次，使用可达性分析算法标记，判断对象是否需要执行finalize()方法，如果有必要执行，被一个低优先级的Finalizer线程执行。finalize()方法是对象逃脱死亡的最后一次机会。如果对象在finalize()中没有重新与引用链上任何一个对象建立关联，则会被回收。 当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。 方法区的回收方法区主要存放永久代对象。主要是对常量池的回收和对类的卸载。 类卸载条件： 该类所有的实例已经被回收，Java堆中不存在该类的任何实例 加载该类的CladdLoader被回收。 该类对应的java.lang.Class对象没有在任何地方被引用 垃圾收集算法标记-清除算法两个阶段：标记，清除。首先标记所有需要回收的对象，标记完成统一回收。 不足： 标记和清除效率都不高 标记清除后会产生大量不连续的内存碎片 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 不足为只用内存的一半 使用该算法收集新生代 标记-整理算法让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法将Java堆分为新生代和老年代。新生代选用复制算法，老年代使用：标记-清除或者标记-整理算法。 垃圾收集器 1. Serial 收集器单线程收集器，进行垃圾收集时，必须暂停其他所有线程。 优点：简单高效，单个CPU环境，单线程收集效率高。 是Client模式下默认的新生代收集器。 2. ParNew 收集器Serial收集器的多线程版。 Server模式下虚拟机的默认新生代收集器。 3. Parallel Scavenge 收集器使用复制算法，多线程。 其他收集器关注点是尽量缩短垃圾收集时用户线程的停顿时间，它的目的是达到一个可控的吞吐量。 4. Serial Old 收集器Serial收集器的老年代版本，单线程，使用 标记-整理算法 Srver场景： 作为CMS收集器的后备 JDK1.5 前与 Parallel Scavenge收集器搭配 5. Parallel Old 收集器Parallel Scavenge 收集器的老年代版本。 在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 6. CMS收集器基于 标记-清除算法 流程： 初始标记：标记GC Roots能直接关联到的对象，速度快。需要Stop The World 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。需要Stop The World 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 优点：并发收集，低停顿 缺点： 对CPU资源敏感，因此吞吐量低 无法处理浮动垃圾， 标记 - 清除算法导致的空间碎片 7. G1 收集器G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 特点： 并行与并发：使用多个CPU缩短 STW的时间 分代收集： 空间整合：整体使用 标记-整理 算法，局部使用复制算法 可预测的停顿 收集范围是整个Java堆，把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 步骤： 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 内存分配与回收策略Minor GC 和 Full GC Minor GC：发生在新生代的垃圾收集，频繁，回收速度快 Full GC：发生在老年代的垃圾收集。伴随着至少一次的Minor GC，速度慢。 内存分配1. 对象优先在Eden分配大多数情况下，对象优先在新生代Eden分配。当Eden空间不够时，发起Minor GC。 2. 大对象直接进入老年代最典型的大对象是那种很长的字符串以及数组。 3. 长期存活对象直接进入老年代对象在Eden出生并经历第一次Minor GC后任然存活，并能被Survivor接受，将被移动到Survivor空间，对象年龄为1,。对象在Survivor区每熬过一次，Minor GC，年龄增加一岁，增加到（默认15岁）被晋升到老年代中。 年龄阈值通过-XX:PretenureSizeThreshold设定 4. 动态对象年龄判定如果在Survivor空间中，相同年龄所有对象大小的总和大于Survivor空间的一半，年两大于等于改年龄的对象直接进入老年代。 5. 空间分配担保出现大量对象在Minor GC后仍然存活的情况，需要老年代进行分配担保，Survivor空间无法容纳的对象直接进入老年代。 类加载机制类与类加载器比较两个类是否相等，只有在两个类有同一个类加载器加载的前提下才有意义，否则，即使这两个类来自于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，这连个类必定不相等。 类加载器分类 启动类加载器 扩展类加载器 应用程序类加载器 双亲委派模型 双亲委派模型要求，除了顶层的启动类加载器，其他加载器都应该有自己的父类加载器。类加载器以组合的关系复用父加载器。 工作过程如果一个类加载器收到了类加载请求，它首先不会加载这个类，而是把这个请求委派给父类加载器完成，每一层次都是如此，因此所有的加载请求最终都会传送到顶层的启动类加载器，只有当父类加载器无法完成这个加载请求，子加载器才会尝试自己加载。 好处Java类随着他的加载器有了带有优先级的层次关系。例如 java.lang.Object 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2017. CS-Notes-Java 虚拟机 Javadoop - HotSpot JVM 内存管理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[西南交大教务模拟登陆]]></title>
    <url>%2F2019%2F01%2F29%2F%E8%A5%BF%E5%8D%97%E4%BA%A4%E5%A4%A7%E6%95%99%E5%8A%A1%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[最近由于需要做一个获取学生课表的项目，就去研究了下如何模拟登录，并用Python成功模拟登录。在此记录一下自己的分析过程。 登录分析使用Chrome登录教务网，打开调试模式，使用NetWork记录点击“登录按钮”后发生的过程 点击登录后浏览器请求的地址为http://dean.vatuu.com/vatuu/UserLoginAction，这就是我们需要记录的一个url，模拟登录时就向改网址发送请求； 我们需要重点分析Header和cookie。查看Response Header，该网址返回的Header信息有个Set-Cookie字段；在Request-Headers中，有一个JSESSIONID UserLoadingAction是登录成功后跳转的一个页面。查看Request Header中的Cookie为学号+JSESSIONID，因此明白JSESSIONID以及如何获取它至关重要。 另一个问题就是验证码，我采用人工输入的方式。审查元素，查看验证码的接口，得到其地址。 复制这个地址，粘贴到地址栏，得到验证码。 我猜想验证码和JSESSIONID有很大关系。退出教务登录，打开调试工具的“Application-Cookies”可以看到保存的Cookie，清除 刷新验证码地址，可以看到会再次出现JSESSIONID 因此可以假设通过验证码获取JSESSIONDI 使用Python尝试登录123456789101112def get_jsessionid(): """ 访问登录界面，通过Response Header用于获取set-cookie """ s = requests.Session() r = s.get(get_photo_url) with open('./static/ranstring.jpg', 'wb') as file: file.write(r.content) get_head = r.headers set_cookie = str(get_head['Set-Cookie']) jessid = set_cookie.split(';')[0] return jessid 运行后，可以看到获取到了JSESSIONID。 之后模拟登录。 123456789101112131415161718jsessionid = get_jsessionid()full_cookie = 'username='+str(data['username'])+'; ' + str(jsessionid)log_msg = ""def login(): """ 登录 """ # 登录需要的cookie只有jsessionid headers['cookie'] = jsessionid data['ranstring'] = input("验证码：") # UserLoginAction res = requests.post( user_log_url, data, headers=headers, allow_redirects=True) log_msg = res.text log_msg = json.loads(log_msg) print(log_msg['loginMsg']) 看到出现教务返回的登录成功等字样就表示登录成功。 尝试获取课表时，却提示未登录。我认为UserLoadingAction这一步也是必须的。 再次分析 查看UserLoadingAction，发现向它传送的数据中有一个“loginMsg”字段，这正是点击‘’登录系统“成功后返回的字段的一部分 在登录时访问UserLoadingAction查看是否生效 123456789101112131415161718192021def login(): """ 登录 两步：UserLoginAction + UserLoadingAction """ headers['cookie'] = jsessionid data['ranstring'] = input("验证码：") # UserLoginAction res = requests.post( user_log_url, data, headers=headers, allow_redirects=True) # with open('./response.html') as file: # file.writer(response.text) log_msg = res.text log_msg = json.loads(log_msg) print(log_msg['loginMsg']) # UserLoadingAction headers['cookie'] = full_cookie data_loading = &#123; 'loginMsg': log_msg['loginMsg'] &#125; res = requests.post(user_loading_url, data=data_loading, headers=headers) 查看res，会提示登录成功，这时在访问课表的网址，就正常返回了课表 总结 正确的Header和Cookie很重要]]></content>
      <categories>
        <category>学校</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
</search>
