<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring Boot与MyBatis-Plus进阶使用]]></title>
    <url>%2F2019%2F08%2F07%2FSpring-Boot%E4%B8%8EMyBatis-Plus%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[几个月前整合完了MBP，用的比较少，所以MBP的高级功能没有详细体验。今天发先MBP有很多强大的功能，可以少写许多代码，就体验了一下。 自动生成代码不同于mybatis的生成代码，mybatis-plus可以生成controller等代码。AutoGenerator 是 MyBatis-Plus 的代码生成器，通过 AutoGenerator 可以快速生成 Entity、Mapper、Mapper XML、Service、Controller 等各个模块的代码，极大的提升了开发效率。 额外添加依赖： 123456789101112&lt;!-- 代码生成器依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatis-plus代码生成器默认模板--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt;&lt;/dependency&gt; 编写SQL123456789DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` bigint(20) DEFAULT NULL COMMENT &apos;唯一标示&apos;, `code` varchar(20) DEFAULT NULL COMMENT &apos;编码&apos;, `name` varchar(64) DEFAULT NULL COMMENT &apos;名称&apos;, `status` char(1) DEFAULT &apos;1&apos; COMMENT &apos;状态 1启用 0 停用&apos;, `gmt_create` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, `gmt_modified` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;修改时间&apos;) ENGINE=InnoDB DEFAULT CHARSET=utf8; 编写配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class MysqlGenerator &#123; private static final String PACKAGE_NAME = "com.example"; private static final String OUT_PATH = "/src/main/java"; private static final String AUTHOR = "spring"; private static final String MODULE_NAME = "demo"; /** * 数据库相关连接 */ private static final String URL = "jdbc:mysql://[]:3306/springboot_mybatis?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false"; private static final String USERNAME = ""; private static final String PASSWORD = ""; private static final String DRIVER = "com.mysql.cj.jdbc.Driver"; public static void main(String[] args) &#123; // 代码生成器 AutoGenerator generator = new AutoGenerator(); // 全局配置 String projectPath = System.getProperty("user.dir"); generator.setGlobalConfig(new GlobalConfig() // 输出目录 .setOutputDir(projectPath + OUT_PATH) // 覆盖文件 .setFileOverride(true) .setOpen(false) .setAuthor(AUTHOR) .setXmlName("%sMapper") // 自定义文件命名，注意 %s 会自动填充表实体属性！ .setMapperName("%sDao") .setServiceName("%Service") // 开启resultMap .setBaseResultMap(true) // 开启BaseColumnList .setBaseColumnList(true) ); // 数据源配置 generator.setDataSource(new DataSourceConfig() .setUrl(URL) .setUsername(USERNAME) .setPassword(PASSWORD) .setDriverName(DRIVER) ); //包配置 generator.setPackageInfo(new PackageConfig() .setModuleName(MODULE_NAME) .setParent(PACKAGE_NAME) .setMapper("dao") ); // 如果模板引擎是 velocity String templatePath = "/templates/mapper.xml.vm"; // 自定义配置 InjectionConfig cfg = new InjectionConfig() &#123; @Override public void initMap() &#123; &#125; &#125;; // 自定义输出配置 List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;(); focList.add(new FileOutConfig(templatePath) &#123; @Override public String outputFile(TableInfo tableInfo) &#123; // 配置xxxMapper.xml路径和文件名 return projectPath + "/src/main/resources/mapper/" + "/" + tableInfo.getEntityName() + "Mapper.xml"; &#125; &#125;); cfg.setFileOutConfigList(focList); generator.setCfg(cfg); // 配置模板 generator.setTemplate(new TemplateConfig() .setXml(null) // 禁止生成Controller //.setController(null) ); // 策略配置 generator.setStrategy(new StrategyConfig() .setNaming(NamingStrategy.underline_to_camel) .setColumnNaming(NamingStrategy.underline_to_camel) // public User setName(String name) &#123;this.name = name; return this;&#125; .setEntityColumnConstant(true) .setEntityLombokModel(true) .setControllerMappingHyphenStyle(true) ); generator.setTemplateEngine(new VelocityTemplateEngine()); // 执行 generator.execute(); &#125;&#125; 生成后运行如图所示。第一次编写比较麻烦，但是编写完成后可以存入到IDEA的模板中，下次直接生成MysqlGenerate.java模板，只需做些小小的修改即可使用。 官网代码生成器指南 通用的CRUD配置MyBatis-Plus 12345678@Configuration@MapperScan("com.example.demo.dao")public class MyBatisPlusConfig &#123; @Bean public PaginationInterceptor paginationInterceptor() &#123; return new PaginationInterceptor(); &#125;&#125; 对于常用的CRUD，不用自己写xml，因为MyBatis-Plus内置了一些常用操作。例如： 123456789@Testpublic void insert() &#123; User user = new User(); user.setName(&quot;Jon&quot;); user.setCode(&quot;009&quot;); user.setStatus(&quot;0&quot;); int res = userDao.insert(user); log.info(&quot;--插入 &#123;&#125; 条&quot;, res);&#125; 批量插入。属于Service CRUD的接口 1234567891011121314@Testpublic void saveMany() &#123; int cap = 15; List&lt;User&gt; users = new ArrayList&lt;&gt;(cap); for (int i = 0; i &lt; cap; ++i) &#123; User user = new User(); user.setName("Jon + " + i); user.setStatus("A"); user.setCode("007" + i); users.add(user); &#125; userService.saveBatch(users); log.info("-----批量插入--------");&#125; 更多使用：CRUD接口 分页插件在MyBatisPlusConfig中配置如下： 12345678/** * 分页插件 */@Beanpublic PaginationInterceptor paginationInterceptor() &#123; // paginationInterceptor.setLimit(你的最大单页限制数量，默认 500 条，小于 0 如 -1 不受限制); return new PaginationInterceptor();&#125; dao层 12345678910111213public interface UserDao extends BaseMapper&lt;User&gt; &#123; /** * &lt;p&gt; * 查询 : 根据state状态查询用户列表，分页显示 * 注意!!: 如果入参是有多个,需要加注解指定参数名才能在xml中取值 * &lt;/p&gt; * * @param page 分页对象,xml中可以从里面进行取值,传递参数 Page 即自动分页,必须放在第一位(你可以继承Page实现自己的分页对象) * @param status 状态 * @return 分页对象 */ IPage&lt;User&gt; selectPage(Page page, @Param("status") String status);&#125; mapper编写 123456&lt;!--分页查询--&gt;&lt;select id="selectPage" resultMap="BaseResultMap"&gt; select &lt;include refid="Base_Column_List"/&gt; from user&lt;/select&gt; 测试 123456789101112131415161718/** * 分页查询测试 */@Testpublic void findPage() &#123; Page&lt;User&gt; page = new Page&lt;&gt;(1, 3); // 当前页码 每页数 Page&lt;User&gt; page = new Page&lt;&gt;(1, 3); IPage&lt;User&gt; userIPage = userDao.selectPage(page, "A"); log.info(userIPage.toString()); log.info("---总条数：&#123;&#125; ---", userIPage.getTotal()); log.info("---当前页：&#123;&#125; ---", userIPage.getCurrent()); log.info("---总页码：&#123;&#125; ---", userIPage.getPages()); log.info("---每页多少条：&#123;&#125; ---", userIPage.getSize()); List&lt;User&gt; users = userIPage.getRecords(); users.forEach(user -&gt; log.info(user.toString()));&#125; 参考 官网 Mybatis-Plus使用全解]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合RabbitMq]]></title>
    <url>%2F2019%2F08%2F06%2FSpring-Boot%E6%95%B4%E5%90%88RabbitMq%2F</url>
    <content type="text"><![CDATA[整合RabbitMQ 启动IDEA，初始化Spring Boot，选择message - rabbitmq 配置文件123456spring: rabbitmq: host: rabbitmq ip地址 port: 5672 username: root password: pass Rabbit设置RabbitMqConfig 123456789101112131415161718192021222324252627@Configurationpublic class RabbitMqConfig &#123; /** * 一对一 */ @Bean public Queue queueOne() &#123; return new Queue(RabbitConst.QUEUE_ONE); &#125; /** * 用来测试一对多 */ @Bean public Queue queueMany() &#123; return new Queue(RabbitConst.QUEUE_MANY); &#125; /** * 对象的发送和接受 */ @Bean public Queue objectQueue() &#123; return new Queue(RabbitConst.QUEUE_OBJECT); &#125;&#125; 一对一测试发送者 rabbitTemplate 是 Spring Boot 提供的默认实现 123456789101112131415@Componentpublic class HelloSender &#123; private final AmqpTemplate rabbitTemplate; private Logger logger = LoggerFactory.getLogger(this.getClass()); public HelloSender(AmqpTemplate rabbitTemplate) &#123; this.rabbitTemplate = rabbitTemplate; &#125; public void send()&#123; String context = "send hello" + new Date(); logger.info("Send: &#123;&#125;", context); this.rabbitTemplate.convertAndSend(RabbitConst.QUEUE_ONE, context); &#125;&#125; 接受者 通过@RabbitListener注解要接收消息的方法 12345678910@Component@RabbitListener(queues = RabbitConst.QUEUE_ONE)public class HelloReceiver &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @RabbitHandler public void process(String hello) &#123; logger.info("HelloReceive &#123;&#125;", hello); &#125;&#125; 高级使用对象支持12345678910111213141516171819202122232425262728293031/**发送者*/@Componentpublic class ObjectSender &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); private final AmqpTemplate rabbitTemplate; public ObjectSender(AmqpTemplate rabbitTemplate) &#123; this.rabbitTemplate = rabbitTemplate; &#125; public void send(User user) &#123; logger.info("-----ObjectSender send user: &#123;&#125;-----", user.toString()); rabbitTemplate.convertAndSend(RabbitConst.QUEUE_OBJECT, user); &#125;&#125;/**接受者*/@Component@RabbitListener(queues = RabbitConst.QUEUE_OBJECT)public class ObjectReceiver &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @RabbitHandler public void process(User user) &#123; logger.info("-----receive user: &#123;&#125; -----", user.toString()); &#125;&#125; 参考 纯洁的微笑 - Spring Boot(八)：RabbitMQ 详解]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合Kafka]]></title>
    <url>%2F2019%2F07%2F27%2FSpring-Boot%E6%95%B4%E5%90%88Kafka%2F</url>
    <content type="text"><![CDATA[整合Kafka。 Kafka介绍Kafka是一种高吞吐量的分布式发布订阅消息系统，是消息中间件的一种。它一些基本术语： Kafka将消息以topic为单位进行归纳 向Kafka topic发布消息的程序称为producers 预定topic并消费消息的程序称为consumer Kafka以集群方式运行，可由一个或多个服务组成，每个服务叫做一个broker 前面已经搭建好了Kafka，搭建过程 Spring Boot整合Kafka使用IDEA构建项目Spring Boot项目，选择依赖message-Apache Kafka。 实体类12345678910111213@Datapublic class Message implements Serializable &#123; private String form; private String message; public Message() &#123; &#125; public Message(String form, String message) &#123; this.form = form; this.message = message; &#125;&#125; 配置application.yml。Spring Boot支持在application.yml中配置Kafka的生产者配置和消费者配置。当然也可以使用@Configuration使用Java类配置。 123456789101112spring: kafka: consumer: bootstrap-servers: localhost:9092 group-id: test-consumer auto-offset-reset: latest key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer producer: bootstrap-servers: localhost:9092 key-serializer: org.apache.kafka.common.serialization.StringDeserializer value-serializer: org.apache.kafka.common.serialization.StringDeserializer 创建生产者发送消息 123456789101112131415161718192021222324@Servicepublic class Producer &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); private static final String TOPIC = "users"; @Autowired private KafkaTemplate&lt;String, String&gt; kafkaTemplate; public void sendMessage(String message) &#123; ListenableFuture&lt;SendResult&lt;String, String&gt;&gt; future = this.kafkaTemplate.send(TOPIC, message); future.addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, String&gt;&gt;() &#123; @Override public void onFailure(Throwable ex) &#123; logger.error("消息：&#123;&#125; 发送失败，原因：&#123;&#125;", message, ex.getMessage()); &#125; @Override public void onSuccess(SendResult&lt;String, String&gt; result) &#123; logger.info("成功发送消息：&#123;&#125;, offset=[&#123;&#125;]", message, result.getRecordMetadata()); &#125; &#125;); &#125;&#125; 在send方法中，通过回调的方式确定消息是否发送成功。 我们没有配置KafkaTemplate，因此使用@Service自动配置。 创建消费者接受消息 12345678public class Consumer &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @KafkaListener(topics = "users") public void consumer(String message) throws IOException&#123; logger.info("接受消息：&#123;&#125;", message); &#125;&#125; @KafkaListener注解来监听名称为users的Topic bootstrap-servers:生产者消费者的地址。 key-deserializer和value-deserializer指定了序列化策略，生产者指定为kafka提供的StringSerializer，用来发送简单的String类消息 发布消息123456789101112131415@Service@RestControllerpublic class SendMessageController &#123; private final Producer producer; @Autowired SendMessageController(Producer producer) &#123; this.producer = producer; &#125; @GetMapping("send/&#123;message&#125;") public void send(@PathVariable String message) &#123; this.producer.sendMessage(message); &#125;&#125; 错误启动后，访问http://localhost:8080/send/hello，发现报告一下错误： 消息：hello,mrbird 发送失败，原因：Failed to send; nested exception is org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for users-0: 30047 ms has passed since batch creation plus linger time [Producer clientId=producer-1] Connection to node 1001 could not be established. Broker may not be available. 猜测是由于使用Docker创建了Kafka，导致外网访问Kafka时没有配置好正确的IP。该问题待解决。 参考 How to Work with Apache Kafka in Your Spring Boot Application MrBird - Spring Boot整合Kafka]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker搭建Kafka]]></title>
    <url>%2F2019%2F07%2F26%2FDocker%E6%90%AD%E5%BB%BAKafka%2F</url>
    <content type="text"><![CDATA[准备在项目中学习Kafka，因此准备在Linux环境下使用Docker搭建Kafka环境。 准备我使用的是Ubuntu 16.04，已经安装好Docker和Docker Compose。Kafka没有官方镜像，但是有知名的第三方镜像wurstmeister/kafka ，同时，需要用zookeeper管理kafka，因此可以用wurstmeister/zookeeper 使用docker-compose123456789101112131415161718version: '3.0'services: zookeeper: image: wurstmeister/zookeeper ports: - "2181:2181" kafka: image: wurstmeister/kafka ports: - "9092:9092" environment: # 注意这里填写宿主的ip KAFKA_ADVERTISED_HOST_NAME: 172.18.0.1 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_HEAP_OPTS: -Xmx256M -Xms256M volumes: - /var/run/docker.sock:/var/run/docker.sock 指定KAFKA_HEAP_OPTS是由于我的主机内存小，需要限制内存，否则无法启动。如果主机内存足够，不需要限制 KAFKA_ADVERTISED_HOST_NAME需要用到宿主机的IP。在Ubuntu18.04中，每次登陆都会显示系统信息，docker0就是填写的宿主机ip。 在Ubuntu16.04中，可以使用下面的命令查询： 1ip addr show docker0 查询结果为：172.18.0.1 启动kafka 1docker-compose up -d 之后通过 docker ps可以看到启动了一个zookeeper容器和一个kafka容器。 验证 进入到kafka容器中 1docker exec -it kafka_kafka_1 /bin/bash 创建一个topic， 1234bash-4.4&gt; kafka-topics.sh --create --topic test --zookeeper kafka_zookeeper_1:2181 --replication-factor 1 --partitions 1# Created topic test.bash-4.4&gt; kafka-topics.sh --list --zookeeper kafka_zookeeper_1:2181# test 发布几条消息 123456bash-4.4&gt; kafka-console-producer.sh --topic=test --broker-list kafka_kafka_1:9092&gt;hello this is kafka&gt;wow awesome&gt;hahah&gt;hello r^c退出 接受消息 12345bash-4.4&gt; kafka-console-consumer.sh --bootstrap-server kafka_kafka_1:9092 --from-beginning --topic testhello this is kafkawow awesomehahahhello r 接收到了发布的消息，部署正常。 待解决使用Spring Boot整合Kafka时发现无法连接，一直报错[Producer clientId=producer-1] Connection to node 1001 could not be established. Broker may not be available.显示Google了好久暂时未解决，猜测是由于使用Docker，内外网ip没有设置正确，导致外网无法访问。 参考 使用Docker快速搭建Kafka开发环境 StackOverflow - kafka 8 and memory - There is insufficient memory for the Java Runtime Environment to continue]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>docker-compose</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的遍历-算法]]></title>
    <url>%2F2019%2F07%2F12%2F%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[二叉树的先中后遍历的递归与非递归实现，层序遍历，Mirros遍历 先序遍历LeetCode-144. Binary Tree Preorder Traversal 递归实现123456789101112131415class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; preOrderHelp(res, root); return res; &#125; private void preOrderHelp(List&lt;Integer&gt; res, TreeNode root)&#123; if(root == null) return; res.add(root.val); preOrderHelp(res, root.left); preOrderHelp(res, root.right); &#125;&#125; 非递归实现使用栈保存节点。注意入栈时是右孩子先入栈。 123456789101112131415161718class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); TreeNode node = null; while(!stack.isEmpty())&#123; node = stack.pop(); if(node != null)&#123; res.add(node.val); stack.push(node.right); stack.push(node.left); &#125; &#125; return res; &#125;&#125; 非递归实现2不需要入栈，每次遍历到“左”节点，立即输出即可。 123456789101112131415161718class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; TreeNode cur = root; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while(cur != null || !stack.empty())&#123; while(cur != null)&#123; res.add(cur.val); stack.push(cur); cur = cur.left; &#125; cur = stack.pop(); cur = cur.right; &#125; return res; &#125;&#125; 中序遍历LeetCode - 94. Binary Tree Inorder Traversal 递归实现123456789101112131415class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; inorderHelp(res, root); return res; &#125; private void inorderHelp(List&lt;Integer&gt; res, TreeNode root)&#123; if(root == null) return; inorderHelp(res, root.left); res.add(root.val); inorderHelp(res, root.right); &#125;&#125; 非递归实现12345678910111213141516171819class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; TreeNode cur = root; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while(cur != null || !stack.isEmpty())&#123; while(cur != null)&#123; stack.push(cur); cur = cur.left; &#125; cur = stack.pop(); res.add(cur.val); cur = cur.right; &#125; return res; &#125;&#125; 后序遍历LeetCode - 145. Binary Tree Postorder Traversal 递归123456789101112131415class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; postorderHelp(res, root); return res; &#125; private void postorderHelp(List&lt;Integer&gt; res, TreeNode root)&#123; if(root == null) return; postorderHelp(res, root.left); postorderHelp(res, root.right); res.add(root.val); &#125;&#125; 非递归12 层序遍历newcoder - 从上往下打印二叉树 LeetCode - 102. Binary Tree Level Order Traversal 使用队列作为辅助结构 12345678910111213141516public class Solution &#123; public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) &#123; ArrayList&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); TreeNode node = null; while(!queue.isEmpty())&#123; node = queue.poll(); res.add(node.val); if(node.left != null) queue.offer(node.left); if(node.right != null) queue.offer(node.right); &#125; return res; &#125;&#125; Morris遍历Morris遍历可以在O(N)的时间复杂度内完成遍历，且空间复杂度为O(1)，N：二叉树节点个数。其遍历规则为： 当前节点cur，如果cur无左孩子，cur右移（cur = cur.right） 如果cur 有左孩子，找到cur左子树最右的节点，记为mostright。 如果mostright的right指向空，让其指向cur，cur 左移（cur = cur.left） 如果mostright的right指向cur，让其指向空，cur 右移 123456789101112131415161718192021public void mirros(TreeNode root)&#123; if(root == null) return; TreeNode cur = root; TreeNode mostRight = null; while(cur != null)&#123; mostRight = cur.left; if(mostRight != null)&#123; while(mostRight.right != null &amp;&amp; mostRight.right != cur)&#123; mostRight = mostRight.right; &#125; if(mostRight.right == null)&#123; mostRight.right = cur; cur = cur.left; continue; &#125;else&#123; mostRight.right = null; &#125; &#125; cur = cur.right; &#125;&#125; 先序遍历1234567891011121314151617181920212223242526272829class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; TreeNode cur = root; TreeNode mostRight = null; while(cur != null)&#123; mostRight = cur.left; if(mostRight != null)&#123; while(mostRight.right != null &amp;&amp; mostRight.right != cur)&#123; mostRight = mostRight.right; &#125; if(mostRight.right == null)&#123; mostRight.right = cur; // 先序 res.add(cur.val); cur = cur.left; continue; &#125;else&#123; mostRight.right = null; &#125; &#125;else&#123;// 先序 res.add(cur.val); &#125; cur = cur.right; &#125; return res; &#125;&#125; 中序遍历12345678910111213141516171819202122232425262728class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; TreeNode cur = root; TreeNode most = null; while(cur != null)&#123; most = cur.left; if(most != null)&#123; while(most.right != null &amp;&amp; most.right != cur)&#123; most = most.right; &#125; if(most.right == null)&#123; most.right = cur; cur = cur.left; continue; &#125;else&#123; most.right = null; &#125; &#125; // 中序 res.add(cur.val); cur = cur.right; &#125; return res; &#125;&#125; 参考 掘金 - 刷题二叉树非递归遍历]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caddy使用记录]]></title>
    <url>%2F2019%2F06%2F23%2FCaddy%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[Caddy是使用Go语言编写的一个轻量的web服务器，类似Nginx。 官网 Caddy轻量，配置简单，插件丰富，我一般使用用来折腾自己的VPS，这里记录下其安装过程和配置文件 安装使用官方提供的脚本安装 1curl https://getcaddy.com | bash -s personal 带插件 1curl https://getcaddy.com | bash -s personal http.webdav 配置Caddyfile 12345:6600 &#123; root /data timeouts none gzip&#125; 运行1caddy -conf /path/Caddyfile 也可以使用nohup后台运行 1nohup caddy -conf /path/Caddyfile &amp; 插件webdav123456789:6600 &#123; root /media timeouts none gzip basicauth / user password webdav &#123; scope /media #需要显示的路径 &#125;&#125;]]></content>
      <categories>
        <category>Caddy</category>
      </categories>
      <tags>
        <tag>Caddy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用脚本收集]]></title>
    <url>%2F2019%2F05%2F30%2FLinux%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[包括Docker, Docker-compose 安装Docker适用于Ubuntu 18.04 12345678910111213apt-get remove docker docker-engine docker.io containerd runcapt-get updatesudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable"sudo apt updateapt-get install docker-ce docker-ce-cli containerd.iodocker --version 如果出现 unable to resolve host ubuntu，首先查看/etc/hostname中的内容，之后编辑/etc/hosts，添加以下内容：127.0.1.1 ubutnu 安装docker-compose1234sudo curl -L "https://github.com/docker/compose/releases/download/1.23.2/docker-compose-Linux-x86_64" -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composedocker-compose --versionecho 'docker docker-compose installed' 安装 Miniconda12# 下载wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 之后执行脚本，选择安装位置（我一般选/usr/local/bin/miniconda3） plus1wget -N --no-check-certificate "https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh" &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.sh Rclone使用Rclone挂载Onedriver网盘 官网安装教程 1curl https://rclone.org/install.sh | sudo bash 客户端授权。 需要在本地Windows上下载rclone。下载。解压。使用cmd进入rclone文件夹。执行reclone authorize “onedrive”，选择，登录onedriver账号后会出现{&#39;accss_token&#39;:&#39;xxx&#39;}，复制xxx内容 之后在Linux上通过脚本安装。安装完成执行： rclone config 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677No remotes found - make a new onen) New remotes) Set configuration passwordq) Quit confign/s/q&gt; nname&gt; springType of storage to configure.Enter a string value. Press Enter for the default ("").Choose a number from below, or type in your own value ....19 / Microsoft OneDrive \ "onedrive"Storage&gt; 19** See help for onedrive backend at: https://rclone.org/onedrive/ **Microsoft App Client IdLeave blank normally.Enter a string value. Press Enter for the default ("").client_id&gt; Microsoft App Client SecretLeave blank normally.Enter a string value. Press Enter for the default ("").client_secret&gt; Edit advanced config? (y/n)y) Yesn) Noy/n&gt; nRemote configUse auto config? * Say Y if not sure * Say N if you are working on a remote or headless machiney) Yesn) Noy/n&gt; nFor this to work, you will need rclone available on a machine that has a web browser available.Execute the following on your machine: rclone authorize "onedrive"Then paste the result below:result&gt; ## 刚才复制的tokenChoose a number from below, or type in an existing value 1 / OneDrive Personal or Business \ "onedrive"Your choice&gt; 1Found 1 drives, please select the one you want to use:0: (personal) id=xxxChose drive to use:&gt; 0Found drive 'root' of type 'personal', URL: https://onedrive.live.com/?cid=xxIs that okay?y) Yesn) Noy/n&gt; y--------------------[spring]type = onedrivetoken = xxxdrive_id = xxxdrive_type = personal--------------------y) Yes this is OKe) Edit this remoted) Delete this remotey/e/d&gt; yCurrent remotes:Name Type==== ====xxx onedrivee) Edit existing remoten) New remoted) Delete remoter) Rename remotec) Copy remotes) Set configuration passwordq) Quit confige/n/d/r/c/s/q&gt; q 挂载 rclone mount DriveName:Folder LocalFolder –copy-links –no-gzip-encoding –no-check-certificate –allow-other –allow-non-empty –umask 00 这样挂载后会卡住不动，因此可以让其在后台运行： nohup rclone mount DriveName:Folder LocalFolder –copy-links –no-gzip-encoding –no-check-certificate –allow-other –allow-non-empty –umask 00 &amp; 之后使用df -h可以查看]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合Shiro]]></title>
    <url>%2F2019%2F05%2F27%2FSpring-Boot%E6%95%B4%E5%90%88Shiro%2F</url>
    <content type="text"><![CDATA[整合Shiro 开始使用IDEA创建项目。 pom.xml依赖如下 123456789101112131415161718192021222324252627282930313233&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 其中，使用Shiro官方支持的ehcache缓存。 修改application.yml 123456789101112server: port: 8080spring: datasource: url: jdbc:mysql://localhost:3306/springboot_shiro?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 654321 driver-class-name: com.mysql.cj.jdbc.Driver thymeleaf: mode: LEGACYHTML5 cache: false 初始化数据库 12345678DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `username` varchar(255) DEFAULT NULL COMMENT &apos;用户名&apos;, `password` varchar(255) DEFAULT NULL COMMENT &apos;密码&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; 实体类Usre.java 1234567@Data@ToStringpublic class User &#123; private Long id; private String username; private String password;&#125; mapper，service 12345678910111213141516171819202122232425// mapperpublic interface UserMapper &#123; @Select("select * from user where username = #&#123;username&#125;") User findByUserName(String username);&#125;//servicepublic interface UserService &#123; User findByUsername(String username);&#125;// impl@Servicepublic class UserServiceImpl implements UserService &#123; private final UserMapper userMapper; public UserServiceImpl(UserMapper userMapper) &#123; this.userMapper = userMapper; &#125; @Override public User findByUsername(String name)&#123; return userMapper.findByUsername(name); &#125;&#125; Shiro配置 首先要配置的是 ShiroConfig 类，Apache Shiro 核心通过 Filter 来实现，就好像 SpringMvc 通过 DispachServlet 来主控制一样。 既然是使用 Filter 一般也就能猜到，是通过 URL 规则来进行过滤和权限校验，所以我们需要定义一系列关于 URL 的规则和访问权限。 shiroConfig.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Configurationpublic class ShiroConfig &#123; @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager) &#123; ShiroFilterFactoryBean filterFactoryBean = new ShiroFilterFactoryBean(); filterFactoryBean.setSecurityManager(securityManager); filterFactoryBean.setLoginUrl("/login"); // 拦截器 Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); // 配置退出 filterChainDefinitionMap.put("/logout", "logout"); // 如果不设置默认会自动寻找Web工程根目录下的"/login.jsp"页面; filterChainDefinitionMap.put("/login", "anon"); // 静态资源 filterChainDefinitionMap.put("/css/**", "anon"); filterChainDefinitionMap.put("/js/**", "anon"); filterChainDefinitionMap.put("/lib/**", "anon"); // 其他请求都拦截， filterChainDefinitionMap.put("/**", "user"); filterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return filterFactoryBean; &#125; @Bean public MyShiroRealm myShiroRealm() &#123; return new MyShiroRealm(); &#125; @Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(myShiroRealm()); securityManager.setSessionManager(sessionManager()); return securityManager; &#125; @Bean public SessionManager sessionManager() &#123; DefaultWebSessionManager sessionManager = new DefaultWebSessionManager(); // 10min sessionManager.setGlobalSessionTimeout(60 * 60 * 10); sessionManager.setSessionDAO(new EnterpriseCacheSessionDAO()); return sessionManager; &#125;&#125; Filter Chain 定义说明： 1、一个URL可以配置多个 Filter，使用逗号分隔 2、当设置多个过滤器时，全部验证通过，才视为通过 3、部分过滤器可指定参数，如 perms，roles 自定义Realm实现 在认证、授权内部实现机制中都有提到，最终处理都将交给Real进行处理。因为在 Shiro 中，最终是通过 Realm 来获取应用程序中的用户、角色及权限信息的。通常情况下，在 Realm 中会直接从我们的数据源中获取 Shiro 需要的验证信息。可以说，Realm 是专用于安全框架的 DAO. Shiro 的认证过程最终会交由 Realm 执行，这时会调用 Realm 的getAuthenticationInfo(token)方法。 该方法主要执行以下操作: 1、检查提交的进行认证的令牌信息 2、根据令牌信息从数据源(通常为数据库)中获取用户信息 3、对用户信息进行匹配验证。 4、验证通过将返回一个封装了用户信息的AuthenticationInfo实例。 5、验证失败则抛出AuthenticationException异常信息。 而在我们的应用程序中要做的就是自定义一个 Realm 类，继承AuthorizingRealm 抽象类，重载 doGetAuthenticationInfo()，重写获取用户信息的方法。 MyShiroRealm.java 12345678910111213141516171819202122232425262728293031323334353637public class MyShiroRealm extends AuthorizingRealm &#123; @Resource private UserService userService; /** * 权限校检 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; return null; &#125; /** * 主要是用来进行身份认证的，也就是说验证用户输入的账号和密码是否正确。 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; /* * 1. 从Token中获取输入的用户名密码 * 2. 通过输入的用户名查询数据库得到密码 * 3. 调用Authentication进行密码校验 */ // 获取用户名和密码 String username = (String) authenticationToken.getPrincipal(); String password = new String((char[]) authenticationToken.getCredentials()); User user = userService.findByUsername(username); if (user == null) &#123; throw new UnknownAccountException(); &#125; if (!password.equals(user.getPassword())) &#123; throw new IncorrectCredentialsException(); &#125; return new SimpleAuthenticationInfo(user, password, getName()); &#125;&#125; AuthorizationInfo用于权限校验 AuthenticationInfo用于身份验证 以上，shiro配置便完成了 测试 创建LoginController.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Controllerpublic class LoginController &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 首页 */ @GetMapping(value = &#123;"/", "/index"&#125;) public String index() &#123; return "index"; &#125; /** * 登录地址 */ @GetMapping("/login") public String login() &#123; return "login"; &#125; /** * 登录接口 * * @return 状态信息，或成功页面视图 */ @PostMapping("/login") public String login(String username, String password, Model model) &#123; String info = null; // 封装Token信息 = 用户名+密码 UsernamePasswordToken token = new UsernamePasswordToken(username, password); // shiro subject 实例 Subject subject = SecurityUtils.getSubject(); try &#123; subject.login(token); info = String.valueOf(subject.isAuthenticated()); model.addAttribute("info", "登录状态 ==&gt;" + info); return "/index"; &#125; catch (UnknownAccountException e) &#123; e.printStackTrace(); info = "未知账户异常"; &#125; catch (AuthenticationException e) &#123; e.printStackTrace(); info = "账户名密码错误"; &#125; catch (Exception e) &#123; e.printStackTrace(); info = "其他异常"; &#125; model.addAttribute("info", "登录状态 ==&gt;" + info); logger.info("登录状态 ==&gt;&#123;&#125;" + info); return "login"; &#125;&#125; @Controller用来告诉Spring这是个处理HTTP请求的控制器。 @RestController是@ResponseBody和@Controller的组合，被标记的控制器类所有return数据都自动封装为JSON格式。 @GetMapping标记该请求是Get请求，如果用Post请求则会报错no support 对于出现的两个login接口，@GetMapping和@PostMapping利用Java的方法重载创建了两个名称相同的接口，但是根据HTTP请求方法的不同（Get还是Post）会自动寻找对应的映射方法。 登录页面 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;登录&lt;/h1&gt;&lt;form method="post" action="/login"&gt; &lt;label&gt; &lt;input type="text" name="username"&gt; &lt;/label&gt; &lt;br&gt; &lt;label&gt; &lt;input type="password" name="password"&gt; &lt;/label&gt; &lt;br&gt; &lt;input type="submit" value="登录"&gt;&lt;/form&gt;&lt;div style="color: blue;" th:text="$&#123;info&#125;"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 如上，前台form表单中的action=&quot;/login&quot;和method=&quot;post&quot;决定了请求走这个地址，通过调用subject.login(token)，Shiro自动查询Realm实现，于是找到我们自定义的Realm实现：AuthRealm，进而通过SimpleAuthenticationInfo方法验证了登录用户的身份，如果身份认证成功，就return &quot;/index&quot;，否则就return &quot;/login&quot;。 参考 纯洁的微笑 - Spring Boot (十四)： Spring Boot 整合 Shiro-登录认证和权限管理 TyCoding]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合Thymeleaf]]></title>
    <url>%2F2019%2F05%2F27%2FSpring-Boot%E6%95%B4%E5%90%88Thymeleaf%2F</url>
    <content type="text"><![CDATA[Thymeleaf是一个跟freemarker等类似的模板引擎，能够替代JSP，它也是springboot的官方推荐方案。 但是我一般倾向于使用前后端分离的模式，前端使用Vus.js 等框架，这里学习Thymeleaf主要是快速实现一些网页，以便继续学习Spring Boot中需要用到网页的部分。 开始使用IDEA新建Spring Boot项目，依赖中选择 Core-Lombok，Web- web, Template Engines-Thymeleaf。 修改applicatiom.yml 1234567891011server: port: 8080spring: thymeleaf: mode: LEGACYHTML5 encoding: UTF-8 servlet: content-type: text/html suffix: .html cache: false 其中spring.thymeleaf.mode = LEGACYHTML5配置thymeleaf的模式，不要使用spring.thymeleaf.mode = HTML5，因为严格遵循HTML5规范会对非严格的报错，例如&lt;meta charset=&quot;UTF-8&quot;&gt;，&lt;meta&gt;标签没有结束&lt;meta /&gt;就会报错。 在 main/resources/templates新建index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Index&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;This is index page&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 若想要在HTML页面中使用Thymeleaf，需要&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 新建RouterController.java 1234567@Controllerpublic class RouterController &#123; @GetMapping("/index") public String index()&#123; return "index"; &#125;&#125; 这里的 return “index”中的index 是指sources/template中的 index.html文件。如果是templates/common/main.html页面，就应该return &quot;/common/main.html&quot; 浏览器访问http://localhost:8080/便可看到刚才的页面。 Thymeleaf常用表达式变量 ${user.username} 修改RouterController.java 12345678@Controllerpublic class RouterController &#123; @GetMapping("/") public String index(Model model)&#123; model.addAttribute("demo", "一个测试"); return "index"; &#125;&#125; 修改index.html 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Index&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;This is index page&lt;/h1&gt; &lt;br&gt; &lt;p&gt;表达式：&lt;span th:text="$&#123;demo&#125;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 更多Thymeleaf相关可以参考这里 参考 TyCoding]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合MyBatis-Plus]]></title>
    <url>%2F2019%2F05%2F24%2FSpring-Boot%E6%95%B4%E5%90%88MyBatis-Plus%2F</url>
    <content type="text"><![CDATA[MyBatis-Plus是MyBatis的增强工具。 介绍官网：官网 由于Mybatis plus完全基于Mybatis,且吸收了一部分HIbernate的优点,提供集成的CRUD,基本上现在开发中都使用Mybatis Plus替代原生Mybatis框架 MybatisPlus 不能和 Mybatis同时使用 使用添加依赖123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 数据数据库 Schema 脚本: 12345678910DROP TABLE IF EXISTS user;CREATE TABLE user( id BIGINT(20) NOT NULL COMMENT &apos;主键ID&apos;, name VARCHAR(30) NULL DEFAULT NULL COMMENT &apos;姓名&apos;, age INT(11) NULL DEFAULT NULL COMMENT &apos;年龄&apos;, email VARCHAR(50) NULL DEFAULT NULL COMMENT &apos;邮箱&apos;, PRIMARY KEY (id)); 其对应的数据库 Data 脚本如下： 12345678DELETE FROM user;INSERT INTO user (id, name, age, email) VALUES(1, &apos;Jone&apos;, 18, &apos;test1@baomidou.com&apos;),(2, &apos;Jack&apos;, 20, &apos;test2@baomidou.com&apos;),(3, &apos;Tom&apos;, 28, &apos;test3@baomidou.com&apos;),(4, &apos;Sandy&apos;, 21, &apos;test4@baomidou.com&apos;),(5, &apos;Billie&apos;, 24, &apos;test5@baomidou.com&apos;); 配置文件可以参考Spring-Boot整合MyBatis 12345678server: port: 8080spring: datasource: url: jdbc:mysql://localhost:3306/springboot_mybatis?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 654321 driver-class-name: com.mysql.cj.jdbc.Driver 注：这里driver-class-name使用的是com.mysql.cj.jdbc.Driver，com.mysql.cj.jdbc.Driver 是 mysql-connector-java 6中的，需要指定时区serverTimezone。 业务设置。指定mapper地址，启用分页功能。 12345678@Configuration@MapperScan("com.example.demo.mapper")public class MyBatisPlusConfig &#123; @Bean public PaginationInterceptor paginationInterceptor() &#123; return new PaginationInterceptor(); &#125;&#125; 使用lombok创建实体类。 1234567@Datapublic class User &#123; private Long id; private String name; private Integer age; private String email;&#125; 创建mapper 12public interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; 测试12345678@SpringBootTest@RunWith(SpringRunner.class)public class UserMapperTest &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private UserMapper userMapper;&#125; 查询一个和查询全部 12345678910111213@Testpublic void testSelectOne() &#123; User user = userMapper.selectById(1L); logger.info("user = &#123;&#125;", user);&#125;@Testpublic void testSelectAll() &#123; List&lt;User&gt; list = userMapper.selectList(null); list.forEach(user -&gt; &#123; logger.info("user = &#123;&#125;", user); &#125;);&#125; 分页查询 1234567891011@Testpublic void testPage()&#123; logger.info("----------分页---------"); Page&lt;User&gt; page = new Page&lt;&gt;(1,2); IPage&lt;User&gt; userIPage = userMapper.selectPage(page, new QueryWrapper&lt;User&gt;().gt("age", 6)); logger.info("总条数：&#123;&#125;", userIPage.getTotal()); logger.info("当前页数：&#123;&#125;", userIPage.getCurrent()); logger.info("当前每页显示数：&#123;&#125;", userIPage.getSize()); logger.info("----------分页---------");&#125; 更新 1234567891011@Testpublic void update() &#123; User user = userMapper.selectById(2L); assertThat(user.getAge()).isEqualTo(20); userMapper.update( null, Wrappers.&lt;User&gt;lambdaUpdate().set(User::getEmail, "123@123").eq(User::getId, 2) ); assertThat(userMapper.selectById(2).getEmail()).isEqualTo("123@123");&#125; 更多CRUD接口可以查看这里：CRUD接口 参考 官网 纯洁的微笑 - Spring Boot 2 (十一)：如何优雅的使用 MyBatis 之 MyBatis-Plus]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok安装及使用]]></title>
    <url>%2F2019%2F05%2F23%2FLombok%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[使用IDEA安装Lombok及其使用。 Lombok是什么Lombok是一个通过注解以达到减少代码的Java库,如通过注解的方式减少get,set方法,构造方法等。 官网：Project Lombok 安装首先向pom.xml中添加依赖： 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 其中 scope=provided，就说明 Lombok 只在编译阶段生效。也就是说，Lombok 会在编译期静悄悄地将带 Lombok 注解的源码文件正确编译为完整的 class 文件。 IDEA插件通过安装插件，让IDEA能够识别。安装过程可参考官网：setup - IntelliJ IDEA 使用常用注解 @var @Data @Setter @Getter @NonNull @Synchronized @ToString @Log @EqualsAndHashCode @Cleanup @SneakyThrows @var Mutably! Hassle-free local variables. 1234567891011public void test() &#123; var list = new ArrayList&lt;String&gt;(10); list.add("Hello"); list.add("Ming"); var one = list.get(0); System.out.println(one); for (var a : list) &#123; System.out.println(a); &#125;&#125; 1234567891011public void test() &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(10); list.add("Hello"); list.add("Ming"); String one = list.get(0); System.out.println(one); for (String a : list) &#123; System.out.println(a); &#125;&#125; @Data All together now: A shortcut for @ToString, @EqualsAndHashCode, @Getter on all fields, and @Setter on all non-final fields, and @RequiredArgsConstructor! 作用于类。相当于同时加上以下注解@Setter @Getter,@ToString,@EqualsAndHashCode 1234567@Datapublic class User &#123; private Long id; private String name; private String sex; private String address;&#125; @Getter/@Setter Never write public int getFoo() {return foo;} again. 作用于属性。 1234public class User &#123; @Getter@Setter private String name;&#125; 相当于 1234567891011public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; @NonNull You can use @NonNull on the parameter of a method or constructor to have lombok generate a null-check statement for you. 该注解快速判断是否为空,如果为空,则抛出java.lang.NullPointerException 官网例子： 12345678public class NonNullExample extends Something &#123; private String name; public NonNullExample(@NonNull Person person) &#123; super("Hello"); this.name = person.getName(); &#125;&#125; 1234567891011public class NonNullExample extends Something &#123; private String name; public NonNullExample(@NonNull Person person) &#123; super("Hello"); if (person == null) &#123; throw new NullPointerException("person is marked @NonNull but is null"); &#125; this.name = person.getName(); &#125;&#125; @Synchronized作用范围为方法。自动添加到同步机制,有趣的是,生成的代码锁代码块 123456private DateFormat format = new SimpleDateFormat("MM-dd-YYYY");@Synchronizedpublic String synchronizedFormat(Date date) &#123; return format.format(date);&#125; 12345678private final java.lang.Object $lock = new java.lang.Object[0];private DateFormat format = new SimpleDateFormat("MM-dd-YYYY");public String synchronizedFormat(Date date) &#123; synchronized ($lock) &#123; return format.format(date); &#125;&#125; @ToString可以进一步设置： callSuper 是否输出父类的toString方法,默认为false includeFieldNames 是否包含字段名称,默认为true exclude 排除生成tostring的字段 12345@ToString(callSuper = true, exclude = &#123;"address"&#125;)public class User &#123; private String name; private String address;&#125; @Log可以使用Log4j，Log4j2，Slf4j等。具体看官方文档 SpringBoot选用 SLF4j和logback 123456@Slf4jpublic class LogEx&#123; public void test()&#123; log.error("Error") &#125;&#125; @Cleanup用于确保已分配的资源被释放,如IO的连接关闭。 123456789public void testCleanUp() &#123; try &#123; @Cleanup ByteArrayOutputStream baos = new ByteArrayOutputStream(); baos.write(new byte[] &#123;'Y','e','s'&#125;); System.out.println(baos.toString()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 参考 官方文档：Lombok features Lombok使用详解]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合MyBatis]]></title>
    <url>%2F2019%2F05%2F21%2FSpring-Boot%E6%95%B4%E5%90%88MyBatis%2F</url>
    <content type="text"><![CDATA[整合MyBatis。 使用IDEA构建 打开IDEA，新建Spring Boot项目，依赖选择Web-web，SQL-MyBatis, SQL-JDBC,SQL-MySQL。 (暂时不用)更改pom.xml，添加PageHelper和mybatis generator依赖。在dependencies中太添加以下： 123456789101112&lt;!-- 分页插件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.10&lt;/version&gt;&lt;/dependency&gt;&lt;!-- alibaba的druid数据库连接池 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt;&lt;/dependency&gt; 在build-plugins中添加以下： 12345678910&lt;!-- mybatis generator 自动生成代码插件 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt;&lt;/plugin&gt; 在项目下新建包model，新建实体类User.java mybatis相关文件配置：在resources文件夹下新建mybatis文件夹，在mybatis文件夹下新建mybatis-config.xml作为mybatis的配置文件；再新建mapper文件夹，存放mapper文件。 使用更精简的yml替代properties配置文件：将application.properties更改为application.yml 123456789101112131415161718server: port: 8080spring: datasource: url: jdbc:mysql://localhost:3306/springboot_mybatis?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 654321 driver-class-name: com.mysql.cj.jdbc.Drivermybatis: mapper-locations: classpath:mybatis/mapper/*.xml type-aliases-package: com.example.mybatis.model configuration: # 开启获取数据库自增主键 use-generated-keys: true # 开启驼峰命名转换 map-underscore-to-camel-case: true 创建数据库 123456789DROP TABLE IF EXISTS `users`;CREATE TABLE `users` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;主键id&apos;, `userName` varchar(32) DEFAULT NULL COMMENT &apos;用户名&apos;, `passWord` varchar(32) DEFAULT NULL COMMENT &apos;密码&apos;, `user_sex` varchar(32) DEFAULT NULL, `nick_name` varchar(32) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=28 DEFAULT CHARSET=utf8; 使用XML至此的配置都是xml版本的 CRUD创建model：/model/User.java 123456public class User &#123; private Long id; private String username; private String password; private String sex;&#125; 创建interface：/mapper/UserMapper.java 1234567891011public interface UserMapper &#123; void insert(User user); void update(User user); void delete(Long id); User getById(Long id); List&lt;User&gt; getAll();&#125; 在 resources/mapper下创建 UserMapper.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.example.mybatis.mapper.UserMapper"&gt; &lt;!-- namespace xxMapper.java文件--&gt; &lt;sql id="Base_Column_List"&gt; id, username, password, sex &lt;/sql&gt; &lt;select id="getById" resultType="com.example.mybatis.model.User"&gt; SELECT &lt;include refid="Base_Column_List"/&gt; FROM users WHERE id = #&#123;id&#125; &lt;/select&gt; &lt;select id="getAll" resultType="com.example.mybatis.model.User"&gt; SELECT &lt;include refid="Base_Column_List"/&gt; FROM users &lt;/select&gt; &lt;insert id="insert" parameterType="com.example.mybatis.model.User"&gt; INSERT INTO user(username, password, sex) VALUES (#&#123;username&#125;, #&#123;password&#125;, #&#123;sex&#125;) &lt;/insert&gt; &lt;update id="update" parameterType="com.example.mybatis.model.User"&gt; UPDATE users SET &lt;if test="userName != null"&gt;username = #&#123;username&#125;,&lt;/if&gt; &lt;if test="passWord != null"&gt;password = #&#123;password&#125;,&lt;/if&gt; WHERE id = #&#123;id&#125; &lt;/update&gt; &lt;delete id="delete" parameterType="long"&gt; DELETE FROM users WHERE id = #&#123;id&#125; &lt;/delete&gt; &lt;/mapper&gt; 更改xxApplication，在项目入口添加@MapperScan(&quot;com.example.mybatis.mapper&quot;)，使其能够扫描到mapper。 测试123456789101112131415@RunWith(SpringRunner.class)@SpringBootTestpublic class UserMapperTest &#123; @Autowired private UserMapper userMapper; @Test public void insert() &#123; userMapper.insert(new User("aa", "pass1", "man")); userMapper.insert(new User("aa", "pass1", "man")); userMapper.insert(new User("aa", "pass1", "man")); assertEquals(3, userMapper.getAll().size()); &#125;&#125; 使用注解开发Mapper1234567891011121314151617181920public interface UserMapperAno &#123; @Select("SELECT * FROM users") @Results(&#123; @Result(property = "username", column = "username") &#125;) List&lt;User&gt; getAll(); @Select("SELECT * FROM users WHERE id = #&#123;id&#125;") @Results(&#123; @Result(property = "username", column = "username") &#125;) User getById(); @Insert("INSERT INTO users(username, password, sex) " + "values(#&#123;username&#125;, #&#123;password&#125;, #&#123;sex&#125;)") void insert(); @Delete("DELETE FROM users WHERE id=#&#123;id&#125;") void delete();&#125; #与$ #将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。如：order by #user_id#，如果传入的值是111,那么解析成sql时的值为order by “111”, 如果传入的值是id，则解析成的sql为order by “id”. $将传入的数据直接显示生成在sql中。如：order by $user_id$，如果传入的值是111,那么解析成sql时的值为order by user_id, 如果传入的值是id，则解析成的sql为order by id. #方式能够很大程度防止sql注入。 $方式无法防止Sql注入。 $方式一般用于传入数据库对象，例如传入表名. 一般能用#的就别用$. 测试1234567891011121314151617181920212223@SpringBootTest@RunWith(SpringRunner.class)public class UserMapperAnoTest &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private UserMapperAno userMapperAno; @Test public void getAll() &#123; List&lt;User&gt; users = userMapperAno.getAll(); users.forEach(user -&gt; logger.info("user = &#123;&#125;", user) ); &#125; @Test public void getById() &#123; User user = userMapperAno.getById(29L); logger.info("user = &#123;&#125;", user); &#125;&#125; 注解 对比 xml两种模式各有特点，注解版适合简单快速的模式，其实像现在流行的这种微服务模式，一个微服务就会对应一个自已的数据库，多表连接查询的需求会大大的降低，会越来越适合这种模式。 复杂的查询，比如Mybatis的动态SQL特性在注解中应该很难体现，而在XML中就很容易实现了。 参考 CSDN - Spring boot Mybatis 整合（完整版） Github - spring-boot-examples 纯洁的微笑 - Spring Boot(六)：如何优雅的使用 Mybatis]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Scoop管理Windows软件]]></title>
    <url>%2F2019%2F05%2F14%2F%E4%BD%BF%E7%94%A8Scoop%E7%AE%A1%E7%90%86Windows%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[体验了一下Scoop这款Windows上的软件包管理器，记录下其安装，配置过程。 安装 官方网址 快速入门 我的电脑是Windows 10 1903，满足基础环境。打开PowerShell 保证允许本地脚本运行 1set-executionpolicy remotesigned -scope currentuser 如果你不想将scoop将软件默认安装到C盘，可以自定义scoop包安装路径 12$env:SCOOP='D:\scoop'[environment]::setEnvironmentVariable('SCOOP',$env:SCOOP,'User') 安装scoop 1iex (new-object net.webclient).downloadstring('https://get.scoop.sh') 安装完成，使用 scoop help验证。出现“Usage: scoop [] Some useful commands are…”等字样说明安装成功。 之后可以使用 scoop help查看命令参考 使用安装软件：scoop install 软件名 更新：scoop update 移除所有旧版本：scoop cleanup * 卸载：scoop uninstall 软件名 软件仓库Scoop默认仓库（main bucket）是有限的，但是可以添加仓库。 最常见的bucket - extras，其包含各个版本的 Firefox、福昕阅读器、Geek Uninstaller、Inkscape、Snipaste 等等 添加：scoop bucket add extras 查找官方维护的仓库：scoop bucket known 关于更多Scoop仓库的信息，可以参考少数派这篇文章 参考 少数派 - 「一行代码」搞定软件安装卸载，用 Scoop 管理你的 Windows 软件 Windows | Scoop软件包管理神器 少数派 - 给 Scoop 加上这些软件仓库，让它变成强大的 Windows 软件管理器]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合Redis]]></title>
    <url>%2F2019%2F05%2F12%2FSpring-Boot%E6%95%B4%E5%90%88Redis%2F</url>
    <content type="text"><![CDATA[Spring Boot整合Redis 建立项目 使用IDEA新建Spring Boot项目，依赖选择 web-web，NoSQL-redis。 application.properties 123456789101112131415161718192021## Spring Boot启动端口号server.port=8080# Redis服务器地址spring.redis.host=149.129.78.187# Redis端口spring.redis.port=6379# Redis密码spring.redis.password=# Redis数据库索引spring.redis.database=0# 连接池最大连接数spring.redis.jedis.pool.max-active=8# 连接池最大阻塞等待时间 负值没有限制spring.redis.jedis.pool.max-wait=-1# 连接池最大空闲连接spring.redis.jedis.pool.max-idle=8# 最小空闲连接spring.redis.jedis.pool.min-idle=0# 连接超时时间spring.redis.timeout=100 测试用例 12345678910111213@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoApplicationTests &#123; @Autowired private StringRedisTemplate redisTemplate; @Test public void test() throws Exception&#123; redisTemplate.opsForValue().set("a", "aaa"); Assert.assertEquals("aaa", redisTemplate.opsForValue().get("a")); &#125;&#125; 简单的测试与Redis的连接，使用自动配置的StringRedisTemplate对象进行Redis的读写操作 参考 掘金-SpringBoot整合Redis Spring Boot 使用NoSQL数据库 Redis]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA构建第一个Spring Boot项目]]></title>
    <url>%2F2019%2F05%2F12%2FIDEA%E6%9E%84%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AASpring-Boot%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[使用IDEA快速构建一个Spring Boot项目，并将其打包成jar文件。 HelloWorld实战 新建项目。IDEA中选择Spring Initializ，填写Group等信息。选择依赖，选择web-web，finnish完成项目创建。 项目结构说明： xxxApplication：main()方法，用于启动 xxxApplicationTests：空的Junit测试 application.properties：空文件，用于配置属性 pom.xml：Maven构建说明文件 Controller。新建controller包，并新建HelloWorldController.java文件，代码如下： 12345678@RestControllerpublic class HelloWorldController &#123; @RequestMapping("/") public String hello()&#123; return "Hello World"; &#125;&#125; @RestController和@RequestMapping注解是来自SpringMVC的注解，它们不是SpringBoot的特定部分。 @RestController：提供实现REST API可以服务JSON,XML或者其他。这里是以String的形式渲染出结果。它是 @Controller 和 @ResponseBody 注解的合体版 @RequestMapping：提供路由信息，”/“路径的HTTP Request都会被映射到hello方法进行处理。 启动应用。浏览器访问http://localhost:8080/，浏览器输出 “Hello World” 测试类。 1234567public class HelloWorldControllerTest &#123; @Test public void hello() &#123; assertEquals("Hello World", new HelloWorldController().hello()); &#125;&#125; 打包 在pom.xml中添加&lt;packaging&gt;jar&lt;/packaging&gt;，指定打成的包为jar。 整个pom.xml文件为 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.demo&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 与 pom.xml文件同级运行 mvn clean package，首先要确保Maven正确安装。打包成功后，在项目目录下target文件夹中生成jar 进入target文件夹，使用java -jar jar包名称即可运行Spring Boot项目 参考 Spring Boot 之 HelloWorld详解 SpringBoot简单打包部署(附工程)]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis设计与实现-笔记]]></title>
    <url>%2F2019%2F05%2F09%2FRedis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[《Redis设计与实现》读书笔记，和其他资料， Redis使用场景计数器对String进行自增自减。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 查找表例如 DNS 记录就很适合使用 Redis 进行存储。 查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 消息队列List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息 不过最好使用 Kafka、RabbitMQ 等消息中间件。 实时消息系统通过发布与订阅实现 其他Set 可以实现交集、并集等操作，从而实现共同好友等功能。 ZSet 可以实现有序性操作，从而实现排行榜等功能。 简单动态字符串相比于C字符串，SDS的优点： O(1)时间复杂度获取字符串长度 杜绝缓冲区溢出 减少修改字符串长度时所需的内存重新分配次数。 空间预分配。 惰性空间释放。 二进制安全。 兼容部分C字符串函数。 链表 Redis的链表是双端链表，是无环链表。每个节点都有一个前指针和后指针。 Redis中的链表实现了很多功能，如列表键，发布与订阅，慢查询，监视器等。 字典 字典用于：数据库和哈希键等。 使用哈希表作为字典的底层实现，每个字典两个哈希表，一个平时使用，另一个在rehash是使用。 哈希表使用渐进式rehash进行扩容或收操作。 哈希表使用链地址法解决哈希冲突。同一个索引上的多个键值连接成一个单向链表。（类似Java中HashMap解决哈希冲突） 备注：常用四种解决哈希冲突方法：开放定址法，链地址法，再哈希，建立公共溢出区。 跳跃表 跳跃表是有序集合的底层实现之一 每个跳跃表节点的层高都是1至32之间的随机数。 同一个跳跃表中，多个节点可以有相同的分值，成员对象必须是唯一的。 跳跃表中节点按分值大小排序，分值相同，节点按照成员对象大小排序。 与红黑树相比，跳跃表的优点： 实现简单 插入速度快速，不需要进行旋转 支持无锁操作。31 整数集合 是集合键的底层实现之一 底层为数组，有序，无重复的保存集合元素，有需要时，会根据新添加元素的类型，改变数组的类型。 升级好处：提升灵活性（不必担心类型错误），节约内存。 只支持升级，不支持降级。 压缩列表 为节约内存而开发的顺序型数据结构 列表建和哈希键的底层实现之一 添加新节点，或者删除新节点，可能引发连锁更新（每个节点previous_entry_length更新），但出现几率不高。 可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 对象 数据库中每个键值对的键和值都是一个对象。 Redis共享值为0-9999的字符串对象。 字符串对象编码：int, raw, embstr long类型的整数—int long double类型的浮点数 — embstr或raw 字符串值或长度大的long类型 — embstr或raw。 embstr编码的对象被修改时总会变成raw编码。 列表对象编码：ziplist或linkedlist(底层使用双端列表) 使用ziplist编码的条件：列表对象所有字符串长度都不小于64字节。列表对象保存的元素数量小于512个。 哈希对象编码：ziplist（底层压缩列表）或hashtable（字典） 集合对象编码：intset(底层整数集合)或hashtable(底层字典) 有序集合对象编码：ziplist 或 skiplist 内存回收使用引用计数实现内存回收机制。对象不再被使用时就回收。 对象的生命周期：创建对象，操作对象，释放对象。 对象共享通过对象的引用计数属性实现。 多个键共享一个值对象： 数据库键的值指向一个现有值对象 被共享的值对象引用计数增一。 Redis在初始化时，创建一万个字符串对象(0 - 9999的整数值)。用到时，服务器共享这些对象。 持久化RDB持久化 将某个时间点的所有数据都存放到硬盘上。保存数据库中的键值对 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。 如果系统发生故障，将会丢失最后一次创建快照之后的数据。 如果数据量很大，保存快照的时间会很长。 两种生成RDB文件的命令：SAVE, BGSAVE SAVE命令由服务器进程执行操作，会阻塞服务器。BGSAVE命令由子进程执行，不会阻塞服务器。 RDB文件是一个经过压缩的文件 如果开启了AOF持久化，会首先使用AOF文件 AOF持久化 通过保存Redis服务器所执行的写命令记录数据库状态 AOF文件所有命令都以Redis命令请求协议格式保存。 appendfsync选项对AOF持久化功能的安全性和Redis服务器的性能有很大影响。 服务器载入并执行AOF文件中的命令还原数据库。 AOF重写产生性的AOF文件，保存状态一样，体积更小 AOF重写通过读取数据库中的键值对实现， 使用 BGREWRITEAOF命令，完成AOF文件重写。 对比Memchached两者都属于内存 键值关系型数据库。 数据类型Redis支持五中数据类型，Memchached仅支持字符串类型。 持久化Redis支持AOF日志和RDB快照两种持久化策略，memchached不支持。 分布式Redis Cluster实现分布式支持。Memchached不支持。 内存管理在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。 Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。 事务 Redis中的事务具有ACID的特性 多个命令进入到事务队列中，按照FIFO顺序执行。 参考 黄健宏. Redis 设计与实现 [M]. 机械工业出版社, 2014. CS-Notes - Redis]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis常用命令学习]]></title>
    <url>%2F2019%2F04%2F27%2FRedis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[学习Redis常用命令 StringSET set key value [expiration EX seconds|PX milliseconds][NX|XX] 将字符串值 value 关联到 key 。如果 key 已经持有其他值， SET 就覆写旧值， 无视类型。当 SET 命令对一个带有生存时间（TTL）的键进行设置之后， 该键原有的 TTL 将被清除。 从 Redis 2.6.12 版本开始， SET 命令只在设置操作成功完成时才返回 OK ； 如果命令使用了 NX或者 XX 选项， 但是因为条件没达到而造成设置操作未执行， 那么命令将返回空批量回复（NULL Bulk Reply）。 SET key “value”GET key SET key “value” EX seconds：将键的过期时间设置为 seconds 秒。 执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value 。 SET key “value” NX：只在键不存在时， 才对键进行设置操作。 执行 SET key value NX 的效果等同于执行 SETNX key value 。 SET key “value” XX：只在键已经存在时， 才对键进行设置操作。 GET返回与键 key 相关联的字符串值。 GETSET将键 key 的值设为 value ， 并返回键 key 在被设置之前的旧值。 键 key 在被设置之前并不存在， 那么命令返回 nil 。 STRLEN key返回键 key 储存的字符串值的长度。当键 key 不存在时， 命令返回 0 。 APPEND如果键 key 已经存在并且它的值是一个字符串， APPEND 命令将把 value 追加到键 key 现有值的末尾。如果 key 不存在， APPEND 就简单地将键 key 的值设为 value ， 就像执行 SET key value 一样。 SETRANGE SETRANGE key offset value 从偏移量 offset 开始， 用 value 参数覆写(overwrite)键 key 储存的字符串值。不存在的键 key 当作空白字符串处理。 GETRANGE GETRANGE key start end 返回键 key 储存的字符串值的指定部分， 字符串的截取范围由 start 和 end 两个偏移量决定 (包括 start 和 end 在内)。 INCR为键 key 储存的数字值加上一。如果键 key 不存在， 那么它的值会先被初始化为 0 ， 然后再执行 INCR 命令。如果键 key 储存的值不能被解释为数字， 那么 INCR 命令将返回一个错误。 INCRBY INCRBY key increment 为键 key 储存的数字值加上增量 increment 。如果键 key 不存在， 那么键 key 的值会先被初始化为 0 ， 然后再执行 INCRBY 命令。 ListLPUSH LPUSH key value 将一个或多个值 value 插入到列表 key 的表头。如果有多个 value 值，那么各个 value 值按从左到右的顺序依次插入到表头： 比如说，对空列表 mylist 执行命令 LPUSH mylist a b c ，列表的值将是 c b a ，这等同于原子性地执行 LPUSH mylist a 、 LPUSH mylist b 和 LPUSH mylist c 三个命令。 LPUSHX LPUSHX key value 将值 value 插入到列表 key 的表头，当且仅当 key 存在并且是一个列表。 和 LPUSH key value [value …] 命令相反，当 key 不存在时， LPUSHX 命令什么也不做。 RPUSH RPUSH key value [value …] LPOP LPOP key 移除并返回列表 key的头元素 RPOPRPOPLPUSH RPOPLPUSH source destination 执行两个动作：1. 将列表source中的最后一个元素弹出并返回给客户端 2. source弹出的元素插入destination，作为destination的头元素。 如果 source 和 destination 相同，则列表中的表尾元素被移动到表头，并返回该元素，可以把这种特殊情况视作列表的旋转(rotation)操作。 LREM LREM key count value 根据count 的值，移除列表中与 value相等的元素 count &gt; 0 : 从表头开始向表尾搜索，移除与 value 相等的元素，数量为 count 。 count &lt; 0 : 从表尾开始向表头搜索，移除与 value 相等的元素，数量为 count 的绝对值。` count = 0 : 移除表中所有与 value 相等的值。 LLEN LLEN key 返回key的长度 LINDEX key index返回列表中，下表为index的元素。0表示第一个元素，-1表示倒数第一个，-2 表示倒数第二个。越界返回nil. LINSERT key BEFORE|AFTER pivot value将值 value 插入到列表 key 当中，位于值 pivot 之前或之后。当 pivot 不存在于列表 key 时，不执行任何操作。当 key 不存在时， key 被视为空列表，不执行任何操作。 LSET key index value将列表 key 下标为 index 的元素的值设置为 value LRANGE key start stop返回列表 key 中指定区间内的元素，区间以偏移量 start 和 stop 指定。 stop 下标也在 LRANGE 命令的取值范围之内(闭区间) 超出范围的下标值不会引起错误。 如果 start 下标比列表的最大下标 end ( LLEN list 减去 1 )还要大，那么 LRANGE 返回一个空列表。 如果 stop 下标比 end 下标还要大，Redis将 stop 的值设置为 end 。 查看key中的所有元素：LRANGE key 0 -1 LTRIM key start stop对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 HashHSET hash field value将哈希表 hash 中域 field 的值设置为 value 。 如果给定的哈希表并不存在， 那么一个新的哈希表将被创建并执行 HSET 操作。 如果域 field 已经存在于哈希表中， 那么它的旧值将被新值 value 覆盖。 HSETNX hash field value当且仅当域 field 尚未存在于哈希表的情况下， 将它的值设置为 value 。 如果给定域已经存在于哈希表当中， 那么命令将放弃执行设置操作。 如果哈希表 hash 不存在， 那么一个新的哈希表将被创建并执行 HSETNX 命令。 HGET hash field返回哈希表中给定域的值 HEXISTS hash field检查field是否存在于hash中，存在返回1，否则0 HDEL key field [field …]删除 HLEN keyHSTRLEN key field返回哈希表 key 中， 与给定域 field 相关联的值的字符串长度（string length）。 HINCRBY key field increment哈希表 key 中的域 field 的值加上增量 increment 。 增量也可以为负数，相当于对给定域进行减法操作。 如果 key 不存在，一个新的哈希表被创建并执行 HINCRBY 命令。 如果域 field 不存在，那么在执行命令前，域的值被初始化为 0 。 HINCRBYFLOAT key field increment为哈希表 key 中的域 field 加上浮点数增量 increment 。 HMSET key field value [field value …]同时将多个field-value 设置到哈希表中 HMGET key field [field …]返回哈希表中，一个或多个给定的值 HKEYS key返回哈希表 key 中的所有域。 HVALS key返回哈希表 key 中所有域的值。 HGETALL key返回哈希表中，所有的域和值，以列表形式。在返回值里，紧跟每个域名(field name)之后是域的值(value)，所以返回值的长度是哈希表大小的两倍。 SetsSADD key member [member …]将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略。 SISMEMBER key member判断 member 元素是否集合 key 的成员。是，返回1，不是或key不存在，0. SPOP key移除并返回集合中的一个随机元素。 SRANDMEMBER key [count]如果命令执行时，只提供了 key 参数，那么返回集合中的一个随机元素。 如果 count 为正数，且小于集合基数，那么命令返回一个包含 count 个元素的数组，数组中的元素各不相同。如果 count 大于等于集合基数，那么返回整个集合。 如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count 的绝对值。 SREM key member移除key中的一个或多个元素，不存在的将被忽略 SMOVE source destination member将 member 元素从 source 集合移动到 destination 集合。 SMOVE 是原子性操作。 SCARD key返回集合元素数量。key不存在，返回0. SMEMBERS key返回集合 key 中的所有成员。不存在的 key 被视为空集合。 SINTER key [key …]返回所有集合的交集成员。 SINTERSTORE destination key [key …]这个命令类似于 SINTER key [key …] 命令，但它将结果保存到 destination 集合，而不是简单地返回结果集。 destination 可以是 key 本身。 SUNION key [key …]返回一个集合的全部成员，该集合是所有给定集合的并集。 SUNIONSTORE destination key [key …]SDIFF返回多个集合的差集 SDIFFSTORE destination key [key …]这个命令的作用和 SDIFF key [key …] 类似，但它将结果保存到 destination 集合，而不是简单地返回结果集。 Sorted SetsZADD key score member [[score member][score member] …]将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 如果某个 member 已经是有序集的成员，那么更新这个 member 的 score 值，并通过重新插入这个 member 元素，来保证该 member 在正确的位置上。 score 值可以是整数值或双精度浮点数。 ZSCORE key member返回有序集 key 中，成员 member 的 score 值。 ZINCRBY key increment member为有序集 key 的成员 member 的 score 值加上增量 increment 。 可以通过传递一个负数值 increment ，让 score 减去相应的值，比如 ZINCRBY key -5 member ，就是让 member 的 score 值减去 5 。 当 key 不存在，或 member 不是 key 的成员时， ZINCRBY key increment member 等同于 ZADD key increment member 。 ZCARD key返回key的长度 ZCOUNT key min max返回key中score在[min … max]中成员的数量 ZRANGE key start stop [WITHSCORES]返回key中，指定区间内的成员，成员位置按照score值递增排序；相同score的成员按照字典顺序。 如果你需要成员按 score 值递减(从大到小)来排列，请使用 ZREVRANGE key start stop WITHSCORES] 命令。 ZREVRANGE key start stop [WITHSCORES]和ZRANGE 类似，只不过排序规则变为递减。 ZRANGEBYSCORE key min max [WITHSCORES][LIMIT offset count]返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 ZREVRANGEBYSCORE key min max [WITHSCORES][LIMIT offset count]ZRANKZRANK key member 返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。排名以 0 为底，也就是说， score 值最小的成员排名为 0 。 ZREVRANK ZREVRANK key member 逆序 ZREM ZREM key member 移除。 返回移除成功的数量。 ZREMRANGEBYRANK ZREMRANGEBYRANK key start stop 移除有序集 key 中，指定排名(rank)区间内的所有成员。 ZREMRANGEBYSCORE ZREMRANGEBYSCORE key min max 移除score在[min … max]之间的所有成员 ZRANGEBYLEX ZRANGEBYLEX key min max [LIMIT offset count] 返回给定的有序集合键 key 中， 值介于 min 和 max 之间的成员。 合法的 min 和 max 参数必须包含 ( 或者 [ ， 其中 ( 表示开区间（指定的值不会被包含在范围之内）， 而 [ 则表示闭区间（指定的值会被包含在范围之内）。 ZRANGEBYLEX myset [a [d 返回member中值在 a和d之间（包含）的成员。 特殊值 + 和 - 在 min 参数以及 max 参数中具有特殊的意义， 其中 + 表示正无限， 而 - 表示负无限。 因此， 向一个所有成员的分值都相同的有序集合发送命令 ZRANGEBYLEX &lt;zset&gt; - + ， 命令将返回有序集合中的所有元素。 ZLEXCOUNT ZLEXCOUNT key min max 与ZRANGEBYLEX类似，不过是返回数量。 ZREMRANGEBYLEX ZREMRANGEBYLEX key min max 对于一个所有成员的分值都相同的有序集合键 key 来说， 这个命令会移除该集合中， 成员介于 min 和 max 范围内的所有元素。 DBEXISTS key检查key是否存在 TYPE keykey的存储值的类型 RENAME key newkeykey改名为newkey RENAMENXMOVE key db将当前数据库的 key 移动到给定的数据库 db 当中。 redis默认使用数据库 0 DEL key [key …]删除一个或多个key RANDOMKEY从当前数据库随机返回一个key DBSIZE返回当前数据库的key 的数量。 KEYS pattern查找所有符合给定模式 pattern 的 key ， 比如说： KEYS * 匹配数据库中所有 key 。 KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。 KEYS h*llo 匹配 hllo 和 heeeeello 等。 KEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hillo 。 SCANredisdoc - SCNA SORTredisdoc - sort FLUSHDB清空当前数据库。总是返回OK FLUSHALL清空整个Redis SELECT index切换到指定数据库 OBJECT ENCODING查看一个数据库键的值对象编码。 自动过期EXPIRE EXPIRE key seconds 为给定 key 设置生存时间(单位：秒)，当 key 过期时(生存时间为 0 )，它会被自动删除。 可以对一个已经带有生存时间的 key 执行 EXPIRE 命令，新指定的生存时间会取代旧的生存时间。 PEXPIRE PEXPIRE key milliseconds 毫秒为单位 EXPIREAT EXPIREAT key timestamp 秒数时间戳 PEXPIREAT PEXPIREAT key milliseconds-timestamp PERSIST PERSIST key 移除key 的生存时间 TTL key以秒为单位返回剩余生存时间 持久化SAVESAVE 命令执行一个同步保存操作，将当前 Redis 实例的所有数据快照(snapshot)以 RDB 文件的形式保存到硬盘。 SAVE会阻塞所有客户端。 BGSAVE在后台异步(Asynchronously)保存当前数据库的数据到磁盘。 BGSAVE 命令执行之后立即返回 OK ，然后 Redis fork 出一个新子进程，原来的 Redis 进程(父进程)继续处理客户端请求，而子进程则负责将数据保存到磁盘，然后退出。 BGREWRITEAOF执行一个 AOF文件 重写操作。重写会创建一个当前 AOF 文件的体积优化版本。 发布与订阅PUBLISH PUBLISH channel message 将信息 message 发送到指定的频道 channel 。返回接收到消息 message 的订阅者数量 SUBSCRIBE SUBSCRIBE channel [channel …] 订阅给定的一个或多个频道的信息。 事务MULTI标记一个事务块的开始。 事务块内的多条命令会按照先后顺序被放进一个队列当中，最后由 EXEC 命令原子性(atomic)地执行。 EXEC执行所有事务块内的命令。 DISCARD取消事务 WATCH监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 参考 redisdoc redis-commands]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-结构型]]></title>
    <url>%2F2019%2F04%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[设计模式中结构型模式。结构型模式旨在通过改变代码结构来达到解耦的目的，使得我们的代码容易维护和扩展。 主要包括代理模式（Proxy Pattern），适配器模式（Adapter Pattern），桥接（Bridge），装饰器模式（Decorator Pattern），外观模式（Facade Pattern），组合模式（Composite Pattern），享元模式。 1. 代理模式（Proxy Pattern）代理模式（Proxy Pattern）中，一个类代表另一个类的功能。 Spring框架的AOP就是代理模式的体现。 意图：为其他对象提供一种代理以控制对这个对象的访问。 1234567891011121314151617181920212223242526272829303132public interface FoodService&#123; Food makeChicken(); Food makeNoodle();&#125;public class FoodServiceImpl implements FoodService&#123; public Food makechicken()&#123; Food f = new Chicken(); f.setChicken("aa"); f.setSpicy("bb"); return f; &#125; public Food makeNoodle()&#123; Food f = new Noodle(); f.setNoodle("aa"); f.setSalt("bb"); return f; &#125;&#125;public class FoodServiceProxy implements FoodService&#123; private FoodService foodService = new FoodServiceImpl(); public Food makeChicken()&#123; // 制作chicken Food food = foodService.makeChicken(); // chicken制作完成 food.addCondiment("add"); return food; &#125;&#125; 代理模式说白了就是做 “方法包装” 或做 “方法增强”。AOP 中，其实就是动态代理的过程。比如 Spring 中，我们自己不定义代理类，但是 Spring 会帮我们动态来定义代理，然后把我们定义在 @Before、@After、@Around 中的代码逻辑动态添加到代理中。 JDK java.util.Arrays#asList() java.util.Collections#list() java.util.Collections#enumeration() javax.xml.bind.annotation.adapters.XMLAdapter 2. 适配器模式（Adapter Pattern）适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。 123456789101112131415161718public interface Duck &#123; public void quack();// 鸭叫 public void fly();&#125;public interface Cock &#123; public void gobble();// 鸡叫 public void fly();&#125;public class WildCock implements Cock&#123; public void gobble()&#123; System.out.println("鸡叫");; &#125; public void fly()&#123; System.out.println("鸡飞"); &#125;&#125; 使用适配器模式，让鸭实现鸡叫 123456789101112public class CockAdapter implements Duck&#123; Cock cock; public CockAdapter(Cock cock) &#123; this.cock = cock; &#125; @Override public void quack()&#123; // 鸡叫 cock.gobble(); &#125;&#125; 3. 桥梁模式（Bridge）桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。 首先定义桥梁，接口，定义提供的接口方法 123public interface DrawApi&#123; public void draw(int radius, int x, int y);&#125; 实现类 123456789101112public class RedPen implements DrawApi&#123; @Override public void draw(int radius, int x, int y)&#123; System.out.println("用红色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125;public class GreenPen implements DrawAPI &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用绿色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125; 定义抽象类 12345678public abstract class Shape &#123; protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI)&#123; this.drawAPI = drawAPI; &#125; public abstract void draw(); &#125; 1234567891011121314// 长方形public class Rectangle extends Shape &#123; private int x; private int y; public Rectangle(int x, int y, DrawAPI drawAPI) &#123; super(drawAPI); this.x = x; this.y = y; &#125; public void draw() &#123; drawAPI.draw(0, x, y); &#125;&#125; 1234public static void main(String[] args) &#123; Shape redRectangle = new Rectangle(4, 8, new RedPen()); redRectangle.draw();&#125; JDK AWT JDBC 4. 装饰模式（Decorator Pattern）装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。 意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 1234567/** * 定义基本饮料类 */public abstract class Beverage&#123; public abstract String getDesc(); public abstract double price();&#125; 添加三个饮料实现红茶， 绿茶 1234567891011121314151617181920212223public class BlackTea extends Beverage&#123; @Override public String getDesc() &#123; return "红茶"; &#125; @Override public double price() &#123; return 11; &#125;&#125;public class GreenTea extends Beverage&#123; @Override public String getDesc() &#123; return "绿茶"; &#125; @Override public double price() &#123; return 22; &#125;&#125; 调料，即装饰器的基类，继承自Beverage 1234// 调料public abstract class Condiment extends Beverage&#123; &#125; 定义具体调料 12345678910111213141516171819202122232425262728public class Lemon extends Condiment&#123; // private Beverage beverage; // 传入具体饮料 public Lemon(Beverage beverage)&#123; this.beverage = beverage; &#125; @Override public String getDesc() &#123; // 装饰 return beverage.getDesc() + " 加柠檬"; &#125;&#125;public class Mango extends Condiment &#123; private Beverage bevarage; public Mango(Beverage bevarage) &#123; this.bevarage = bevarage; &#125; public String getDescription() &#123; return bevarage.getDescription() + ", 加芒果"; &#125; public double cost() &#123; return beverage.cost() + 3; // 加芒果需要 3 元 &#125;&#125; 客户端 12345678910public static void main(String[] args) &#123; // 首先，我们需要一个基础饮料，红茶、绿茶或咖啡 Beverage beverage = new GreenTea(); // 开始装饰 beverage = new Lemon(beverage); // 先加一份柠檬 beverage = new Mongo(beverage); // 再加一份芒果 System.out.println(beverage.getDescription() + " 价格：￥" + beverage.cost()); //"绿茶, 加柠檬, 加芒果 价格：￥16"&#125; JDK java.io.BufferedInputStream(InputStream) java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap 5. 外观模式（Facade Pattern）外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。 意图：为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 创建接口，和实现类 123456789101112131415161718public interface Shape&#123; void draw();&#125;public class Circle implements Shape&#123; @Override public void draw()&#123; System.out.println("Circle draw"); &#125;&#125;public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println("Square::draw()"); &#125;&#125; 创建外观类 12345678910111213141516public class ShapeMaker&#123; private Shape circle; private Shape square; public ShapeMaker() &#123; circle = new Circle(); square = new Square(); &#125; public void drawCircle()&#123; circle.draw(); &#125; public void drawSquare()&#123; square.draw(); &#125;&#125; 客户端 123456public static void main(String[] args) &#123; ShapeMaker shapeMaker = new ShapeMaker(); shapeMaker.drawCircle(); shapeMaker.drawSquare(); &#125; 6. 组合模式（Composite Pattern）组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。 1234567891011121314151617181920212223242526272829public class Employee &#123; private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; // 下属 public Employee(String name,String dept, int sal) &#123; this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); &#125; public void add(Employee e) &#123; subordinates.add(e); &#125; public void remove(Employee e) &#123; subordinates.remove(e); &#125; public List&lt;Employee&gt; getSubordinates()&#123; return subordinates; &#125; public String toString()&#123; return ("Employee :[ Name : " + name + ", dept : " + dept + ", salary :" + salary+" ]"); &#125; &#125; JDK javax.swing.JComponent#add(Component) java.awt.Container#add(Component) java.util.Map#putAll(Map) java.util.List#addAll(Collection) java.util.Set#addAll(Collection) 7. 享元模式JDKJava 利用缓存来加速大量小对象的访问时间。 java.lang.Integer#valueOf(int) java.lang.Boolean#valueOf(boolean) java.lang.Byte#valueOf(byte) java.lang.Character#valueOf(char) 参考 Javadoop - 设计模式也可以这么简单 CS-Notes - 设计模式 菜鸟教程 - 设计模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-创建型]]></title>
    <url>%2F2019%2F04%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[设计模式中的创建型模式。创建型模式的作用就是创建对象，说到创建一个对象，最熟悉的就是 new 一个对象，然后 set 相关属性。但是，在很多场景下，我们需要给客户端提供更加友好的创建对象的方式，尤其是那种我们定义了类，但是需要提供给其他开发者用的时候。包括单例，简单工厂，工厂方法，抽象工厂，生成器，原型模式。 1. 单例模式（重要）为了保证全局使用的是同一对象，一方面是安全性考虑，一方面是为了节省资源。 使用一个私有构造函数，一个私有静态变量，一个公有静态变量来实现。 构造方法声明为private,使得无法从外部类来实例化对象，然后在类内部的方法中返回实例化的单一对象。 1. 饿汉模式12345678910public class Singleton &#123; // new Singleton() 堵死 private Singleton() &#123;&#125;; // 私有静态实例，该类第一次使用进行创建 private static Singleton instance = new Singleton(); public static Singleton getInstance() &#123; return instance; &#125;&#125; 在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。一般情况下使用。 2. 懒汉模式(线程不安全)123456789101112public class Singleton &#123; private Singleton() &#123; &#125; private static Singleton instance; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 使用了懒加载模式，但是却存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例 3. 懒汉模式 （线程安全）123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance;&#125; 使用 synchronized,每次调用getInstance方法时都需要进行同步，造成不必要的同步开销， 4. 双重检查模式（DCL）1234567891011121314public class Singleton &#123; private Singleton()&#123;&#125; private volatile static Singleton instance; public static Singleton getInstance()&#123; if(instance == null)&#123; synchronized (Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 双重检验锁模式（double checked locking pattern），两次检验instance是否为null。 5. 嵌套类类单例模式（推荐）1234567891011public class Singleton &#123; private Singleton() &#123;&#125; private static class SingletonHolder &#123; private static final Singleton INSTANCEE = new Singleton(); &#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCEE; &#125;&#125; Singleton类被加载时，静态内部类SingletonHolder没有被加载进内存，只有当调用getInstance()方法，触发SingletonHolder.INSTANCEE，SingletonHolder才被加载，此时初始化INSTANCE实例，且JVM确保INSTANCE只实例化一次。使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。 6. 枚举类（最佳）123public enum EasySingleton&#123; INSTANCE;&#125; 实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。 总结一般情况下使用第一种 饿汉模式，明确要求要懒加载（lazy initialization），使用第五种静态内部类。涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。 2. 简单工厂模式简单工厂模式通常就是这样，一个工厂类 XxxFactory，里面有一个静态方法，根据我们不同的参数，返回不同的派生自同一个父类（或实现同一接口）的实例对象。 12345678910public class SimpleFactory &#123; public Product createProduct(int type)&#123; if(type == 1)&#123; return new ConcreteProduct1(); &#125; else if(type == 2)&#123; return new ConcreteProduct2(); &#125; return new ConcreteProduct(); &#125;&#125; 3. 工厂模式（重要）意图：定义了一个创建对象的接口，但由子类决定要实例化哪个类。工厂方法把实例化操作推迟到子类。 简单工厂中，创建对象的是另一个类，而在工厂方法中，是由子类来创建对象。 Spring中的IOC就用到了工厂模式。 1234567891011121314151617181920212223public interface FoodFactory&#123; Food makeFood(String name);&#125;public class ChineseFoodFactory implements FoodFactory&#123; @Override public Food makeFood(String name)&#123; if (name.equals("A")) &#123; return new ChineseFoodA(); &#125; else if (name.equals("B")) &#123; return new ChineseFoodB(); &#125; else &#123; return null; &#125; &#125;&#125;public class AmericaFoodFactory implements FoodFactory&#123; @Override public Food makeFood(String name)&#123; return new AmericaFood(name); &#125;&#125; 调用 12345678public class App&#123; public static void main(String[] args)&#123; // 选择具体工厂 FoodFactory fac = new ChineseFoodFactory(); // 由工厂生产对象 Food food = fac.makeFood("A"); &#125;&#125; 4. 抽象工厂模式意图：提供一个接口，用于创建 相关的对象家族 。主要解决接口选择问题。 12345678public static void main(String[] args)&#123; // 建造大厂 ComputerFactory cf = new AmdFactory(); Cpu cpu = cf.makeCpu(); Disk disk = cf.makeDisk(); // 组装 Computer res = new Computer(cpu, disk);&#125; 5. 建造者模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class User &#123; private String name; private String pass; private String nickName; private int age; private User(String name, String pass, String nickName, int age) &#123; this.name = name; this.pass = pass; this.nickName = nickName; this.age = age; &#125; // 静态方法，生成一个Builder public static UserBuilder builder() &#123; return new UserBuilder(); &#125; public static class UserBuilder &#123; // 下面是和 User 一模一样的一堆属性 private String name; private String pass; private String nickName; private int age; private UserBuilder() &#123; &#125; // 链式调用各个属性值，返回UserBuilder public UserBuilder name(String name) &#123; this.name = name; return this; &#125; public UserBuilder pass(String pass) &#123; this.pass = pass; return this; &#125; public UserBuilder nickName(String nickName) &#123; this.nickName = nickName; return this; &#125; public UserBuilder age(int age) &#123; this.age = age; return this; &#125; // build() 方法负责将 UserBuilder 中设置好的属性“复制”到 User 中。 public User build() &#123; return new User(name, pass, nickName, age); &#125; &#125;&#125; 6. 原型模式意图：原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。 123public abstract class Prototype&#123; abstract Prototype myClone();&#125; 1234567891011public class ConcretePrototype extends Prototype&#123; String filed; public ConcretePrototype(Stirng filed)&#123; this.filed = filed; &#125; @Override Prototype myClone() &#123; return new ConcretePrototype(filed); &#125;&#125; Object 类中有一个 clone() 方法，它用于生成一个新的对象，java 要求我们的类必须先实现 Cloneable 接口，此接口没有定义任何方法，但是不这么做的话，在 clone() 的时候，会抛出 CloneNotSupportedException 异常。 java 的克隆是浅克隆，碰到对象引用的时候，克隆出来的对象和原对象中的引用将指向同一个对象。通常实现深克隆的方法是将对象进行序列化，然后再进行反序列化。 参考 Javadoop - 设计模式也可以这么简单 CS-Notes - 设计模式 设计模式（二）单例模式的七种写法 菜鸟教程-单例模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序]]></title>
    <url>%2F2019%2F04%2F11%2F%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[整理常用排序算法。 约定将排序代码放在 sort()方法中。待排序元素实现Comparable接口。 12345678910111213141516171819202122232425public abstract class BaseSort&lt;T extends Comparable&lt;T&gt;&gt; &#123; /** * 排序代码 * * @param array 排序数组 */ public abstract void sort(T[] array); /** * 判断前一个元素是否小于后一个元素 */ protected boolean less(T a, T b) &#123; return a.compareTo(b) &lt; 0; &#125; /** * 交换数组中两个元素 */ protected void swap(T[] nums, int i, int j) &#123; T temp = nums[i]; nums[i] = nums[j]; nums[j] = nums[i]; &#125;&#125; 选择排序描述首先找到数组中最小的那个元素，然后将它和数组中第一个元素交换位置（第一个元素就是最小元素就和自己交换）。之后在剩下的元素中找到最小元素，将它和数组第二位置元素交换位置。知道整个数组有序。它在不断选在剩余元素中的最小者。 选择排序需要 N^2 / 2次比较和 N 次交换。它的运行时间和输入无关。数据移动是最少的。 该算法将第 i 小的元素放在第 i 个位置，i左边的元素不会再被访问。 时间复杂度：O(N^2)。空间复杂度O(1)。排序稳定。 动图 代码1234567891011121314public class Selection&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] array) &#123; int len = array.length; for (int i = 0; i &lt; len; i++) &#123; for (int j = i + 1; j &lt; len; j++) &#123; int min = i; if (less(array[j], array[min])) min = j; swap(array, i, min); &#125; &#125; &#125;&#125; 插入排序描述从第一个元素开始，该元素认为被已排序，取出下一个元素 当前索引左边的元素有序，但可能会被移动。所需时间取决于输入的元素初始序列。 时间复杂度O(n^2)，空间O(1)，稳定。 动图 代码1234567891011public class Insertion&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; for (int i = 1; i &lt; len; ++i) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j - 1]); --j) &#123; swap(a, j, j - 1); &#125; &#125; &#125;&#125; 希尔排序描述基于插入排序。思想是使数组中任意间隔为h的元素都是有序的。希尔排序使用插入排序对间隔 h 的序列进行排序。通过不断减小 h，最后令 h=1，就可以使得整个数组是有序的。 希尔排序的运行时间达不到平方级别，使用递增序列 1, 4, 13, 40, … 的希尔排序所需要的比较次数不会超过 N 的若干倍乘于递增序列的长度。后面介绍的高级排序算法只会比希尔排序快两倍左右。 动图 代码123456789101112131415161718public class Shell&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; int h = 1; while (h &lt; len / 3) &#123; h = 3 * h + 1; &#125; while (h &gt;= 1) &#123; for (int i = h; i &lt; len; ++i) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; swap(a, j, j - 1); &#125; &#125; h /= 3; &#125; &#125;&#125; 归并排序描述将一个数组递归的分成两半分别排序，然后将结果归并。 稳定排序。性能不受输入影响。时间复杂度O(NlogN) 动图 1. 原地归并将a[low … mid]和 a[mid + 1… hi]归并成一个有序数组，将结果存在 a[ low … hi]中。 1234567891011121314151617181920212223242526public class MergeSort&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; protected T[] aux; protected void merge(T[] a, int low, int mid, int high) &#123; // 先将所有元素复制到aux[] 中，然后归并回 a[]中。 int i = low, j = mid + 1; // 复制数据到辅助数组 for (int k = low; k &lt;= high; ++k) &#123; aux[i] = a[i]; &#125; for (int k = low; k &lt;= high; ++k) &#123; if (i &gt; mid) &#123; // 左边用尽，取右边元素 a[k] = aux[j++]; &#125; else if (j &gt; high) &#123; a[k] = aux[i++]; &#125; else if (less(aux[j], aux[i])) &#123; // 右半边当前元素小于左半边当前，取右半边 a[k] = aux[j++]; &#125; else &#123; a[k] = aux[i++]; &#125; &#125; &#125;&#125; 2. 自顶向下归并排序时间复杂度一般为O(NlogN) 123456789101112131415161718192021public class Up2DownMerge&lt;T extends Comparable&lt;T&gt;&gt; extends MergeSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; aux = (T[]) new Comparable[a.length]; sort(a, 0, a.length - 1); &#125; private void sort(T[] a, int low, int high) &#123; // 这里最好这样写，否则容易出现StackOverflow 错误 if (high &lt;= low) &#123; return; &#125; int mid = low + (high - low) &gt;&gt; 1; // 将左半边排序 sort(a, low, mid); // 右半边排序 sort(a, mid + 1, high); // 归并 merge(a, low, mid, high); &#125;&#125; 3. 自底向上归并123456789101112public class Down2UpMerge&lt;T extends Comparable&lt;T&gt;&gt; extends MergeSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; aux = (T[]) new Comparable[len]; for (int sz = 1; sz &lt; len; sz += sz) &#123; for (int low = 0; low &lt; len - sz; low += sz * 2) &#123; merge(a, low, low + sz - 1, Math.min(low + sz + sz - 1, len - 1)); &#125; &#125; &#125;&#125; 快速排序描述平均时间复杂度：O(NlogN)，额外空间O(NlogN)，不稳定 动图 基本算法12345678910111213141516171819202122232425262728293031323334353637383940414243public class QuickSort&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] array) &#123; sort(array, 0, array.length - 1); &#125; private void sort(T[] array, int low, int high) &#123; if (high &lt;= low) &#123; return; &#125; int j = partition(array, low, high); sort(array, low, j - 1); sort(array, j + 1, high); &#125; /** 一般写法 **/ private void sort2(T[] arr, int lo, int hi) &#123; if (lo &gt;= hi) &#123; return; &#125; int i = lo, j = hi; T k = arr[lo]; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; arr[j].compareTo(k) &gt; 0) &#123; j--; &#125; if (i &lt; j) &#123; arr[i++] = arr[j]; &#125; while (i &lt; j &amp;&amp; arr[i].compareTo(k) &lt; 0) &#123; i++; &#125; if (i &lt; j) &#123; arr[j--] = arr[i]; &#125; &#125; arr[i] = k; sort(arr, lo, i - 1); sort(arr, i + 1, hi); &#125;&#125; 切分123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private int partition(T[] a, int low, int high) &#123; int i = low, j = high + 1; T temp = a[low]; while (true) &#123; while (less(a[++i], temp) &amp;&amp; i != high) ; while (less(temp, a[--j]) &amp;&amp; j != low) ; if (i &gt;= j) &#123;break;&#125; swap(a, i, j); &#125; // 切分值留在j中。 swap(a, low, j); return j;&#125;/** * 切分的另一种写法 改写法在用来解决TOP K问题是，遇到如[99,99]， k=1的输入会陷入死循环 */private int partition2(T[] a, int low, int high) &#123; T pivot = a[low]; while (low &lt; high) &#123; // 从右向左，找到第一个小于pivot的元素 while (low &lt; high &amp;&amp; less(pivot, a[high])) high--; // 交换 a[low] = a[high]; // 从左到右找到第一个大于pivot的元素 while (low &lt; high &amp;&amp; less(a[low], pivot)) low++; a[high] = a[low]; &#125; a[low] = pivot; return low; // a[0..low-1] &lt; pivot &lt; a[low+1...high]&#125;/** **/private int partition(int[] arr, int low, int high)&#123; int k = arr[low]; while (low&lt;high)&#123; // 需要注意这里的 arr[high] &gt;= pivot while (low&lt;high &amp;&amp; arr[high]&gt;=k) --high; arr[low]=arr[high]; while (low&lt;high &amp;&amp; arr[low]&lt;=k) ++low; arr[high] = arr[low]; &#125; arr[low] = k; return low;&#125; 按照a[low]的值进行切分。从左向右找到第一个大于temp的元素a[i]，从右向左找到第一个小于temp的元素a[j]，交换a[i] 和 a[j]，使得i左侧的元素都不大于temp，j右侧的元素都不小于temp，i和j相遇时循环退出，交换a[low]和a[j]。 改进-三向快速切分对于有大量重复元素的数组，可以将数组切分为三部分，分别对应小于、等于和大于切分元素。 三向切分快速排序对于有大量重复元素的随机数组可以在线性时间内完成排序。 12345678910111213141516171819202122232425public class QuickSort3way&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; sort(a, 0, a.length - 1); &#125; private void sort(T[] a, int low, int high) &#123; if (high &lt; low) return; int lt = low, i = low + 1, gt = high; T v = a[low]; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; swap(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; swap(a, i, gt--); &#125; else &#123; i++; &#125; &#125; // a[lo...lt-1] &lt; v=a[lt...gt] &lt; a[gt+1...high] sort(a, low, lt - 1); sort(a, gt + 1, high); &#125;&#125; 可以提取改成partition方法 1234567891011121314151617181920212223public void sort(int[] a, int low, int high)&#123; if(high &lt; low) return; // 随机快排，在low和high中随机选一个位置，即随机选一个数做划分 swap(a, low + (int)(Math.random()* (high - low + 1)), high ); int[] k = partition(a, low, high); sort(a, low, k[0] - 1); sort(a, k[0] +1, high);&#125;private int[] partition(int[] a, int low, int high)&#123; int lt = low, gt = high, i = low + 1; int k = a[low]; while(i &lt;= gt)&#123; if(a[i] &lt; k)&#123; swap(a, i++, lt++); &#125;else if(a[i] &gt; k)&#123; swap(a, i, gt--); &#125;else&#123; i ++; &#125; &#125; return new int[]&#123;lt, gt&#125;;&#125; 随机快排的额外空间复杂度是最好是O(longN)，最坏是O(N)。空间用来记录断点位置。 使用切分解决Top K问题快速排序的 partition() 方法，会返回一个整数 j 使得 a[l..j-1] 小于等于 a[j]，且 a[j+1..h] 大于等于 a[j]，此时 a[j] 就是数组的第 j 大元素。partition()可以使用O(N)的平均复杂时间从无序数组找到第K大元素。 注意：使用partition找的是第K小的元素，因为partition切分后左边是小于的，右边是大于的，如果要找第K大元素，应该 k = nums.length - k; 可以利用这个特性找出数组的第 k 个元素。 1234567891011121314public T select(T[] nums, int k) &#123; int low = 0, high = nums.length - 1; while (high &gt; low) &#123; int j = partition2(nums, low, high); if (j == k) &#123; return nums[k]; &#125; else if (j &gt; k) &#123; high = j - 1; &#125; else &#123; low = j + 1; &#125; &#125; return nums[k];&#125; 题目二输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 在线编程 123456789101112131415161718192021public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int [] input, int k) &#123; int len = input.length; ArrayList&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(len &lt; 0 || k &gt; len || k&lt;=0) return res; int start = 0, end = len - 1; int index = partion(input, start, end); while(index != (k - 1))&#123; if(index &gt; (k-1))&#123; end = index - 1; index = partion(input, start, end); &#125;else&#123; start = index + 1; index = partion(input, start, end); &#125; &#125; for(int i = 0;i &lt; k;i++)&#123; res.add(input[i]); &#125; return res; &#125;&#125; 堆排序描述时间复杂度，最坏平均最好都是O(NlogN)，空间O(1)，不稳定。 动图 实现堆heap[0]不放元素，根节点是heap[1] 1234567891011121314151617181920212223242526public class Heap&lt;T extends Comparable&lt;T&gt;&gt; &#123; private T[] heap; private int n; public Heap(int maxN) &#123; this.heap = (T[]) new Comparable[maxN + 1]; &#125; public boolean isEmpty() &#123; return n == 0; &#125; public int siza() &#123; return n; &#125; public boolean less(int i, int j) &#123; return heap[i].compareTo(heap[j]) &lt; 0; &#125; public void swap(int i, int j) &#123; T temp = heap[i]; heap[i] = heap[j]; heap[j] = temp; &#125;&#125; 可以将数组理解为一个堆，对于堆中的第i个节点其在数组中的下标为i，其左孩子在数组中下标为2i+1（不越界情况）,右孩子下标为 2 i + 2(不越界)，其父节点为 (i - 1) / 2 上浮在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮。 123456789/** * 节点比父节点大，上浮 */private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k &gt;&gt; 1, k)) &#123; swap(k &gt;&gt; 1, k); k = k &gt;&gt; 1; &#125;&#125; 下沉12345678910111213/** * 父节点小于子节点，下沉 */private void sink(int k) &#123; while ((k &lt;&lt; 1) &lt;= n) &#123; int j = k &lt;&lt; 1; // 找到两个子节点最大的那个子节点 if (j &lt; n &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; swap(k, j); k = j; &#125;&#125; 插入元素插入到最底，然后上浮到合适位置 1234public void insert(T a)&#123; heap[ ++ n] = a; swim(n);&#125; 删除最大12345678910/** * 删除最大元素。首先从数组顶端删除最大，将数组最后一个放在顶端，然后让该元素下沉。 */public T delMax()&#123; T max = heap[1]; swap(1, n --); heap[n+1] = null; sink(1); return max;&#125; 堆排序将最大元素和当前堆中数组最后一个元素交换位置，并且不删除它，那么就可以得到一个从未到头的递减序列。 构建从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 交换堆顶与最后一个元素交换后进行下沉操作 实现123456789101112131415161718192021222324public class HeapSort&lt;T extends Comparable&lt;T&gt;&gt; extends BaseSort&lt;T&gt; &#123; @Override public void sort(T[] a) &#123; int len = a.length; for (int k = len &gt;&gt; 1; k &gt;= 1; k--) &#123; sink(a, k, len); &#125; while (len &gt; 1) &#123; // 交换后进行下沉操作 swap(a, 1, len--); sink(a, 1, len); &#125; &#125; private void sink(T[] num, int k, int n) &#123; while ((k &lt;&lt; 1) &lt;= n) &#123; int j = k &lt;&lt; 1; if (j &lt; n &amp;&amp; less(num[j], num[j + 1])) j++; if (!less(num[k], num[j])) break; swap(num, k, j); k = j; &#125; &#125;&#125; 分析堆高度为logN，插入删除的复杂度都是logN。 堆排序对N个节点进行下沉，复杂度NlogN。 没有利用额外空间。没有利用局部性原理缓存。 题目输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 在线编程 利用堆解决使用最大堆保存这k个数，每次只和堆顶比，如果比堆顶小，删除堆顶，新数入堆。 时间：O(nlogk) Java中的优先队列(PriorityQueue)是基于堆实现的，默认是自然排序，即默认构造最小堆，如果要更改排序规则，可以在构造时使用Comparator指定。优先队列中的元素可以通过Compartor定义规则。 12345678910111213141516171819202122232425import java.util.ArrayList;import java.util.PriorityQueue;import java.util.Comparator;public class Solution &#123; public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int[] input, int k) &#123; int len = input.length; ArrayList&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if (k &lt;= 0 || len &lt; k) return res; PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;&gt;(k, Comparator.reverseOrder()); // 将数组中的元素入堆 for (int a : input) &#123; if (maxHeap.size() &lt; k) &#123; maxHeap.offer(a); &#125; else if (maxHeap.peek() &gt; a) &#123; maxHeap.poll(); maxHeap.offer(a); &#125; &#125; res.addAll(maxHeap); return res; &#125;&#125; 总结 稳定性定义：经过排序之后,能使值相同的数据保持原顺序中的相对位置不变 稳定性口诀： 快选堆希不稳（快速排序，选择排序，堆排序，希尔排序） 插冒归计基稳（插入排序，冒泡排序，归并排序，计数，基数） 参考 《算法》第四版 博客园 - 十大经典排序算法（动图演示） 被忽视的 partition 算法 OSCHINA - 基于堆实现的优先级队列：PriorityQueue 解决 Top K 问题]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-四]]></title>
    <url>%2F2019%2F04%2F11%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[线程池 概述 使用线程池好处 降低资源消耗，重复利用已创建线程 提高响应速度，任务可以不创建就立即执行 提高线程可管理性，线程池统一分配，监控 Executor框架接口Executor接口123public interface Executor &#123; void execute(Runnable command);&#125; 启动线程： 12Thread t = new Thread();executor.execute(t); ExecutorService接口一般使用该接口 12ExecutorService executor = Executors.newFixedThreadPool(args...);ExecutorService executor = Executors.newCachedThreadPool(args...); ThreadPoolExecutorThreadPoolExecutor 是 JDK 中的线程池实现，这个类实现了一个线程池需要的各个方法，它实现了任务提交、线程管理、监控等等方法。 构造函数及重要属性1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize：核心线程数量，默认不会被回收 maximumPoolSize：最大线程数量，线程池能容纳的最大容量，上限被CAPACITY限制（2^29-1）。corePoolSize到maximumPoolSize之间的线程会被回收 keepAliveTime：如果线程数超过corePoolSize，有些线程空闲时间超过该值，执行关闭这些线程 unit：keepAliveTime单位 workQueue：存放任务的队列，添加任务时如果当前线程数超过corePoolsize，向该队列添加任务，线程池中的线程负责到队列中拉取任务 threadFactory：创建线程的工厂类 handler：任务执行失败使用handler通知调用者，默认为抛出异常。 线程池状态123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; Running：接受新任务，处理队列中的任务 Shutdown：不接受提交新任务，处理等待队列中的任务 Stop：不接受提交新任务，不处理队列中任务，中断正在执行的线程 Tidying：所有任务销毁，执行terminated() Terminated：terminated()结束后 拒绝策略队列和线程池都满了，线程池饱和，采取一种策略处理提交的新任务。 线程池框架提供四种策略： AbortPolicy：直接抛出异常。（默认策略） CallerRunsPolicy：只用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务 DiscardPolicy：不处理，丢弃。 Executors工具类，提供工厂方法创建不同类型的线程池。 四种常用线程池 newFixedThreadPool(int Threads)：创建固定数目线程的线程池 newCachedThreadPool()：创建一个可缓存的线程池，调用execute 将重用以前构造的线程（如果线程可用）。如果没有可用的线程，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。 newSingleThreadExecutor()：创建一个单线程化的Executor。 newScheduledThreadPool(int corePoolSize)：建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。 问题一般不建议使用Executors创建。使用Executors创建线程池可能会导致OOM(OutOfMemory ,内存溢出) 正确创建线程池直接调用ThreadPoolExecutor的构造函数来自己创建线程池 123ExecutorService executor = new ThreadPoolExecutor(10, 10, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue(10)); 使用Guava的ThreadFactoryBuilder创建，不仅可以避免OOM的问题，还可以自定义线程名称，更加方便的出错的时候溯源。 123456789101112131415public class ExecutorsDemo &#123; private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat("demo-pool-%d").build(); private static ExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); public static void main(String[] args) &#123; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; pool.execute(new SubThread()); &#125; &#125;&#125; 总结线程创建时机 当前线程数少于corePoolSize，提交任务时新建一个新线程，有该线程执行这个任务 如果当前线程数已经达到corePoolSize，将提交的任务添加到队列中，等待线程池中的线程取队列中取任务。 如果队列已满，就创建新的线程执行任务，需要保证线程池中的线程数不超过maximumPoolSize，如果超过，执行拒绝策略。 参考 Javadoop - 深度解读 java 线程池设计思想及源码实现 掘金 - 深入理解 Java 线程池：ThreadPoolExecutor 掘金 - 重走JAVA之路（五）：面试又被问线程池原理？教你如何反击 Java中线程池，你真的会用吗？ 方腾飞等. Java并发编程的艺术. 机械工业出版社, 2015.]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap源码分析]]></title>
    <url>%2F2019%2F04%2F10%2FConcurrentHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap是HashMap的线程安全版，基于JDK1.8分析其源码。 概述 经典的开源框架Spring的底层数据结构就是使用ConcurrentHashMap实现的。 hash冲突的处理方式也与HashMap类似，冲突的记录被存储到同一位置。 JDK8中实现线程安全是使用CAS算法，而不是以前的Segment概念。 key和value都不允许为空。 初始化1234567891011121314/** * Creates a new, empty map with the default initial table size (16). */public ConcurrentHashMap() &#123;&#125;public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125; 通过提供初始容量，计算了 sizeCtl，sizeCtl = 【 (1.5 * initialCapacity + 1)，然后向上取最近的 2 的 n 次方】 12345678910111213141516171819202122232425private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // cas 将sizeCtl设置为-1，代表抢到了锁 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; // 默认初始容量为16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; // 数组赋值给table table是volatile的 table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; sizeCtl123456789/** * Table initialization and resizing control. When negative, the * table is being initialized or resized: -1 for initialization, * else -(1 + the number of active resizing threads). Otherwise, * when table is null, holds the initial table size to use upon * creation, or 0 for default. After initialization, holds the * next element count value upon which to resize the table. */private transient volatile int sizeCtl; 控制标识符，不同的值有不同的属性。 负数代表正在初始化或正在扩容 -1代表正在初始化 -N标识有N-1个线程正在进行扩容操作 正数或0表示hash表还没被初始化，数值表示初始化或下一次扩容的大小。类似于HashMap中loadfactor的概念。它的值始终是当前ConcurrentHashMap容量的0.75倍，这与loadfactor是对应的。 它是多线程共享的。 Node12345678910111213141516171819202122232425262728293031323334353637383940414243444546static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + "=" + val; &#125; public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; /** * Virtualized support for map.get(); overridden in subclasses. */ Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null; &#125;&#125; 这里的Node和HashMap中实现类似，但有不同， 它对val和next设置了volatile同步锁 不允许调用setValue方法直接改变属性值 增加了find方法辅助map.get()方法 Unsafe与CAS大量使用U.compareAndSwap方法，利用CAS算法实现无锁修改值。基本思想是不断的比较当前内存中的变量值与你指定的变量值是否相等，相等则接受，否则拒绝，因此当前线程中的值并不是最新值，修改可能覆盖其他线程的修改结果。类似乐观锁，SVN的思想。 三个核心方法12345678910111213// 获得i位置上的节点static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125;// 使用cas算法设置i节点的值，实现并发是因为指定i节点原来的值static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;// 使用volatile方法设置节点的值static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; put方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 计算hash int hash = spread(key.hashCode()); // 相应链表长度 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // table为空，初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 根据hash计算节点的index else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 用一次CAS操作技能新值放入其中，put操作结束 // 如果cas失败，说明有并发操作，进入下一个循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 遇到表连接点，帮助进行整合表 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; // f是该位置的头节点且不为空 V oldVal = null; // 对table的index位置加锁，只锁住当前index位置 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 说明是链表节点 if (fh &gt;= 0) &#123; // 记录链表长度 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // hash与key相同，执行覆盖操作 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; // 遍历到了最后一个节点，新建节点插到最后 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 红黑树节点 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 链表长度大于8，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) // 不一定会进行红黑树转换，如果当前数组长度小于64， // 选择进行数组扩容，而不是转换红黑树 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 当key或value为null 的时候，抛出异常，因此ConcurrentHashMap的key与value都不能为空。 流程：计算key的hashCode，然后计算table的index（(n-1) &amp; hash），如果index位置为null，使用casTabAt方法插入，否则使用synchronized关键字对index位置加锁，仅仅锁住index位置因此其他线程可以安全地获取其他位置，提高了并发。然后判断index位置上第一个节点的hashCode值，小于0为红黑树根节点。如果是链表节点，遍历，当hash与key相同时，修改节点值，否则添加新节点。是红黑树节点的情况暂不分析。 get123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 计算hash int h = spread(key.hashCode()); // hash对应index位置不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; // 链表头节点的key与传入的key相同且不为null，返回该节点的值 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 节点在树上 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表查找节点 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 计算hash 根据hash得到index ：hash &amp; (len - 1) 根据该位置的节点性质查找 null，返回null 该位置节点恰好就是，返回该节点的值 该位置节点hash &lt; 0 ，正在扩容，或者是红黑树 链表，遍历查找 1.7中的ConcurrentHashMap1.7中主要使用Segment实现线程安全。 整个ConcurrentHashMap有一个个Segment组成，即ConcurrentHashMap是一个Segment数组，Segment通过集成ReentrantLock进行加锁，每次锁住一个segment。 Segment数组不能扩容，扩容是Segment数组某个位置内部数组HashEntry进行扩容。 参考 CSDN-ConcurrentHashMap源码分析（JDK8版本） 掘金-Java 8 ConcurrentHashMap源码分析 Javadoop - Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用aiohttp进行异步爬虫]]></title>
    <url>%2F2019%2F04%2F04%2F%E4%BD%BF%E7%94%A8aiohttp%E8%BF%9B%E8%A1%8C%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[不久前出于兴趣需要爬取一个网站的图片，保存到本地。这里记录下使用aiohttp的过程。 使用成熟的框架Scrapy爬虫时，其对于图片处理的不是很好，对于GIF也没有太大的支持。查找资料后发现了aiohttp这个框架。 单独使用aiohttp使用BeautifulSoup解析HTML页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748async def process_html(page_url): """解析文章页面，填充item""" async with aiohttp.ClientSession() as session: async with session.get(page_url) as response: cont = await response.read() soup = bs(cont, 'lxml') item['title'] = soup.find('h1').string item['page_url'] = page_url item['time'] = item['page_url'].split('/')[0] content = soup.find('div', class_ = 'main') data_src_temp = content.find_all( 'img', attrs = &#123;'type': 'image'&#125;) # 得到图片链接 for link in data_src_temp: src_temp = link.get('image') item['images_url'].append(src_temp) time_path = os.path.join('imagepath', item['time']) page_path = set_down_path(time_path, item['title']) # print(item['images_url']) for idx, image_url in enumerate(item['images_url']): await down_one(image_url, page_path, idx) async def down_one(img_url, page_path_temp, idx): """得到content后保存到本地""" # 图片后缀 suffix = img_url.split('.')[-1] # 组装单个图片路径 image_name = page_path_temp + "/" + str(idx) + '.' + suffix if os.path.exists(image_name): return # 得到图片内容 async with aiohttp.ClientSession() as session: async with session.get(img_url) as response: content = await response.read() with open(image_name, 'wb') as file: file.write(content) def run(): print("start") t1 = time.time() loop = asyncio.get_event_loop() tasks = [process_html(url) for url in page_urls] loop.run_until_complete(asyncio.wait(tasks)) loop.close() t2 = time.time() print('总共耗时：%s' % (t2 - t1)) aiohttp+Scrapyaiohttp是requests的异步替代版。 下面是结合Scrapy的代码，由Scrapy处理得到每页中每张图片的地址，在pipelines.py中使用aiohttp+asyncio下载图片。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class SaveImagePipeline(object): def set_down_path(self, time_path, title): """ 设置图片的文件夹路径 """ try: if not os.path.exists(time_path): os.mkdir(time_path) page_path = os.path.join(time_path, title) if not os.path.exists(page_path): os.mkdir(page_path) except IOError as e: logging.error(e) return '' return page_path async def down_one(self, img_url, page_path, idx): """得到content后保存到本地""" # 图片后缀 suffix = img_url.split('.')[-1] # 组装单个图片路径 image_name = page_path + "/" + str(idx) + '.' + suffix if os.path.exists(image_name): return # 得到图片内容 async with aiohttp.ClientSession() as session: try: async with session.get(img_url, verify_ssl = False) as response: if response.status == 404: return content = await response.read() with open(image_name, 'wb') as file: file.write(content) except aiohttp.client_exceptions.ClientConnectionError: return tasks = '' def process_item(self, item, spider): post_time = item['time'] title = item['title'] time_path = os.path.join(settings['SAVE_IMAGE_PATH'], post_time) page_path = self.set_down_path(time_path, title) loop = asyncio.get_event_loop() self.tasks = [self.down_one(url, page_path, idx) for idx, url in enumerate(item['images_url'])] loop.run_until_complete(asyncio.wait(self.tasks)) 如果图片更多，保存图片的操作就成了性能限制，可以尝试使用 aiofiles 进行图片保存 参考Welcome to AIOHTTP 掘金-python使用异步每秒钟就能下载一张高清大图，快不快？]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码解析]]></title>
    <url>%2F2019%2F04%2F04%2FHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[基于JDK1.8分析HashMap的底层实现。 概述HashMap线程不安全，允许key为null，value为null，遍历无序。 其底层实现有三种数据结构：数组，链表，红黑树。在JDK8中，一个桶存储的链表结构大于8时会转化为红黑树，在红黑树中查找时间复杂度为O(logn)。 数组用来存储键值对，每一个键值对别成为Entry，这是HashMap的主干。其中的米一个元素初始值都为null。 链表节点NodeJava8中使用Node替代7中的Entry，适用于链表。 12345678910111213141516171819202122232425262728293031323334353637383940static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; // 每一个节点的hashCode由key的hashcode和value的hashCode得到 return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; // 重写equals public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 链表中的每一个节点的hashCode由key的hashcode和value的hashCode得到。 构造函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 默认capacity，table的容量大小，默认16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认装载因子，table能够使用的比例static final float DEFAULT_LOAD_FACTOR = 0.75f;// size 的临界值，当 size 大于等于 threshold 就必须进行扩容操作。int threshold;// 哈希桶transient Node&lt;K,V&gt;[] table;// 默认构造函数，指定loadFactor为默认0.75fpublic HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125;// 指定初始容量的构造函数public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;// 指定初始容量和装载因子的构造函数public HashMap(int initialCapacity, float loadFactor) &#123; // 边界处理 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); // 初始容量不能大于2的30次方 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 装载因子的边界处理 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 新建hash表public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 指定加载因子为默认0.75f this.loadFactor = DEFAULT_LOAD_FACTOR; // putMapEntries(m, false);&#125; 重要参数： capacity：table 容量大小，默认为16，且必须为2的n次方 size：键值对数量 threshold（阈值）：size临界值，size大于等于threshold时需要进行扩容 loadfactor：装载因子，threshold = capacity * loadfactor 增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。 由于在计算中位运算比取模运算效率高的多，所以 HashMap 规定数组的长度为 2^n 。这样用 2^n - 1 做位运算与取模效果一致，并且效率还要高出许多。 tableSizeFor，计算数组容量1234567891011121314151617/** * Returns a power of two size for the given target capacity. 根据期望容量，返回2的n次方实，数组实际容量 length */static final int tableSizeFor(int cap) &#123; //经过下面的 或 和位移 运算， n最终各位都是1。 int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; // 判断n是否越界，小于0赋值1，大于最大容量设为最大容量 // 返回 2的n次方作为 table（哈希桶）的阈值 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; putMapEntries()将另一个Map的所有元素加入表中，参数evict初始化时为false，其他情况为true 12345678910111213141516171819final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; put操作put()往哈希表里插入一个节点的putVal函数,如果参数onlyIfAbsent是true，那么不会覆盖相同key的值value。如果evict是false。那么表示是在初始化时调用的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;// onlyIfAbsent为true时，只有不存在key是进行put操作final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // tab当前hash桶，p临时链表节点 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 第一次放入值，table为空，执行初始化resize() if ((tab = table) == null || (n = tab.length) == 0) // 扩容hash表，并将长度赋给n n = (tab = resize()).length; // 当前节index节点为空，没有hash冲突，直接构建新节点，挂载在index处 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; // 发生了hash冲突 Node&lt;K,V&gt; e; K k; // 如果该index处的第一个数据与插入数据hash相同，key也相等，当前节点赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // p节点是红黑树的节点，调用红黑树的插入 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 不是覆盖操作 // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 遍历到尾部，添加新节点（Java 7是插入到链表前面） p.next = newNode(hash, key, value, null); // 添加新节点后链表长度大于8，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 找到了要覆盖的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // e不为空，存在旧值的key与要插入的key相等 执行覆盖，返回旧值 if (e != null) &#123; // existing mapping for key // 覆盖节点，返回oldva V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; // 以上完成插入新节点的操作 ++modCount; // 判断size是否大于临界值，执行resize操作 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 桶下标 index=(n - 1) &amp; hash HashMap不是在new时申请空间，而是在第一次put时申请空间。没有发生hash冲突，直接构建新节点挂在到index处。 概述：执行put操作时，如果是第一次put，执行resize() 方法；根据key计算hash，hash &amp; (n - 1) 得到在数组中的index位置，如果index位置为空，创建Node节点，挂载在index位置处；index不为空，发生了hash冲突，此时判断index处的第一个节点的key与hash与放入的key与hash是否相等，相等执行覆盖。如果第一个节点是红黑树节点，调用红黑树插入方法，否则是链表节点。遍历链表节点，将要存的节点插入到链表最后，如果存在相等的key，执行覆盖。插入完成后，判断size是否大于临界值，大于则执行resize(); 在JDK8中，插入链表是插在链表最后，即尾插入，而JDK7中是头插入。头插入的一个缺点是在并发情况下插入扩容可能出现链表环发生死循环。 hash()1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; HashMap允许key为null，key为null，hash为0，下标为0 根据key取hash值，扰动函数，使hash均衡，减少hash碰撞的几率。它会综合hash值高位和低位的特征，并存放在低位，因此在与运算时，相当于高低位一起参与了运算，以减少hash碰撞的概率。 JDK8中简化操作。 resize() 重点初始化或加倍哈希桶大小。如果是当前哈希桶是null,分配符合当前阈值的初始容量目标。否则，扩容成以前的两倍。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105final Node&lt;K,V&gt;[] resize() &#123; // 当前表的哈希桶 Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 当前桶容量大于0 if (oldCap &gt; 0) &#123; // 大于最大容量 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 将临界值设为最大 threshold = Integer.MAX_VALUE; // 返回当前哈希桶，不再扩容 return oldTab; &#125; // 如过当前容量的两倍小于最大容量并且当前容量大于默认容量 // 新容量为当前容量的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 新的临界值也为当前的两倍 newThr = oldThr &lt;&lt; 1; &#125; // //如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 容量为0，代表第一次执行put操作，需要初始化 // 容量和临界值都初始化为默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //如果新的阈值是0，对应的是 当前表是空的，但是有阈值的情况 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; //进行越界修复 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 当前哈希桶不为空 if (oldTab != null) &#123; // 遍历 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; // 当前节点有元素，值赋给e if ((e = oldTab[j]) != null) &#123; // 置空，便于GC oldTab[j] = null; //当前链表就一个元素，没有发生hash冲突 if (e.next == null) // 直接将元素放在新的桶里 // 这里去下标 当前节点的hash 与 桶的长度减一 // 桶的长度是2的n次方，这样就是取模 newTab[e.hash &amp; (newCap - 1)] = e; // 发生过hash碰撞且节点是红黑树节点 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 没有放生哈希碰撞，节点小于8，依次放入新的哈希桶对应位置 else &#123; // preserve order //因为扩容是容量翻倍，所以原链表上的每个节点，现在可能存放在原来的下标，即low位， // 或者扩容后的下标，即high位。 high位= low位+原哈希桶容量 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //这里又是一个利用位运算 代替常规运算的高效点： // 利用哈希值 与 旧的容量，可以得到哈希值去模后，是大于等于oldCap还是小于oldCap， // 等于0代表小于oldCap，应该存放在低位，否则存放在高位 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 高位相同的逻辑 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 低位链表存在源index处 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 高位存在新index if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; HashMap中用到了许多位运算，更高效 扩容时，将旧的数组中引用置null，便于GC 取下标 是用 哈希值 与运算 （桶的长度-1） i = (n - 1) &amp; hash。 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。但是效率更高 因为扩容是容量翻倍，所以原链表上的每个节点，现在可能存放在原来的下标，即low位， 或者扩容后的下标，即high位。 high位= low位+原哈希桶容量 resize是很费时间的操作，因此最好在HashMap初始化时指定大小，尽量减少调用resize方法。 get操作get()12345678910111213141516171819202122232425262728293031public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;// 传入扰动后的hash 和 key查找final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 哈希表不为空，根据hash计算下标，该下标有节点的话 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 如果链表头结点就是要查找的节点，直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 链表头结点的下一个节点不为空 if ((e = first.next) != null) &#123; // 是红黑树树节点，使用红黑树的查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 是链表，遍历链表 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; // 没有找到，返回null return null;&#125; 计算key 的hash，根据hash计算index，hash &amp; (len - 1) 判断数组该位置第一个原始是否恰好为要找的 判断第一个节点元素类型是否为TreeNode，是用红黑树方法取数据，不是继续 便利链表，找到相等的key 以上在O(1)的时间里查找执行完 7与8的一些不同 7是数组+链表的结构；8是数组+链表+红黑树，链表长度大于8转化为红黑树 插入时7是头插法；8是尾插法。一种原因是防止形成链表环 7是先计算size后插入；8是先插入后计算 参考 CS-Notes-HashMap 掘金-面试必备：HashMap源码解析（JDK8） Javadoop - Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析 掘金 - HashMap为何从头插入改为尾插入]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL基本语句总结]]></title>
    <url>%2F2019%2F04%2F03%2FMySQL%E5%9F%BA%E6%9C%AC%E8%AF%AD%E5%8F%A5%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[学习《MySQL必知必会》，整理基本语句 查询普通查询DISTINCT 返回唯一的结果12SELECT DISTINCT id FROM products LIMIT 限制查询结果123SELECT id FROM productsLIMIT 5; 1LIMIT 5,5 从5行开始的第五行。（检索的第一行为0为而不是1） 排序查询ORDER BY默认按照升序排序。 123SELECT id FROM productsORDER BY age, name; 首先按照age，在按照name，仅age 有多个相同的时候。 排序方向1ORDER BY age DESC, name 按照age降序排序。name 升序排序。 过滤数据WHERE在SELECT语句中，数据根据WHERE子句中指定的搜索条件进行过滤。 WHERE子句在表名（FROM子句）之后给出 。 WHERE子句的位置 在同时使用ORDER BY和WHERE子句时，应 该让ORDER BY位于WHERE之后， 否则将会产生错误 123SELECT id FROM productsWHERE id = 3; BETWEEN1WHERE price BETWEEN 5 AND 10; BETWEEN匹配范围中所有的值，包括指定的开始值和结束值。 AND1WHERE price age &lt; 10 AND price &gt; 5; OR1WHERE price age &lt; 10 OR price &gt; 5; 计算次序WHERE可包含任意数目的AND和OR操作符。允许两者结合以进行复杂 和高级的过滤。 SQL（像多数语言一样）在处理OR操作符前，优先处理AND操 作符。AND在计算次序中优先级更高 1WHERE (id = 1001 OR id = 1003) AND price &gt; 10; 因为圆括号具有较AND或OR操作符高 的计算次序，DBMS首先过滤圆括号内的OR条件。 任何时候使用具有AND和OR操作 符的WHERE子句，都应该使用圆括号明确地分组操作符。 ININ WHERE子句中用来指定要匹配值的清单的关键字，功能与OR 相当。 IN操作符用来指定条件范 围，范围中的每个条件都可以进行匹配。1WHERE id IN (1002, 1004); IN操作符一般比OR操作符清单执行更快。 IN的最大优点是可以包含其他SELECT语句，使得能够更动态地建 立WHERE子句。 使用别名1SELECT vend_name, '(',vend_country, ')' AS vend_title 使用Concat拼接字段 12345SELECT CONCAT(vend_name,&apos;(&apos;,vend_country, &apos;)&apos;)FROM vendors order by vend_name 执行算数计算 函数聚集函数 AVG() COUNT MAX MIN() SUM() 1SELECT AVG(age) AS avg_price 分组GROUP BY123SELECT id, COUNT(*) AS num_prodsFROM productsGROUP BY id; 将分别计算每个id的数量。GROUP BY子句指 示MySQL按vend_id排序并分组数据。这导致对每个vend_id而不是整个表 计算num_prods一次 。 GROUP BY子句必须出现在WHERE子句之后， ORDER BY子句之前。 HAVING大部分类型的WHERE子句都可以用HAVING来替代。唯一的差别是 WHERE过滤行，而HAVING过滤分组。HAVING支持所有WHERE操作符1234SELECT id, COUNT(*) AS ordersFROM ordersGROUP BY idHAVING COUNT(*) &gt;= 2; HAVING子句，它过滤COUNT(*) &gt;=2（两个以上的订单）的那些分组。 有另一种理解方法，WHERE在数据 分组前进行过滤，HAVING在数据分组后进行过滤。这是一个重 要的区别，WHERE排除的行不包括在分组中 12345SELECT id, COUNT(*) AS ordersFROM ordersWHERE price &gt;= 10GROUP BY idHAVING COUNT(*) &gt;= 2; 第一行是使用了聚集函数的基本SELECT，它与前 面的例子很相像。WHERE子句过滤所有prod_price至少为10的 行。然后按vend_id分组数据，HAVING子句过滤计数为2或2以上的分组。 分组和排序一般在使用GROUP BY子句时，应该也给 出ORDER BY子句。这是保证数据正确排序的唯一方法。 12345SELECT order_num, SUM(quantity*item_price) AS ordertotalFROM orderitemsGROUP BY order_numHAVING SUM(quantity*item_price) &gt;= 50ORDER BY ordertotal GROUP BY子句用来按订单号（order_num列） 分组数据，以便SUM(*)函数能够返回总计订单价格。HAVING子 句过滤数据，使得只返回总计订单价格大于等于50的订单。后，用ORDER BY子句排序输出。 子查询123SELECT order_numFROM orderitemsWHERE prod_id = 'TNT2' 123SELECT cust_idFROM ordersWHERE order_num IN (20005, 20007) 1234567SELECT cust_idFROM ordersWHERE order_num IN ( SELECT order_num FROM orderitems WHERE prod_id = 'TNT2') 首先执行括号中的查询 联结 Join外键（foreign key） 外键为某个表中的一列，它包含另一个表 的主键值，定义了两个表之间的关系 创建联结1234SELECT vent_name, prod_name, prod_priceFROM vendors, productsWHERE vendors.vend_id = products.vend_idORDER BY vend_name, prod_name WHERE子句 指示MySQL匹配vendors表中的vend_id和products表中的vend_id。 内部联结(INNER JOIN ON)123SELECT vend_name, prod_name, prod_priceFROM vendors INNER JOIN productsON vendors.vend_id = products.vend_id 与前面语句相同。两个表之间的关系是FROM子句的组成部分，以INNER JOIN指定。联结条件用特定的ON子句而不是WHERE 子句给出。传递给ON的实际条件与传递给WHERE的相同。 1234567891011SELECT cust_name, cust_contact FROM customers as c, orders as o, orderitems as oi WHERE c.cust_id = o.cust_id AND o.order_num = oi.order_num AND prod_id = &apos;TNT2&apos; 首选 INNER JOIN 高级联结使用表别名12SELECT cust_name, cust_ageFROM customers AS c, orders AS o, ordertimes AS oi 建立c作为customers 的别名 自联结123456789SELECT p1.prod_id, p1.prod_name FROM products AS p1, products as p2WHERE p1.vend_id = p2.vend_id AND p2.prod_id = 'DTNTR'; products是同一张表，第一次出现使用p1,p1前缀明确地给出所需列的全名；第二次出现使用p2 使用自联结替代子查询 自然联结外部联结(LEFT OUTER JOIN)联结包含了那些在相关表中没有关联行的行。这种 类型的联结称为外部联结 123456SELECT customers.cust_id, orders.order_num FROM customers LEFT JOIN orders ON customers.cust_id = orders.cust_id 使用LEFT OUTER JOIN从FROM 子句的左边表（customers表）中选择所有行。 联结详解内连接 INNER JOIN ON 左连接 LEFT JOIN ON / LEFT OUTER JOIN ON左边的表选择所有行，右边只显示符合搜索条件的记录 右连接 RIGHT JOIN ON / RIGHT OUTRE JOIN ON 组合查询可用UNION操作符来组合数条SQL查询。利用UNION，可给出多条SELECT语句，将它们的结果组合成单个结果集。 UNION1234567891011121314151617SELECT vend_id, prod_id, prod_price FROM products WHERE prod_price &lt;= 5 UNIONSELECT vend_id, prod_id, prod_price FROM products WHERE vend_id IN ( 1001, 1002 ) 等价于 123SELECT vend_id, prod_id, prod_priceFROM productsWHERE prod_price &lt;=5 OR vend_id IN (1001, 1002) 注意： UNION中的每个查询必须包含相同的列、表达式或聚集函数 UNION必须由两条或两条以上的SELECT语句组成，语句之间用关 键字UNION分隔（因此，如果组合4条SELECT语句，将要使用3个 UNION关键字） UNION ALLUNION默认去除重复的行，使用UNION ALL 避免。 排序SELECT语句的输出用ORDER BY子句排序。在用UNION组合查询时，只 能使用一条ORDER BY子句，它必须出现在最后一条SELECT语句之后。对 于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一 部分的情况，因此不允许使用多条ORDER BY子句。 增改删插入数据1234567INSERT INTO customers(cust_name, cust_id)VALUES('name', 'id'), ('name_2', 'id_2'); 更新数据123UPDATE customersSET cust_email = 'mail'WHERE cust_id = 1001; 注意不要忘了where 删除数据12DELETE FROM customersWHERE cust_di = 1002; 表操作创建表12345CREATE TABLE customers( cust_id int NOT NULL AUTO_INCREMENT, cust_name char(50)NOT NULL, PRIVARY KEY (cust_id))ENGINE=InnoDB; 参考《MySQL必知必会》 CSDN-图解MySQL 内连接、外连接、左连接、右连接、全连接……太多了]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-三]]></title>
    <url>%2F2019%2F03%2F28%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[Java中的锁，本文主要介绍synchronized关键字和ReentrantLock 锁的分类悲观锁：对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Synchronize关键字和Lock的实现类都是悲观锁 乐观锁：自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。Java中常用CAS算法实现乐观锁。 Synchronized。JVM实现 显式Lock。JDK实现 线程安全首先需要理解线程安全的两个方面：执行控制和内存可见。 执行控制的目的是控制代码执行（顺序）及是否可以并发执行。 内存可见控制的是线程执行结果在内存中对其它线程的可见性。根据Java内存模型的实现，线程在具体执行时，会先拷贝主存数据到线程本地（CPU缓存），操作完成后再把结果从线程本地刷到主存。 synchronized基本性质： 互斥锁。一次只允许一个线程进入被锁 的代码块。 使用对象的内置锁将代码块锁定。Java中每个对象都有一个内置锁 保证线程的原子性。被保护的代码块是一次被执行的，没有任何线程会同时访问 保证线程的可见性。当执行完synchronized之后，修改后的变量对其他的线程是可见的 通过内置锁实现原子性和可见性。 synchronized是Java提供的原子性内置锁，每个对象都可以把它当做锁来使用，称为内部锁，监视器锁。synchronized代码块自动获取内部锁，。 synchronized关键字解决的是执行控制的问题，它会阻止其它线程获取当前对象的监控锁，这样就使得当前对象中被synchronized关键字保护的代码块无法被其它线程访问，也就无法并发执行。 更重要的是，synchronized还会创建一个内存屏障，内存屏障指令保证了所有CPU操作结果都会直接刷到主存中，从而保证了操作的内存可见性，同时也使得先获得这个锁的线程的所有操作，都happens-before于随后获得这个锁的线程的操作。 用法几种用途： 修饰代码块。被修饰的代码块称为同步语句块，作用范围是大括号括起来的代码，作用对象是调用这个代码块的对象。 修饰普通方法。被修饰的方法为同步方法，作用是整个方法，作用对象是调用这个方法的对象。s 修饰静态方法。作用于整个静态方法，作用对象是这个类的所有对象。 修饰类：作用是synchronized括号中的部分，对象是这个类中所有对象。 修饰代码块作用于同一个对象 12345678910111213141516171819202122232425262728293031323334353637public class BlockDemo implements Runnable&#123; private static int count = 0; @Override public void run() &#123; synchronized (this)&#123; for (int i = 0; i &lt; 5; i++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ": " + count++); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; BlockDemo blockDemo = new BlockDemo(); Thread thread1 = new Thread(blockDemo, "thread1"); Thread thread2 = new Thread(blockDemo, "thread2"); thread1.start(); thread2.start(); &#125;&#125;/**thread1: 0thread1: 1thread1: 2thread1: 3thread1: 4thread2: 5thread2: 6thread2: 7thread2: 8thread2: 9**/ 两个并发线程(thread1和thread2)访问同一个对象(blockDemo)中的synchronized代码块，同一时刻只能有一个线程执行，必须等到一个线程执行完另一个线程才执行。 修改 12345678910111213141516Thread thread1 = new Thread(new BlockDemo(), "thread1");Thread thread2 = new Thread(new BlockDemo(), "thread2");thread1.start();thread2.start();/**thread1: 0thread2: 1thread1: 2thread2: 3thread2: 4thread1: 5thread2: 6thread1: 7thread1: 8thread2: 9**/ 两把锁分别锁定两个对象，而这两把锁是互不干扰的，不形成互斥，所以两个线程可以同时执行 修饰方法作用于同一个对象 123public synchronized void func () &#123; // ...&#125; synchronized关键字不能继承。 静态方法123public synchronized static void fun() &#123; // ...&#125; 态方法是属于类的而不属于对象的。同样的，synchronized修饰的静态方法锁定的是这个类的所有对象。 修饰类12345678910public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125; 两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 原理Java虚拟机中的同步基于进入和退出monitor对象实现，无论是显式同步哈市隐式同步都是如此。 Monitor：一个同步工具或同步机制。每个Java对象都有一个看不见的锁，称为内部锁或Monitor锁。 synchronized底层是是通过进入和退出monitor对象实现，对象有自己的对象头，存储了很多信息，其中一个信息标示是被哪个线程持有。 优化锁有四种状态：无锁，偏向锁，轻量级锁，重量级锁。锁可以升级，但是是单向的，只能从低到高级，不会出现锁的降级。 无锁没有对资源进行锁定，但是同时只有一个线程能修改成功。修改会在循环内进行，线程不断尝试修改共享资源，成功就退出，失败继续尝试。CAS即是无锁的实现。 偏向锁同一段代码一直被一个线程访问，那该线程自动获取锁，降低所得获取代价。目标就是在只有一个线程同步代码块时能够提高性能。 可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁当锁是偏向锁时，被另外的线程访问，偏向锁升级为轻量级锁，其他线程通过自旋的形式获取锁，不会阻塞。 重量级锁当自旋超过一定的次数，升级为重量级锁 可重入性可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁 与volatile比较 volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读。synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 volatile仅能够修饰变量，synchronized可以修饰变量，方法，类级别 volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化 对于工作内存与主内存同步延迟现象导致的可见性问题，可以使用synchronized关键字或者volatile关键字解决，它们都可以使一个线程修改后的变量立即对其他线程可见。对于指令重排导致的可见性问题和有序性问题，则可以利用volatile关键字解决，因为volatile的另外一个作用就是禁止重排序优化。 ReentrantLock使用123456789101112131415161718192021222324public class LockExample &#123; private Lock lock = new ReentrantLock(); public void function() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService service = Executors.newCachedThreadPool(); service.execute(lockExample::function); service.execute(lockExample::function); &#125;&#125;// 结果// 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 原理ReentrantLock是基于AQS（AbstractQueuedSynchronizer）实现的，AQS的基础是CAS。 与synchronized比较 synchronize是JVM实现，Lock是JDK实现。 性能差别不大 synchronize的锁和Lock都是非公平锁，Lock可以实现公平锁 一个 ReentrantLock 可以同时绑定多个 Condition 对象。 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 参考 掘金 - Java锁机制了解一下 CS-Notes 美团技术团队 - 不可不说的Java“锁”事 深入理解Java并发之synchronized实现原理 《Java并发编程的艺术》 [CSDN - 全面理解Java内存模型(JMM)及volatile关键字 Java中Synchronized的用法]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-二]]></title>
    <url>%2F2019%2F03%2F28%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[Java内存模型，volatile关键字 Java内存模型线程安全问题。《深入理解Java虚拟机》定义，当多个线程访问同一个对象，如果不考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确结果，藏鞥对象是线程安全的。 出现线程安全的原因一般是 主内存和工作内存数据不一致和重排序导致。 Java内存模型 并发编程两个关键问题：线程之间如何通信，线程之间如何同步。 两种通信机制：共享内存，消息传递 共享内存：线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信，典型的共享内存通信方式就是通过共享对象进行通信。 消息传递：线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信，在java中典型的消息传递方式就是wait()和notify()。 Java并发采用共享内存。 Java线程之间的通信有Java内存模型（JMM）控制，他决定了一个线程的共享变量的写入何时对另一个线程可见。 从抽象角度：JMM定义了线程和主内存之间的抽象关系，线程之间的共享变量存储在主内存中，每个线程都有一个私有本地内存，本地内存中存储了该线程共享变量的副本。本地内存并不真实存在。 两个线程，A和B通信，经历步骤： 线程A将本地内存A中更新过的共享变量刷新到主内存中 线程B到主内存中读取A更新过得变量。 内存模型三大特性三大特性：原子性，可见性，有序性 原子性即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？ 1`i = ``9``;` 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。 那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 可见性可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 主要有三种实现可见性的方式： volatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 有序性有序性指，在本线程内观察，所有操作都是有序的，在一个线程观察另一个线程，所有操作都是无序的。无序是因为发生了指令重排序。在Java内存模型，允许编译器和处理器对指令进行重排序，重排序不会影响单线程程序的执行，会影响到多线程并发执行的正确性。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。 重排序为提高性能，编译器处理器对指令进行重排序，分为三种： 编译器优化 指令级并行 内存系统 针对编译器重排序，JMM的编译器重排序规则会禁止一些特定类型的编译器重排序；针对处理器重排序，编译器在生成指令序列的时候会通过插入内存屏障指令来禁止某些特殊的处理器重排序。 编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序 volatile关键字两个作用： 保证volatile修饰的变量对所有线程可见 禁止指令重排序优化 volatile关键字解决的是内存可见性的问题，会使得所有对volatile变量的读写都会直接刷到主存，即保证了变量的可见性。这样就能满足一些对变量可见性有要求而对读取顺序没有要求的需求。 使用volatile关键字仅能实现对原始变量(如boolen、 short 、int 、long等)操作的原子性，但需要特别注意， volatile不能保证复合操作的原子性，即使只是i++，实际上也是由多个原子操作组成：read i; inc; write i，假如多个线程同时执行i++，volatile只能保证他们操作的i是同一块内存，但依然可能出现写入脏数据的情况。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 实现方式：写一个volatile变量时，JMM将线程对应的工作内存中共享变量刷新到主内存中，读取volatile变量，JMM将该线程对应的工作内存设置为无效，该线程从主内存中读取更像变量。 volatile自身变量具有特性： 可见性。对一个volatile变量的读，总是能看到任意线程对这个volatile变量最后的写入。 原子性。对任意单个volatile变量的读/写具有原子性，但i++不具有。 参考 全面理解Java内存模型(JMM)及volatile关键字 全面理解Java内存模型 Java-并发-Java内存模型 Java内存模型和JVM内存管理 掘金-Java内存模型以及happens-before规则]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令]]></title>
    <url>%2F2019%2F03%2F28%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[整理一些常用的git命令 本地push到远程初始化本地 1git init 本地关联远程 1git remote add origin git@gitres 添加和提交 12git add .git commit -m "注释" push 远程 1234第一次推送master分支时，加上-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，git push -u origin mastergit push origin master 文件操作添加文件目录1234# 添加当前目录所有文件到暂存区git add .git add [file1] [file2]...git add [dir] 撤销add1git rm --cached &lt;file&gt;]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发学习-一]]></title>
    <url>%2F2019%2F03%2F27%2FJava%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[创建线程的三种方式，线程相关方法。 创建线程三种方式：继承Thread类重写run方法，实现Runnable接口，使用FutureTask方式。 继承Thread类重写run方法123456789101112131415161718192021222324252627282930class Thread1 extends Thread &#123; private String name; private int ticket = 20; private Random rand = ThreadLocalRandom.current(); public Thread1(String name) &#123; this.name = name; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(name + "运行：" + i); &#125; try &#123; sleep(rand.nextInt(100)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class Demo extends Thread &#123; public static void main(String[] args) &#123; Thread1 thread1 = new Thread1("A"); Thread1 thread2 = new Thread1("B"); thread1.start(); thread2.start(); &#125;&#125; 实现Runnable接口1234567891011121314151617181920212223242526272829class DemoByRun implements Runnable &#123; private String name; public DemoByRun(String name) &#123; this.name = name; &#125; private Random random = ThreadLocalRandom.current(); @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(name + "运行：" + i); &#125; try &#123; Thread.sleep(random.nextInt(50)); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;&#125;public class Main&#123; public static void main(String[] args) &#123; new Thread(new DemoByRun("A")).start(); new Thread(new DemoByRun("B")).start(); &#125;&#125; 使用FutureTask123456789101112131415public class Main5 &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; DemoByCallable call = new DemoByCallable(); FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(call); new Thread(futureTask).start(); System.out.println(futureTask.get()); &#125;&#125;class DemoByCallable implements Callable&lt;String&gt; &#123; @Override public String call() &#123; return "hello"; &#125;&#125; 继承Thread类的线程同步错误实现123456789101112131415161718192021222324252627282930public class Main3 &#123; public static void main(String[] args) &#123; Ticket3 ticket1 = new Ticket3(); Ticket3 ticket2 = new Ticket3(); Ticket3 ticket3 = new Ticket3(); ticket2.start(); ticket1.start(); ticket3.start(); &#125;&#125;class Ticket3 extends Thread &#123; private int ticket = 5; @Override public void run() &#123; while (ticket &gt; 0) &#123; synchronized (this) &#123; if (ticket &gt; 0) &#123; System.out.println(currentThread().getName() + "运行，此时的剩余票数" + this.ticket--); &#125; &#125; try &#123; sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 继承Thread类的线程同步正确实现123456789101112131415161718192021222324252627public class Main4 &#123; public static void main(String[] args) &#123; Ticket4 ticket4 = new Ticket4(); new Thread(ticket4).start(); new Thread(ticket4).start(); new Thread(ticket4).start(); &#125;&#125;class Ticket4 extends Thread&#123; private int ticket = 6; @Override public void run() &#123; while (ticket &gt; 0)&#123; synchronized (this)&#123; System.out.println(currentThread().getName() + "运行，此时的剩余票数为" + -- this.ticket); &#125; try &#123; sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 比较实现Runnable接口比继承Thread类所具有的优势： 1）：适合多个相同的程序代码的线程去处理同一个资源 2）：可以避免java中的单继承的限制 3）：增加程序的健壮性，代码可以被多个线程共享，代码和数据独立 4）：线程池只能放入实现Runable或callable类线程，不能直接放入继承Thread的类 两者都有的： 适合多个相同的程序代码的线程去处理同一个资源增加程序的健壮性，代码可以被多个线程共享，代码和数据独立 线程状态的转换 新建状态（New）：新创建了一个线程对象 就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的 start() 方法，该状态的线程位于可运行的线程池中，变为可运行状态，这个时候，只要获取了 cpu 的执行权，就可以运行，进入运行状态。 运行状态（Running）： 就绪状态的线程从 cpu 获得了执行权之后，便可进入此状态，执行 run() 方法里面的代码。 阻塞状态（Blocked）：阻塞状态是线程因为某种原因失去了 cpu 的使用权，暂时停止运行，一直等到线程进入就绪状态，才有机会转到运行状态，阻塞一般分为下面三种： 等待阻塞 ：运行的线程执行了 wait() 方法， JVM 会把该线程放入线程等待池中，（wait() 会释放持有的锁 ） 同步阻塞：运行的线程在获取对象的同步锁时，如果该同步锁被其他线程占用，这时此线程是无法运行的，那么 JVM 就会把该线程放入锁池中，导致阻塞 其他阻塞：运行的线程执行 sleep() 或者 join() 方法，或者发出了 I/O 请求，JVM 会把该线程置为阻塞状态，当 sleep() 状态超时、join() 等待线程终止或者超时、或者 I/O 处理完毕时，线程会重新进入就绪状态，（注意：sleep() 是不会释放本身持有的锁的） 无限期等待：等待其他线程显式地唤醒，否则不分配CPU时间片 死亡状态（Dead）：线程执行完了之后或者因为程序异常退出了 run() 方法，结束该线程的生命周期 线程常用函数start与run区别start()是启动一个新线程。通过start()方法来启动的新线程，处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行相应线程的run()方法， start() 可以启动一个新线程，run()不能 start()不能被重复调用，run()可以 start()中的run代码可以不执行完就继续执行下面的代码，即进行了线程切换。直接调用run方法必须等待其代码全部执行完才能继续执行下面的代码。 start() 实现了多线程，run()没有实现多线程。 通知与等待wait()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class MyThreadPrint extends Thread &#123; private String name; private final Object prev; private final Object self; private MyThreadPrint(String name, Object prev, Object self) &#123; this.name = name; this.prev = prev; this.self = self; &#125; @Override public void run() &#123; int count = 10; while (count &gt; 0) &#123; synchronized (prev) &#123; synchronized (self) &#123; System.out.println(name); count--; self.notify(); &#125; try &#123; prev.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Object A = new Object(); Object B = new Object(); Object C = new Object(); MyThreadPrint myA = new MyThreadPrint("A", C, A); MyThreadPrint myB = new MyThreadPrint("B", A, B); MyThreadPrint myC = new MyThreadPrint("C", B, C); try &#123; new Thread(myA).start(); Thread.sleep(100); new Thread(myB).start(); Thread.sleep(100); new Thread(myC).start(); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Obj.wait()，与Obj.notify()必须要与synchronized(Obj)一起使用，也就是wait,与notify是针对已经获取了Obj锁进行操作，从语法角度来说就是Obj.wait(),Obj.notify必须在synchronized(Obj){…}语句块内。从功能上来说wait就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的notify()唤醒该线程，才能继续获取对象锁，并继续执行。但有一点需要注意的是notify()调用后，并不是马上就释放对象锁的，而是在相应的synchronized(){}语句块执行结束，自动释放锁后，JVM会在wait()对象锁的线程中随机选取一线程，赋予其对象锁，唤醒线程，继续执行。Thread.sleep()与Object.wait()二者都可以暂停当前线程，释放CPU控制权，主要的区别在于Object.wait()在释放CPU同时，释放了对象锁的控制。 一个对象锁是prev，就是前一个线程所持有的对象锁。还有一个就是自身对象锁。主要的思想就是，为了控制执行的顺序，必须要先持有prev锁，也就前一个线程要释放自身对象锁，再去申请自身对象锁，两者兼备时打印，之后首先调用self.notify()释放自身对象锁，唤醒下一个等待线程，再调用prev.wait()释放prev对象锁，终止当前线程，等待循环结束后再次被唤醒。运行上述代码，可以发现三个线程循环打印ABC，共10次。程序运行的主要过程就是A线程最先运行，持有C,A对象锁，后释放A,C锁，唤醒B。线程B等待A锁，再申请B锁，后打印B，再释放B，A锁，唤醒C，线程C等待B锁，再申请C锁，后打印C，再释放C,B锁，唤醒A。看起来似乎没什么问题，但如果你仔细想一下，就会发现有问题，就是初始条件，三个线程按照A,B,C的顺序来启动，按照前面的思考，A唤醒B，B唤醒C，C再唤醒A。但是这种假设依赖于JVM中线程调度、执行的顺序。 setPriority(): 更改线程的优先级。 MIN_PRIORITY = 1NORM_PRIORITY = 5MAX_PRIORITY = 10 Join()为什么要用join()方法在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。1234567891011121314151617181920public class Main &#123; public static void main(String[] args) &#123; System.out.println(Thread.currentThread().getName()+"主线程运行开始!"); Thread1 mTh1=new Thread1("A"); Thread1 mTh2=new Thread1("B"); mTh1.start(); mTh2.start(); try &#123; mTh1.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; mTh2.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+ "主线程运行结束!"); &#125;&#125; yield():暂停当前正在执行的线程对象，并执行其他线程。 yield()应该做的是让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。结论：yield()从未导致线程转到等待/睡眠/阻塞状态。在大多数情况下，yield()将导致线程从运行状态转到可运行状态，但有可能没有效果。 sleep()和yield()的区别 sleep()和yield()的区别):sleep()使当前线程进入停滞状态，所以执行sleep()的线程在指定的时间内肯定不会被执行；yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。 sleep 方法使当前运行中的线程睡眼一段时间，进入不可运行状态，这段时间的长短是由程序设定的，yield 方法使当前线程让出 CPU 占有权，但让出的时间是不可设定的。实际上，yield()方法对应了如下操作：先检测当前是否有相同优先级的线程处于同可运行状态，如有，则把 CPU 的占有权交给此线程，否则，继续运行原来的线程。所以yield()方法称为“退让”，它把运行机会让给了同等优先级的其他线程 另外，sleep 方法允许较低优先级的线程获得运行机会，但 yield() 方法执行时，当前线程仍处在可运行状态，所以，不可能让出较低优先级的线程些时获得 CPU 占有权。在一个运行系统中，如果较高优先级的线程没有调用 sleep 方法，又没有受到 I\O 阻塞，那么，较低优先级线程只能等待所有较高优先级的线程运行结束，才有机会运行。 wait和sleep区别共同点： 他们都是在多线程的环境下，都可以在程序的调用处阻塞指定的毫秒数，并返回。 wait()和sleep()都可以通过interrupt()方法 打断线程的暂停状态 ，从而使线程立刻抛出InterruptedException。如果线程A希望立即结束线程B，则可以对线程B对应的Thread实例调用interrupt方法。如果此刻线程B正在wait/sleep /join，则线程B会立刻抛出InterruptedException，在catch() {} 中直接return即可安全地结束线程。需要注意的是，InterruptedException是线程自己从内部抛出的，并不是interrupt()方法抛出的。对某一线程调用 interrupt()时，如果该线程正在执行普通的代码，那么该线程根本就不会抛出InterruptedException。但是，一旦该线程进入到 wait()/sleep()/join()后，就会立刻抛出InterruptedException 。不同点： Thread类的方法：sleep(),yield()等Object的方法：wait()和notify()等 每个对象都有一个锁来控制同步访问。Synchronized关键字可以和对象的锁交互，来实现线程的同步。sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。 wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用 所以sleep()和wait()方法的最大区别是： sleep()睡眠时，保持对象锁，仍然占有该锁； 而wait()睡眠时，释放对象锁。 但是wait()和sleep()都可以通过interrupt()方法打断线程的暂停状态，从而使线程立刻抛出InterruptedException（但不建议使用该方法）。 参考Java多线程学习（吐血超详细总结） Java多线程基础学习]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose收集]]></title>
    <url>%2F2019%2F03%2F26%2Fdocker-compose%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[自己写的，收集整理的一些docker-compose.yml。 已有：Aria2, filebrowser, MongoDB, Redis Aria2一个多线程下载器，可由网页端管理 123456789101112131415version: '2'services: aria2: image: wahyd4/aria2-ui container_name: aria2 ports: - "6810:80" - "6800:6800" volumes: - /usr/conf/aria2:/root/conf - /media/download/aria2:/var/www:rw #- /usr/data/aria2:/var/www:rw environment: - DOMAIN=:80 restart: always 安装完成后通过http:ip/端口/ui才能访问到ui页面 filebrowserinstallation 首先需要在你需要准备config.json和database.db。默认用户名/密码为admin/admin config.json 12345678&#123; "port": 80, "baseURL": "", "address": "", "log": "stdout", "database": "/database.db", "root": "/srv"&#125; docker-compose.yml 123456789101112version: '2'services: file: container_name: filebrowser image: filebrowser/filebrowser ports: - "6880:80" volumes: - /media:/srv - /usr/conf/filebrowser/config.json:/config.json - /usr/conf/filebrowser/database.db:/database.db restart: unless-stopped Kod可道云 12345678910version: '2'services: kod: image: qinkangdeid/kodexplorer container_name: kod ports: - "80:80" volumes: - /usr/conf/kod:/var/www/html - /media:/data MongoDB123456789101112131415version: '3.1'services: mongo: image: mongo container_name: mongodb restart: always environment: MONGO_INITDB_ROOT_USERNAME: username MONGO_INITDB_ROOT_PASSWORD: password ports: - "27017:27017" volumes: - /usr/data/mongodb:/data/db MongoDB删除重复字段 123456789101112131415161718192021222324252627282930db.climage.aggregate([ &#123; $group: &#123; _id: &#123; title: '$title', page_url: '$page_url' &#125;, count: &#123; $sum: 1 &#125;, dups: &#123; $addToSet: '$_id' &#125; &#125; &#125;, &#123; $match: &#123; count: &#123; $gt: 1 &#125; &#125; &#125;]).forEach(function(doc) &#123; doc.dups.shift(); db.climage.remove(&#123; _id: &#123; $in: doc.dups &#125; &#125;);&#125;); NextCloud123456789101112131415version: "2"services: nextcloud: image: linuxserver/nextcloud container_name: nextcloud environment: - PUID=0 - PGID=0 - TZ=Asia/Shanghai volumes: - /usr/conf/nextcloud:/config - /media:/data ports: - "80:80" restart: unless-stopped RabbitMq1234567891011121314version: '3.0'services: rabbitmq: image: rabbitmq:management-alpine container_name: rabbitmq environment: - RABBITMQ_DEFAULT_USER=root - RABBITMQ_DEFAULT_PASS=654321 ports: - "1560:15672" - "5672:5672" volumes: - ./data:/var/lib/rabbitmq restart: always 5672：rabbitmq服务端口 1560：rabbitmq网页端口 Redis1234567891011version: '2'services: redis: image: redis container_name: redis ports: - 6379:6379 volumes: - /usr/conf/redis/redis.conf:/usr/local/etc/redis/redis.conf - /usr/conf/redis/data:/data restart: unless-stopped]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java虚拟机]]></title>
    <url>%2F2019%2F03%2F22%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[《深入理解Java虚拟机》读书笔记，以及其他关于JVM的一些博客 Java运行时数据区分为：程序计数器，Java虚拟机栈，本地方法区，Java堆，方法区 程序计数器，Java虚拟机，本地方法区是线程私有，随线程而生，随线程而灭。 程序计数器记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空），分支，跳转，异常处理都需要计数器完成。 Java虚拟机栈每个方法在执行的同时会创建一个栈帧用于存储局部变量表，操作数栈，常量池引用等信息。每一个方法从调用到执行完成的过程，对应一个栈帧在虚拟机中入栈到出栈的过程。 异常： 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。 本地方法栈为虚拟机使用到的Native方法服务。 异常： StackOverError， OutOfMemoryError Java堆被所有线程共享。存放对象实例，是垃圾收集器管理的主要区域，“GC堆”。 异常： OutOfMemoryError 方法区线程共享。存放被虚拟机加载的类信息，常量，静态变量，即时编译后的代码等数据。和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。 运行时常量池是方法区的一部分。用于存放编译期生成的各种字面量和符号引用。具备动态性。 直接内存在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。 垃圾收集主要针对堆和方法区。 判断对象是否可回收引用计数法为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 目前主流Java虚拟机没有使用这种方法。 可达性分析算法以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。 可作为GC Roots的对象： 虚拟机栈引用的对象 方法区静态属性引用对象 常量引用的对象 本地方法栈中引用的对象 引用类型 强引用 强引用的对象不会被回收。 1Object obj = new Object(); 软引用 有用但非必须的对象。在内存不够的情况下被回收。 弱引用 一定会被回收。 虚引用 又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。 为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。 回收过程一个对象死亡经历两次标记过程。第一次，使用可达性分析算法标记，判断对象是否需要执行finalize()方法，如果有必要执行，被一个低优先级的Finalizer线程执行。finalize()方法是对象逃脱死亡的最后一次机会。如果对象在finalize()中没有重新与引用链上任何一个对象建立关联，则会被回收。 当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。任何一个对象的finalize()只会被系统自动调用一次 方法区的回收方法区主要存放永久代对象。主要是对常量池的回收和对类的卸载。 类卸载条件： 该类所有的实例已经被回收，Java堆中不存在该类的任何实例 加载该类的CladdLoader被回收。 该类对应的java.lang.Class对象没有在任何地方被引用 垃圾收集算法标记-清除算法两个阶段：标记，清除。首先标记所有需要回收的对象，标记完成统一回收。 不足： 标记和清除效率都不高 标记清除后会产生大量不连续的内存碎片 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 实现简单，运行高效。不足为只用内存的一半 使用该算法收集新生代 标记-整理算法让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法将Java堆分为新生代和老年代。新生代选用复制算法，老年代使用：标记-清除或者标记-整理算法。 HotSpot算法实现GC进行时必须停顿所有Java执行线程，即STW(Stop The World)。 程序执行时只有在安全点才能发生GC。 垃圾收集器 1. Serial 收集器单线程收集器，进行垃圾收集时，必须暂停其他所有线程。 优点：简单高效，单个CPU环境，单线程收集效率高。 是Client模式下默认的新生代收集器。 2. ParNew 收集器Serial收集器的多线程版。 Server模式下虚拟机的默认新生代收集器。 3. Parallel Scavenge 收集器使用复制算法，多线程。 其他收集器关注点是尽量缩短垃圾收集时用户线程的停顿时间，它的目的是达到一个可控的吞吐量。 4. Serial Old 收集器Serial收集器的老年代版本，单线程，使用 标记-整理算法 Srver场景： 作为CMS收集器的后备 JDK1.5 前与 Parallel Scavenge收集器搭配 5. Parallel Old 收集器Parallel Scavenge 收集器的老年代版本。 在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 6. CMS收集器基于 标记-清除算法 流程： 初始标记：标记GC Roots能直接关联到的对象，速度快。需要Stop The World 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。需要Stop The World 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 优点：并发收集，低停顿 缺点： 对CPU资源敏感，因此吞吐量低 无法处理浮动垃圾， 标记 - 清除算法导致的空间碎片 7. G1 收集器G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 特点： 并行与并发：使用多个CPU缩短 STW的时间 分代收集： 空间整合：整体使用 标记-整理 算法，局部使用复制算法 可预测的停顿 收集范围是整个Java堆，把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 步骤： 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 内存分配与回收策略Minor GC 和 Full GC Minor GC：发生在新生代的垃圾收集，频繁，回收速度快 Full GC：发生在老年代的垃圾收集。伴随着至少一次的Minor GC，速度慢。 内存分配1. 对象优先在Eden分配大多数情况下，对象优先在新生代Eden分配。当Eden空间不够时，发起Minor GC。 2. 大对象直接进入老年代最典型的大对象是那种很长的字符串以及数组。 通过-XX:PretenureSizeThreshold参数，大于这个设置值的对象直接在老年代分配。避免在Eden曲和两个Survivor区发生大量内存复制。 3. 长期存活对象直接进入老年代对象在Eden出生并经历第一次Minor GC后任然存活，并能被Survivor接受，将被移动到Survivor空间，对象年龄为1,。对象在Survivor区每熬过一次，Minor GC，年龄增加一岁，增加到（默认15岁）被晋升到老年代中。 年龄阈值通过-XX:PretenureSizeThreshold设定 4. 动态对象年龄判定如果在Survivor空间中，相同年龄所有对象大小的总和大于Survivor空间的一半，年两大于等于改年龄的对象直接进入老年代。 5. 空间分配担保出现大量对象在Minor GC后仍然存活的情况，需要老年代进行分配担保，Survivor空间无法容纳的对象直接进入老年代。 类加载机制类与类加载器比较两个类是否相等，只有在两个类有同一个类加载器加载的前提下才有意义，否则，即使这两个类来自于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，这连个类必定不相等。 类加载器分类 启动类加载器 扩展类加载器 应用程序类加载器 双亲委派模型 双亲委派模型要求，除了顶层的启动类加载器，其他加载器都应该有自己的父类加载器。类加载器以组合的关系复用父加载器。 工作过程如果一个类加载器收到了类加载请求，它首先不会加载这个类，而是把这个请求委派给父类加载器完成，每一层次都是如此，因此所有的加载请求最终都会传送到顶层的启动类加载器，只有当父类加载器无法完成这个加载请求，子加载器才会尝试自己加载。 好处Java类随着他的加载器有了带有优先级的层次关系。例如 java.lang.Object 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2017. CS-Notes-Java 虚拟机 Javadoop - HotSpot JVM 内存管理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[西南交大教务模拟登陆]]></title>
    <url>%2F2019%2F01%2F29%2F%E8%A5%BF%E5%8D%97%E4%BA%A4%E5%A4%A7%E6%95%99%E5%8A%A1%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[最近由于需要做一个获取学生课表的项目，就去研究了下如何模拟登录，并用Python成功模拟登录。在此记录一下自己的分析过程。 登录分析使用Chrome登录教务网，打开调试模式，使用NetWork记录点击“登录按钮”后发生的过程 点击登录后浏览器请求的地址为http://dean.vatuu.com/vatuu/UserLoginAction，这就是我们需要记录的一个url，模拟登录时就向改网址发送请求； 我们需要重点分析Header和cookie。查看Response Header，该网址返回的Header信息有个Set-Cookie字段；在Request-Headers中，有一个JSESSIONID UserLoadingAction是登录成功后跳转的一个页面。查看Request Header中的Cookie为学号+JSESSIONID，因此明白JSESSIONID以及如何获取它至关重要。 另一个问题就是验证码，我采用人工输入的方式。审查元素，查看验证码的接口，得到其地址。 复制这个地址，粘贴到地址栏，得到验证码。 我猜想验证码和JSESSIONID有很大关系。退出教务登录，打开调试工具的“Application-Cookies”可以看到保存的Cookie，清除 刷新验证码地址，可以看到会再次出现JSESSIONID 因此可以假设通过验证码获取JSESSIONDI 使用Python尝试登录123456789101112def get_jsessionid(): """ 访问登录界面，通过Response Header用于获取set-cookie """ s = requests.Session() r = s.get(get_photo_url) with open('./static/ranstring.jpg', 'wb') as file: file.write(r.content) get_head = r.headers set_cookie = str(get_head['Set-Cookie']) jessid = set_cookie.split(';')[0] return jessid 运行后，可以看到获取到了JSESSIONID。 之后模拟登录。 123456789101112131415161718jsessionid = get_jsessionid()full_cookie = 'username='+str(data['username'])+'; ' + str(jsessionid)log_msg = ""def login(): """ 登录 """ # 登录需要的cookie只有jsessionid headers['cookie'] = jsessionid data['ranstring'] = input("验证码：") # UserLoginAction res = requests.post( user_log_url, data, headers=headers, allow_redirects=True) log_msg = res.text log_msg = json.loads(log_msg) print(log_msg['loginMsg']) 看到出现教务返回的登录成功等字样就表示登录成功。 尝试获取课表时，却提示未登录。我认为UserLoadingAction这一步也是必须的。 再次分析 查看UserLoadingAction，发现向它传送的数据中有一个“loginMsg”字段，这正是点击‘’登录系统“成功后返回的字段的一部分 在登录时访问UserLoadingAction查看是否生效 123456789101112131415161718192021def login(): """ 登录 两步：UserLoginAction + UserLoadingAction """ headers['cookie'] = jsessionid data['ranstring'] = input("验证码：") # UserLoginAction res = requests.post( user_log_url, data, headers=headers, allow_redirects=True) # with open('./response.html') as file: # file.writer(response.text) log_msg = res.text log_msg = json.loads(log_msg) print(log_msg['loginMsg']) # UserLoadingAction headers['cookie'] = full_cookie data_loading = &#123; 'loginMsg': log_msg['loginMsg'] &#125; res = requests.post(user_loading_url, data=data_loading, headers=headers) 查看res，会提示登录成功，这时在访问课表的网址，就正常返回了课表 总结 正确的Header和Cookie很重要]]></content>
      <categories>
        <category>学校</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
</search>
